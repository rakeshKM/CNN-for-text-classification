{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import numpy as np\n",
    "import argparse\n",
    "from collections import Counter\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading split information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11855\n"
     ]
    }
   ],
   "source": [
    "split_ind = []\n",
    "with open('../Datasets/SST1_dataset/datasetSplit.txt') as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        entry = line.split(',')\n",
    "        split_ind.append(int(entry[1]))\n",
    "\n",
    "print(len(split_ind))\n",
    "\n",
    "# Merging validation set to training data\n",
    "for i in range(len(split_ind)):\n",
    "    if split_ind[i] == 3:\n",
    "        split_ind[i] = 1\n",
    "        \n",
    "N_train = split_ind.count(1)\n",
    "N_test = split_ind.count(2)\n",
    "N_category = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Phrase -> Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239232 14058\n"
     ]
    }
   ],
   "source": [
    "phr_to_ind = dict()\n",
    "\n",
    "with open('../Datasets/SST1_dataset/dictionary.txt') as f:\n",
    "    for line in f:\n",
    "        entry = line.split('|')\n",
    "        phr_to_ind[entry[0]] = int(entry[1])\n",
    "\n",
    "keys = phr_to_ind.keys();\n",
    "\n",
    "print(len(phr_to_ind), phr_to_ind['Good'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9645 2210\n"
     ]
    }
   ],
   "source": [
    "# Without doing the below computation directly load the stored output\n",
    "x_train_sent = []\n",
    "x_test_sent = []\n",
    "sentiment = []\n",
    "\n",
    "counter = 0\n",
    "with open('../Datasets/SST1_dataset/SentenceWithCorrection.txt') as f:\n",
    "    for line in f:\n",
    "        sent = line[:-1]\n",
    "        if(split_ind[counter] == 1):\n",
    "            x_train_sent.append(sent)\n",
    "        else:\n",
    "            x_test_sent.append(sent)\n",
    "        \n",
    "        sentiment.append(phr_to_ind[sent])\n",
    "        counter += 1\n",
    "\n",
    "print(len(x_train_sent), len(x_test_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading sentiment information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9645 2210\n"
     ]
    }
   ],
   "source": [
    "ind_to_senti = dict()\n",
    "\n",
    "with open('../Datasets/SST1_dataset/sentiment_labels.txt') as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        entry = line.split('|')\n",
    "        ind_to_senti[int(entry[0])] = float(entry[1])\n",
    "\n",
    "y_label = []\n",
    "\n",
    "for ind in sentiment:\n",
    "    val = ind_to_senti[ind]\n",
    "    if val >= 0.0 and val <= 0.2:\n",
    "        y_label.append(0);\n",
    "    elif val > 0.2 and val <= 0.4:\n",
    "        y_label.append(1)\n",
    "    elif val > 0.4 and val <= 0.6:\n",
    "        y_label.append(2)\n",
    "    elif val > 0.6 and val <= 0.8:\n",
    "        y_label.append(3)\n",
    "    else:\n",
    "        y_label.append(4)\n",
    "\n",
    "y_train_org, y_test_org = [], []\n",
    "\n",
    "for i in range(len(y_label)):\n",
    "    label = y_label[i]\n",
    "    if split_ind[i] == 1:\n",
    "        y_train_org.append(label)\n",
    "    else:\n",
    "        y_test_org.append(label)\n",
    "        \n",
    "print(len(y_train_org), len(y_test_org))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Tokenize operation\n",
    "def tokenize(sentence, grams):\n",
    "    words = sentence.split()\n",
    "    tokens = []\n",
    "    for gram in grams:\n",
    "        for i in range(len(words) - gram + 1):\n",
    "            tokens += [\"_*_\".join(words[i:i+gram])]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def compute_ratio(poscounts, negcounts, alpha=1):\n",
    "    pos_keys = list(poscounts.keys())\n",
    "    neg_keys = list(negcounts.keys())\n",
    "    \n",
    "    alltokens = list(set( pos_keys + neg_keys))\n",
    "    dic = dict((t, i) for i, t in enumerate(alltokens))\n",
    "    d = len(dic)\n",
    "    p, q = np.ones(d) * alpha , np.ones(d) * alpha\n",
    "    for t in alltokens:\n",
    "        p[dic[t]] += poscounts[t]\n",
    "        q[dic[t]] += negcounts[t]\n",
    "    p /= abs(p).sum()\n",
    "    q /= abs(q).sum()\n",
    "    r = np.log(p/q)\n",
    "    return dic, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Creating train and test input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ngrams = [1,2,3]\n",
    "# max_token_num = -1;\n",
    "\n",
    "# for sent in x_train_sent:\n",
    "#     tokens = list(set(tokenize(sent, ngrams)))\n",
    "#     max_token_num = max(max_token_num, len(tokens))\n",
    "\n",
    "\n",
    "# for sent in x_test_sent:\n",
    "#     tokens = list(set(tokenize(sent, ngrams)))\n",
    "#     max_token_num = max(max_token_num, len(tokens))\n",
    "\n",
    "# X_train = np.zeros((len(x_train_sent), max_token_num), np.float64)\n",
    "# X_test = np.zeros((len(x_test_sent), max_token_num), np.float64)\n",
    "\n",
    "# print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f11 = open('train_pos-sent.txt', 'w')\n",
    "f12 = open('train_neg-sent.txt', 'w')\n",
    "\n",
    "count = 0\n",
    "for sent in x_train_sent:\n",
    "    if y_train_org[count] == 0:\n",
    "        f11.write(sent + '\\n')\n",
    "    else:\n",
    "        f12.write(sent + '\\n')\n",
    "    count += 1\n",
    "\n",
    "\n",
    "f21 = open('test_pos-sent.txt', 'w')\n",
    "f22 = open('test_neg-sent.txt', 'w')\n",
    "\n",
    "count = 0\n",
    "for sent in x_test_sent:\n",
    "    if y_test_org[count] == 0:\n",
    "        f21.write(sent + '\\n')\n",
    "    else:\n",
    "        f22.write(sent + '\\n')\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data class distribution: 8414 1231\n",
      "Test data class distribution: 1931 279\n",
      "Dictionary Size: 19463\n",
      "Trained SVM for cateogory:  0\n",
      "Train Accuracy 0.872369103162\n",
      "Test Accuracy 0.873755656109\n"
     ]
    }
   ],
   "source": [
    "ngrams = [1]\n",
    "Categories = [0,1,2,3,4]\n",
    "\n",
    "svm_oneVsAll = dict()\n",
    "\n",
    "N_TRAIN = len(y_train_org)\n",
    "N_TEST = len(y_test_org)\n",
    "N_CATEGORIES = len(Categories)\n",
    "\n",
    "y_train = np.zeros( (N_TRAIN,), np.int16)\n",
    "y_test  = np.zeros( (N_TEST,),  np.int16)\n",
    "\n",
    "pred_oneVsAll = np.zeros((N_TEST, N_CATEGORIES), np.int16)\n",
    "\n",
    "for category in Categories:\n",
    "    \n",
    "    for i in range(N_TRAIN):\n",
    "        if y_train_org[i] == category:\n",
    "            y_train[i] = 1\n",
    "        else:\n",
    "            y_train[i] = -1\n",
    "\n",
    "        \n",
    "    for i in range(N_TEST):\n",
    "        y_test[i] = (1) if y_test_org[i] == category else (-1)\n",
    "    \n",
    "    pos_obsv_num = np.sum(y_train == 1)\n",
    "    neg_obsv_num = np.sum(y_train == -1)\n",
    "    \n",
    "    print( 'Training data class distribution:', np.sum(y_train == -1), np.sum(y_train == 1))\n",
    "    print( 'Test data class distribution:', np.sum(y_test == -1), np.sum(y_test == 1))\n",
    "    \n",
    "    ratio = pos_obsv_num / neg_obsv_num\n",
    "    \n",
    "    svm_oneVsAll[category] = svm.SVC()\n",
    "    \n",
    "    # Getting count of words belonging to positive and negative class\n",
    "    poscounts = Counter()\n",
    "    negcounts = Counter()\n",
    "\n",
    "    counter = 0\n",
    "    for sent in x_train_sent:\n",
    "        if y_train[counter] == 1:\n",
    "            poscounts.update(tokenize(sent, ngrams))\n",
    "        else:\n",
    "            negcounts.update(tokenize(sent, ngrams))\n",
    "        counter += 1\n",
    "\n",
    "    dic, r = compute_ratio(poscounts, negcounts)\n",
    "    \n",
    "    print('Dictionary Size:', len(dic))\n",
    "    \n",
    "    vocab_size = len(dic)\n",
    "    \n",
    "    x_train = sp.lil_matrix((N_TRAIN, vocab_size), dtype=np.float32)\n",
    "\n",
    "    \n",
    "    counter = 0\n",
    "    for sent in x_train_sent:\n",
    "        tokens = tokenize(sent, ngrams)\n",
    "        indexes = []\n",
    "        for t in tokens:\n",
    "            if t in dic.keys():\n",
    "#                 indexes += [dic[t]]\n",
    "                x_train[counter,dic[t]] += r[dic[t]]\n",
    "#         indexes = list(set(indexes))\n",
    "\n",
    "#         for i in indexes:\n",
    "#             x_train[counter,i] = r[i]\n",
    "        \n",
    "        counter += 1 \n",
    "        \n",
    "    # Arrange test data\n",
    "    x_test = sp.lil_matrix((N_TEST, vocab_size), dtype=np.float32)\n",
    "    \n",
    "    counter = 0\n",
    "    for sent in x_test_sent:\n",
    "        tokens = tokenize(sent, ngrams)\n",
    "        indexes = []\n",
    "        for t in tokens:\n",
    "            if t in dic.keys():\n",
    "#                 indexes += [dic[t]]\n",
    "                x_test[counter, dic[t]] += r[dic[t]]\n",
    "#         indexes = list(set(indexes))\n",
    "\n",
    "#         for i in indexes:\n",
    "#             x_test[counter, i] = r[i]\n",
    "            \n",
    "        counter += 1\n",
    "    \n",
    "\n",
    "    svm_oneVsAll[category].fit(x_train, y_train)\n",
    "    print('Trained SVM for cateogory: ', category)\n",
    "    \n",
    "    pred_train = svm_oneVsAll[category].predict(x_train)\n",
    "    print( 'Train Accuracy', np.sum(pred_train == y_train)/ N_TRAIN)\n",
    "\n",
    "    pred_test = svm_oneVsAll[category].predict(x_test)\n",
    "    print( 'Test Accuracy', np.sum(pred_test == y_test)/ N_TEST)\n",
    "    \n",
    "    pred_oneVsAll[:, category] = pred_test\n",
    "    break\n",
    "    \n",
    "    print('------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',_*_a_*_thrill': 0,\n",
       " 'Auteuil_*_is_*_a': 2,\n",
       " 'Twinkie_*_--': 4,\n",
       " 'skill_*_of': 5,\n",
       " 'stillborn_*_except': 8,\n",
       " 'congratulate_*_himself_*_for': 10,\n",
       " 'a_*_soufflé_*_gone': 11,\n",
       " 'Things_*_I_*_Know': 13,\n",
       " 'in_*_handy': 216729,\n",
       " 'amateurish_*_,_*_quasi-improvised': 43369,\n",
       " 'fictional_*_,_*_some': 14,\n",
       " 'wanton_*_slipperiness_*_of': 237576,\n",
       " 'sons_*_,_*_and': 15,\n",
       " 'scenario': 173398,\n",
       " 'bombards_*_the': 226429,\n",
       " 'and_*_Cook': 16,\n",
       " 'strategy': 17,\n",
       " 'incognito_*_in_*_a': 18,\n",
       " 'From_*_New': 6,\n",
       " 'the_*_internal': 19,\n",
       " \"(_*_Kline_*_'s\": 148325,\n",
       " 'vistas_*_are_*_sweeping': 20,\n",
       " 'laughable_*_in_*_the': 23,\n",
       " 'other_*_,_*_but': 22,\n",
       " 'manifestation_*_of_*_institutionalized': 226684,\n",
       " 'and_*_a_*_personal': 24,\n",
       " 'stanzas_*_of': 236757,\n",
       " 'Coke_*_.': 25,\n",
       " 'Contradicts': 3,\n",
       " 'romance_*_you': 26,\n",
       " 'unemployment_*_,_*_Time': 28,\n",
       " 'price_*_of_*_popularity': 29,\n",
       " 'who_*_finds_*_his': 30,\n",
       " 'best_*_gay_*_love': 237578,\n",
       " 'has_*_been_*_able': 31,\n",
       " 'of_*_grace': 32,\n",
       " 'the_*_preachy_*_Circuit': 33,\n",
       " 'audiences_*_will': 35,\n",
       " 'embark_*_a': 36,\n",
       " 'whip-crack_*_of': 173400,\n",
       " 'size_*_of_*_a': 37,\n",
       " 'The_*_real_*_charm': 38,\n",
       " 'aristocracy_*_and': 39,\n",
       " 'face_*_while': 40,\n",
       " 'alive_*_to_*_witness': 41,\n",
       " 'Ya-Ya_*_Sisterhood_*_,': 7,\n",
       " 'Triumph_*_,': 42,\n",
       " 'looks_*_wonderful': 43,\n",
       " 'plot_*_follows_*_a': 43374,\n",
       " 'no_*_glance_*_.': 44,\n",
       " 'Menace': 50,\n",
       " 'special_*_is_*_how': 46,\n",
       " 'guiding_*_lights_*_.': 48,\n",
       " 'laughs_*_and_*_genuinely': 216735,\n",
       " 'Ring': 177525,\n",
       " 'narrative_*_flow_*_much': 9,\n",
       " 'freshness_*_and_*_modesty': 51,\n",
       " 'in_*_Late': 232886,\n",
       " 'good_*_pace_*_,': 52,\n",
       " 'because_*_Half_*_Past': 53,\n",
       " 'overlong_*_soap_*_opera': 55757,\n",
       " 'heart-wrenching_*_,': 47218,\n",
       " 'Smoochy_*_has': 55,\n",
       " 'Liu_*_never': 56,\n",
       " 'to_*_camp_*_or': 57,\n",
       " 'drama_*_:_*_What': 58,\n",
       " 'made_*_A_*_Walk': 59,\n",
       " \"'_*_were\": 60,\n",
       " \"'s_*_fitting_*_that\": 61,\n",
       " 'like_*_having_*_a': 185583,\n",
       " 'then_*_--_*_strangely': 62,\n",
       " 'Which_*_is': 70727,\n",
       " 'violent_*_,_*_self-indulgent': 64,\n",
       " 'might_*_soon_*_be': 65,\n",
       " 'of_*_those_*_energetic': 216739,\n",
       " 'this_*_sort_*_of': 66,\n",
       " 'while_*_clearly': 67,\n",
       " 'of_*_lo_*_mein': 68,\n",
       " 'cute_*_drama_*_.': 43382,\n",
       " 'direction_*_occasionally': 69,\n",
       " 'Fence': 216740,\n",
       " 'in_*_just': 70,\n",
       " 'shout_*_insults': 71,\n",
       " 'story_*_are_*_disjointed': 72,\n",
       " 'dullest_*_Irish': 75,\n",
       " 'about_*_impossible_*_,': 76,\n",
       " 'than_*_body_*_count': 77,\n",
       " 'standards_*_.': 130031,\n",
       " 'dulls_*_the_*_human': 79,\n",
       " 'to_*_face_*_and': 216744,\n",
       " 'animation_*_work_*_may': 80,\n",
       " 'Kennedy_*_,': 81,\n",
       " 'way_*_toward': 82,\n",
       " 'insults': 83,\n",
       " 'Troubling_*_and_*_powerful': 85,\n",
       " 'in_*_San_*_Diego': 86,\n",
       " 'Good_*_Thing': 86913,\n",
       " 'energy_*_of': 87,\n",
       " 'Although_*_mainstream': 88,\n",
       " 'should_*_be_*_ingratiating': 89,\n",
       " 'its_*_company_*_.': 90,\n",
       " 'light_*_on': 91,\n",
       " 'be_*_cut_*_and': 130034,\n",
       " 'viewing_*_this': 92,\n",
       " 'Nightmare': 93,\n",
       " 'not_*_do': 94,\n",
       " 'for_*_Damon\\\\/Bourne_*_or': 95,\n",
       " 'newcomer_*_Ellen': 96,\n",
       " 'is_*_,_*_overall': 97,\n",
       " 'and_*_odd_*_that': 98,\n",
       " 'stars_*_and': 43388,\n",
       " 'that_*_the_*_story': 99,\n",
       " 'cleverest': 86915,\n",
       " 'premise_*_,_*_only': 100,\n",
       " 'attract': 101,\n",
       " 'Seldom_*_has_*_a': 103,\n",
       " 'a_*_boffo_*_last': 104,\n",
       " 'maybe_*_,_*_that': 105,\n",
       " 'of_*_a_*_frustrating': 106,\n",
       " 'screen_*_effortlessly': 107,\n",
       " 'stands_*_for': 110,\n",
       " 'or_*_classical_*_familiarity': 111,\n",
       " 'vu_*_,_*_and': 115,\n",
       " 'cry_*_for_*_your': 114,\n",
       " 'Israeli': 116,\n",
       " 'nowheresville_*_in_*_every': 117,\n",
       " 'an_*_abridged': 127,\n",
       " '..._*_especially': 120,\n",
       " 'a_*_sea': 124,\n",
       " 'float': 195044,\n",
       " 'but_*_if_*_you': 122,\n",
       " 'the_*_working_*_poor': 246786,\n",
       " 'a_*_minute': 216754,\n",
       " 'Hopelessly': 125,\n",
       " 'seek': 126,\n",
       " 'discontent_*_,': 130,\n",
       " 'suffering_*_Afghan': 129,\n",
       " 'modestly_*_action-oriented': 131,\n",
       " 'is_*_indifferent': 132,\n",
       " 'Expands_*_the': 133,\n",
       " 'surprisingly_*_romantic_*_ride': 134,\n",
       " ',_*_critics_*_be': 138,\n",
       " 'compels': 173410,\n",
       " 'how_*_you': 137,\n",
       " 'support_*_a_*_film': 139,\n",
       " \"``_*_Cherish_*_''\": 140,\n",
       " \"Vera_*_'s_*_three\": 141,\n",
       " 'watchable_*_,_*_though': 199375,\n",
       " 'not_*_one_*_of': 21,\n",
       " 'cultivation_*_and': 142,\n",
       " 'loose_*_collection_*_of': 143,\n",
       " 'not_*_badly_*_art-directed': 144,\n",
       " 'arresting_*_little': 145,\n",
       " 'coherent_*_rhythm': 146,\n",
       " 'finding_*_solutions_*_.': 147,\n",
       " 'winning_*_shot_*_.': 148,\n",
       " 'Big_*_Daddy': 149,\n",
       " 'hard_*_not_*_to': 150,\n",
       " 'Hatosy': 173413,\n",
       " 'is_*_a_*_heartfelt': 151,\n",
       " 'lightest_*_,_*_most': 152,\n",
       " 'telling_*_scenes_*_.': 185650,\n",
       " 'have_*_enough_*_vices': 153,\n",
       " 'a_*_winning_*_,': 154,\n",
       " 'served_*_an_*_eviction': 155,\n",
       " 'very_*_welcome_*_sense': 156,\n",
       " 'uninitiated_*_plays': 157,\n",
       " 'mere_*_suggestion_*_,': 158,\n",
       " 'settles_*_too_*_easily': 180157,\n",
       " 'been_*_hoping': 159,\n",
       " 'desperately_*_looks': 161,\n",
       " 'Quite_*_frankly': 173414,\n",
       " 'directing_*_chops_*_,': 130047,\n",
       " 'loses_*_what': 162,\n",
       " 'the_*_fiery_*_presence': 163,\n",
       " 'are_*_many_*_definitions': 164,\n",
       " 'fluke_*_,_*_Lucky': 166,\n",
       " 'histrionics_*_failing': 167,\n",
       " 'Veers': 169,\n",
       " 'ones_*_who_*_are': 173,\n",
       " 'Witherspoon_*_were': 171,\n",
       " 'urbane': 172,\n",
       " 'of_*_art': 174,\n",
       " 'little_*_cult': 176,\n",
       " 'Antwone_*_Fisher_*_or': 177,\n",
       " 'surprisingly_*_`_*_solid': 178,\n",
       " 'Movie_*_makes_*_you': 179,\n",
       " 'and_*_shoot': 180,\n",
       " 'for_*_maximum_*_moisture': 182,\n",
       " 'moved_*_by_*_this': 183,\n",
       " 'release_*_in': 184,\n",
       " 'community': 185,\n",
       " 'exotic_*_surface': 186,\n",
       " 'Bugsy_*_than': 130049,\n",
       " 'mess_*_.': 187,\n",
       " 'rewarding_*_them_*_.': 188,\n",
       " 'of_*_Films_*_You': 189,\n",
       " 'Escape': 190,\n",
       " 'telling_*_of_*_a': 192,\n",
       " 'until': 193,\n",
       " \"Age_*_does_*_n't\": 194,\n",
       " 'bears': 195,\n",
       " 'than_*_a_*_traditionally': 196,\n",
       " 'scenes_*_of_*_torture': 198,\n",
       " 'a_*_basketball_*_game': 200,\n",
       " 'the_*_story_*_in': 202,\n",
       " 'washed_*_out': 203,\n",
       " 'standard_*_romantic_*_comedy': 204,\n",
       " 'terms_*_of_*_execution': 205,\n",
       " 'Terminally_*_brain': 206,\n",
       " 'spin_*_hopelessly': 208,\n",
       " 'feels_*_draggy': 209,\n",
       " 'Parts': 34,\n",
       " 'see_*_a_*_better': 210,\n",
       " 'clicking_*_together': 211,\n",
       " 'not_*_enough_*_to': 212,\n",
       " 'piece_*_with': 213,\n",
       " 'and_*_Corbett': 227783,\n",
       " \"n't_*_Hollywood_*_think\": 214,\n",
       " 'important_*_as': 215,\n",
       " \"'d_*_think_*_by\": 217,\n",
       " 'intriguing_*_wrinkles_*_.': 218,\n",
       " 'Béart_*_and': 220,\n",
       " 'underwhelming_*_.': 221,\n",
       " 'avalanche': 222,\n",
       " ',_*_wire': 223,\n",
       " 'Daphne_*_,_*_you': 224,\n",
       " 'aspiration_*_to': 225,\n",
       " 'articulate_*_player_*_,': 86934,\n",
       " 'Philadelphia': 226,\n",
       " 'then_*_found_*_its': 227,\n",
       " 'a_*_truly_*_frightening': 228,\n",
       " 'totally_*_unexpected': 179398,\n",
       " \"'s_*_Treasure_*_Island\": 86935,\n",
       " 'sleaziness_*_get_*_you': 231,\n",
       " 'an_*_MTV': 247181,\n",
       " 'popular_*_destination_*_for': 189712,\n",
       " 'Vicente_*_Aranda_*_for': 233,\n",
       " 'Another_*_Best_*_of': 234,\n",
       " 'earnest_*_try_*_at': 235,\n",
       " 'shrugging_*_mood': 236,\n",
       " 'many_*_clever_*_things': 237,\n",
       " 'insensitivity_*_towards': 238,\n",
       " 'often_*_achieves': 239,\n",
       " 'dish_*_of': 240,\n",
       " 'youth_*_market': 241,\n",
       " 'can_*_be_*_trained': 224079,\n",
       " 'lifeless': 242,\n",
       " 'writer\\\\/director_*_Bart_*_Freundlich': 233175,\n",
       " 'older_*_fans': 43412,\n",
       " 'boy_*_truly': 243,\n",
       " 'for_*_juicy_*_roles': 203547,\n",
       " ',_*_very_*_silly': 244,\n",
       " '``_*_soon-to-be-forgettable': 216781,\n",
       " 'series_*_than_*_a': 245,\n",
       " 'meets-new_*_mesh_*_is': 246,\n",
       " ',_*_based_*_on': 247,\n",
       " 'become_*_her': 248,\n",
       " 'poised_*_to': 173425,\n",
       " 'its_*_determined': 249,\n",
       " '90-minute_*_movie_*_that': 253562,\n",
       " 'collaboration_*_between_*_damaged': 250,\n",
       " 'guilt_*_and_*_innocence': 251,\n",
       " 'does_*_somehow': 43415,\n",
       " 'and_*_punching_*_people': 174851,\n",
       " 'action_*_,_*_but': 252,\n",
       " 'An_*_effective_*_portrait': 253,\n",
       " 'insistence': 254,\n",
       " 'fright': 255,\n",
       " 'charming_*_and_*_hilarious': 242064,\n",
       " ',_*_with_*_this': 257,\n",
       " '19th_*_century': 130058,\n",
       " 'human_*_one_*_.': 258,\n",
       " 'anti-human': 261,\n",
       " 'references_*_.': 260,\n",
       " 'enormously_*_endearing': 262,\n",
       " 'Movie_*_could_*_have': 264,\n",
       " 'likely_*_to_*_remember': 267,\n",
       " 'a_*_clashing': 268,\n",
       " 'not_*_vintage_*_Spielberg': 269,\n",
       " 'guilty_*_fun_*_to': 86944,\n",
       " 'sometimes_*_funnier': 271,\n",
       " 'descend_*_upon': 272,\n",
       " 'excitement_*_comes': 273,\n",
       " 'pants_*_and': 274,\n",
       " 'time_*_(_*_including': 275,\n",
       " 'college': 127688,\n",
       " \"Grant_*_'s_*_act\": 276,\n",
       " 'action_*_films': 277,\n",
       " 'a_*_Hollywood_*_satire': 278,\n",
       " 'the_*_Damned_*_,': 114296,\n",
       " 'After_*_watching_*_it': 279,\n",
       " 'Bedknobs': 281,\n",
       " 'my_*_uncles': 282,\n",
       " 'carnage_*_and': 283,\n",
       " 'Lucy': 284,\n",
       " 'with_*_bears': 288,\n",
       " 'Before_*_long': 287,\n",
       " 'that_*_borders': 86953,\n",
       " 'heartbreaking': 289,\n",
       " 'shot_*_that': 290,\n",
       " 'cartoons': 291,\n",
       " 'and_*_cerebral': 292,\n",
       " 'relate': 86955,\n",
       " 'Watchable_*_up_*_until': 294,\n",
       " 'rushed_*_to': 295,\n",
       " 'flashes_*_of': 300,\n",
       " 'about_*_a_*_Catholic': 297,\n",
       " 'be_*_gored': 99072,\n",
       " 'alive_*_only_*_when': 299,\n",
       " ')_*_proves_*_once': 301,\n",
       " 'a_*_well-made_*_and': 302,\n",
       " 'an_*_inhuman_*_monster': 47,\n",
       " 'say_*_about_*_growing': 303,\n",
       " \"in_*_a_*_'60s\": 304,\n",
       " 'Nolden_*_--': 305,\n",
       " 'little_*_too_*_obvious': 307,\n",
       " 'be_*_exploring_*_the': 308,\n",
       " \"region_*_'s\": 310,\n",
       " \"of_*_one_*_'s\": 312,\n",
       " 'the_*_plot_*_goes': 313,\n",
       " 'Almost': 49,\n",
       " 'consigned_*_.': 314,\n",
       " 'office_*_.': 43424,\n",
       " 'takes_*_the_*_beauty': 130070,\n",
       " 'parent_*_and': 220746,\n",
       " 'eventually_*_winning_*_squareness': 95865,\n",
       " 'not_*_necessarily': 315,\n",
       " 'lensing_*_of_*_the': 86960,\n",
       " 'by_*_its_*_intimacy': 317,\n",
       " 'Mr._*_Hartley': 216791,\n",
       " 'the_*_failure': 319,\n",
       " 'mean_*_that': 321,\n",
       " 'viewer_*_in': 323,\n",
       " ',_*_parking_*_lots': 216793,\n",
       " 'weird_*_performances': 324,\n",
       " 'and_*_will_*_surely': 325,\n",
       " 'series_*_of_*_Bible': 326,\n",
       " 'the_*_magic_*_that': 328,\n",
       " 'Deserving': 331,\n",
       " 'will_*_stand': 330,\n",
       " 'conjuring_*_up': 332,\n",
       " 'reading_*_your_*_scripts': 333,\n",
       " 'people_*_in_*_ABC': 338,\n",
       " 'manner_*_that_*_by': 336,\n",
       " 'miracles_*_,_*_the': 337,\n",
       " \"Ana_*_'s_*_journey\": 230968,\n",
       " 'hem': 339,\n",
       " 'a_*_shame': 340,\n",
       " 'Hungry-Man_*_portions_*_of': 342,\n",
       " \"`_*_it_*_'s\": 343,\n",
       " 'Barry_*_Sonnenfeld_*_to': 54,\n",
       " 'want_*_to_*_believe': 345,\n",
       " 'a_*_travel-agency': 346,\n",
       " 'gone_*_that': 347,\n",
       " 'somber_*_earnestness': 348,\n",
       " 'and_*_damaged': 349,\n",
       " \"it_*_'s_*_telling\": 43432,\n",
       " 'no_*_one_*_,': 351,\n",
       " 'go_*_through_*_.': 352,\n",
       " 'drama_*_within_*_the': 353,\n",
       " 'escapism_*_.': 355,\n",
       " 'in_*_heels': 356,\n",
       " ',_*_told': 357,\n",
       " 'little_*_else_*_;': 365,\n",
       " 'what_*_gives': 360,\n",
       " 'interesting_*_to_*_those': 363,\n",
       " '``_*_Pick': 362,\n",
       " 'material_*_,_*_provides': 173438,\n",
       " 'rarely_*_seem': 364,\n",
       " 'And_*_people_*_make': 367,\n",
       " 'worrying_*_about': 368,\n",
       " 'proud_*_of': 370,\n",
       " 'strutting_*_and': 371,\n",
       " 'Boasts_*_enough_*_funny': 372,\n",
       " 'unfocused_*_screenplay': 373,\n",
       " 'large-screen_*_format': 374,\n",
       " 'It_*_never_*_is': 375,\n",
       " 'Tommy': 379,\n",
       " 'in_*_insignificance_*_,': 380,\n",
       " 'Kathryn': 130077,\n",
       " 'its_*_story_*_about': 382,\n",
       " 'In_*_capturing': 383,\n",
       " 'amicable_*_endeavor': 173441,\n",
       " 'limited_*_to': 130079,\n",
       " 'Nasty_*_,_*_ugly': 216800,\n",
       " 'soul-searching_*_garbage': 384,\n",
       " 'of_*_denuded': 385,\n",
       " 'interesting_*_but': 387,\n",
       " 'for_*_that_*_reason': 388,\n",
       " 'technological_*_finish': 43439,\n",
       " \"'s_*_reworking\": 390,\n",
       " 'an_*_exploitation_*_piece': 391,\n",
       " 'clever_*_ideas_*_and': 392,\n",
       " 'date_*_last_*_fall': 393,\n",
       " 'reach_*_satisfying_*_conclusions': 394,\n",
       " ',_*_pointless': 395,\n",
       " 'things_*_Pokemon_*_wo': 43441,\n",
       " 'tedious_*_scenes_*_,': 208346,\n",
       " 'say_*_the': 396,\n",
       " 'yet_*_at_*_the': 398,\n",
       " 'enough_*_clever_*_and': 399,\n",
       " 'by_*_editing': 408,\n",
       " 'pretty_*_mediocre_*_family': 401,\n",
       " 'Bard_*_as': 403,\n",
       " 'he_*_directed_*_,': 409,\n",
       " 'four_*_hankies': 207424,\n",
       " 'win': 406,\n",
       " 'resembles_*_this': 407,\n",
       " 'tries-so-hard-to-be-cool_*_``_*_Clockstoppers': 411,\n",
       " 'by_*_emphasizing_*_the': 412,\n",
       " 'restatement_*_is_*_validated': 216801,\n",
       " 'Featuring_*_a': 413,\n",
       " 'First-timer': 416,\n",
       " 'Lane_*_and_*_Richard': 251929,\n",
       " ',_*_narratively': 417,\n",
       " 'biopic_*_hammers_*_home': 255768,\n",
       " \"best_*_does_*_n't\": 242624,\n",
       " \"'s_*_a_*_minor\": 419,\n",
       " \"Cockettes_*_'\": 420,\n",
       " 'color_*_palette': 421,\n",
       " 'Nine_*_Queens_*_is': 422,\n",
       " 'Portentous': 424,\n",
       " 'life_*_as_*_seen': 425,\n",
       " 'his_*_dancing_*_shoes': 427,\n",
       " 'into_*_Charleston_*_rhythms': 130088,\n",
       " 'that_*_encourages_*_you': 429,\n",
       " \"'s_*_Way_*_.\": 257049,\n",
       " 'and_*_forth_*_between': 431,\n",
       " 'breathe_*_out_*_of': 432,\n",
       " 'expect_*_from_*_movies': 435,\n",
       " 'slice_*_it': 434,\n",
       " 'Vincent_*_R.': 436,\n",
       " 'scary_*_enough_*_.': 437,\n",
       " 'miracle_*_in_*_Unfaithful': 63,\n",
       " 'time_*_about_*_10': 438,\n",
       " 'Willis_*_is': 439,\n",
       " 'of_*_phrase_*_that': 441,\n",
       " 'watched': 442,\n",
       " 'is_*_reliable': 443,\n",
       " 'the_*_enterprise_*_.': 444,\n",
       " 'play_*_a': 445,\n",
       " 'is_*_an_*_Actress': 446,\n",
       " 'skin_*_and': 447,\n",
       " 'the_*_usher': 448,\n",
       " 'under_*_the': 449,\n",
       " 'built_*_for_*_controversy': 450,\n",
       " 'cleverly_*_plotted': 451,\n",
       " 'Kissinger_*_.': 452,\n",
       " 'of_*_whatever_*_idealism': 453,\n",
       " 'and_*_Glass_*_put': 455,\n",
       " 'captures_*_,': 456,\n",
       " 'a_*_disastrous': 457,\n",
       " 'Boasts_*_eye-catching': 458,\n",
       " 'Revolution_*_from_*_the': 459,\n",
       " 'of_*_both_*_worlds': 462,\n",
       " 'In_*_gleefully_*_,': 463,\n",
       " ',_*_half_*_an': 464,\n",
       " 'each_*_watered': 465,\n",
       " 'trapped_*_while': 466,\n",
       " 'heavy-handed_*_.': 467,\n",
       " 'many_*_things_*_--': 468,\n",
       " 'graphic_*_treatment': 86979,\n",
       " 'for_*_a_*_routine': 469,\n",
       " '1.2': 471,\n",
       " 'showmanship': 472,\n",
       " 'of_*_Games': 473,\n",
       " ',_*_circumstantial_*_evidence': 475,\n",
       " 'diversity': 476,\n",
       " 'deep_*_or_*_substantial': 185661,\n",
       " 'Every_*_visual': 86982,\n",
       " 'amiable_*_aimlessness_*_that': 485,\n",
       " 'disrespected': 482,\n",
       " 'unwise_*_amalgam_*_of': 483,\n",
       " 'Dodger': 484,\n",
       " \"'s_*_consistently_*_surprising\": 173457,\n",
       " 'fuzziness': 73,\n",
       " ',_*_partly': 486,\n",
       " 'before_*_his': 487,\n",
       " 'more_*_frustrating_*_as': 488,\n",
       " 'funnier_*_than_*_being': 74,\n",
       " 'Hades_*_.': 490,\n",
       " 'pop_*_thriller_*_is': 173462,\n",
       " 'Crush_*_thrillingly': 491,\n",
       " 'It_*_still_*_feels': 492,\n",
       " 'the_*_Great_*_American': 493,\n",
       " 'kind_*_of_*_subject': 494,\n",
       " 'mind-numbingly_*_,': 495,\n",
       " 'psychological_*_grounding_*_for': 496,\n",
       " \"''_*_were\": 497,\n",
       " 'depending_*_upon_*_where': 498,\n",
       " 'ground_*_dramatically_*_,': 499,\n",
       " 'unusually_*_dry-eyed': 501,\n",
       " 'nearly_*_as_*_downbeat': 503,\n",
       " 'a_*_formulaic': 506,\n",
       " 'only_*_by_*_the': 505,\n",
       " 'doing_*_in_*_here': 216814,\n",
       " 'acting_*_debut_*_as': 507,\n",
       " 'its_*_message_*_with': 508,\n",
       " ',_*_obsessive_*_relationships': 509,\n",
       " 'saying_*_that': 510,\n",
       " \"'s_*_similarly_*_updated\": 511,\n",
       " 'difference': 512,\n",
       " 'stormy_*_night_*_...': 513,\n",
       " \"King_*_,_*_'\": 130098,\n",
       " 'Day-Lewis_*_as_*_much': 514,\n",
       " 'compete_*_for': 517,\n",
       " 'be_*_smack_*_in': 516,\n",
       " 'of_*_particular_*_interest': 518,\n",
       " 'idiosyncratic_*_humor': 520,\n",
       " 'where_*_the_*_situations': 521,\n",
       " 'of_*_a_*_corporate': 522,\n",
       " \"'s_*_throbbing\": 523,\n",
       " \"n't_*_faked\": 524,\n",
       " 'make_*_than': 525,\n",
       " 'decades_*_,_*_since': 526,\n",
       " \"'ve_*_marveled\": 527,\n",
       " 'astute_*_first': 528,\n",
       " 'turning_*_one': 530,\n",
       " 'after_*_being_*_an': 531,\n",
       " 'be_*_an_*_astronaut': 532,\n",
       " 'Funeral_*_and_*_Bridget': 534,\n",
       " 'Kendall_*_and_*_directed': 537,\n",
       " 'comes_*_through': 536,\n",
       " 'who_*_could': 539,\n",
       " 'having_*_a_*_hard': 540,\n",
       " 'spirits_*_and_*_leave': 130105,\n",
       " \"curlers_*_is_*_n't\": 541,\n",
       " 'an_*_imaginatively': 542,\n",
       " 'a_*_perverse': 548,\n",
       " 'and_*_truth-in-advertising': 544,\n",
       " \"''_*_which_*_is\": 546,\n",
       " 'magical_*_movie_*_.': 547,\n",
       " 'countenance': 549,\n",
       " 'instructive_*_and_*_thoroughly': 78,\n",
       " 'underplays': 550,\n",
       " 'performers_*_and': 551,\n",
       " 'adaptation_*_of_*_Evans': 553,\n",
       " 'laughed_*_,': 554,\n",
       " 'film_*_comes_*_along': 555,\n",
       " \"the_*_maker_*_'s\": 556,\n",
       " 'by_*_superb': 557,\n",
       " 'it_*_earns': 558,\n",
       " 'decided_*_that_*_--': 216824,\n",
       " 'anything_*_resembling_*_humor': 559,\n",
       " 'reruns_*_.': 561,\n",
       " 'deserve_*_.': 562,\n",
       " 'casting_*_of_*_the': 564,\n",
       " 'it_*_may_*_still': 176526,\n",
       " 'major_*_waste': 565,\n",
       " 'You_*_is_*_pure': 566,\n",
       " 'its_*_comic': 567,\n",
       " 'specific_*_story_*_to': 568,\n",
       " 'Seigner': 569,\n",
       " 'to-do_*_list_*_.': 572,\n",
       " 'narrative_*_as_*_if': 571,\n",
       " 'intelligent_*_humor': 573,\n",
       " 'Perdition': 576,\n",
       " 'turns_*_out': 216827,\n",
       " 'myself_*_howling_*_more': 581,\n",
       " 'twenty-first_*_century_*_America': 580,\n",
       " 'and_*_unsatisfying': 216828,\n",
       " 'and_*_love_*_in': 582,\n",
       " \"through_*_Dahmer_*_'s\": 173473,\n",
       " 'plot_*_threads': 583,\n",
       " 'establishes_*_its_*_ominous': 130116,\n",
       " 'The_*_way': 259243,\n",
       " 'church_*_meetings': 173474,\n",
       " 'an_*_exceptionally': 584,\n",
       " ',_*_pratfalls': 585,\n",
       " \"''_*_,_*_and\": 586,\n",
       " 'easy_*_jokes': 587,\n",
       " 'as_*_a_*_secular': 588,\n",
       " 'Christina_*_Ricci': 589,\n",
       " 'to_*_sneeze_*_at': 590,\n",
       " 'between_*_this_*_and': 591,\n",
       " 'in_*_1990': 592,\n",
       " 'of_*_official': 593,\n",
       " 'Sugar_*_is_*_such': 595,\n",
       " 'glitz': 596,\n",
       " 'Padre_*_Amaro': 259735,\n",
       " 'unpleasant_*_that_*_I': 597,\n",
       " 'questions_*_on': 598,\n",
       " 'mind': 599,\n",
       " 'rapport_*_with': 601,\n",
       " 'is_*_ingenious_*_fun': 602,\n",
       " 'and_*_satisfying': 603,\n",
       " 'exercise_*_in_*_trying': 216834,\n",
       " 'they_*_make': 605,\n",
       " 'says_*_it': 84,\n",
       " 'in_*_the_*_life': 606,\n",
       " 'worth_*_sitting_*_through': 607,\n",
       " 'mean_*_.': 608,\n",
       " 'interminably': 173482,\n",
       " 'the_*_six-time_*_winner': 235134,\n",
       " 'at_*_other_*_times': 610,\n",
       " 'leave_*_the_*_theater': 171875,\n",
       " 'This_*_is_*_absolutely': 611,\n",
       " 'an_*_entertaining': 612,\n",
       " \"Crudup_*_'s_*_screen\": 613,\n",
       " 'crazy_*_confluence_*_of': 614,\n",
       " 'paces_*_again': 616,\n",
       " 'too_*_contrived': 43470,\n",
       " 'very_*_hard': 617,\n",
       " 'redundant_*_to_*_say': 618,\n",
       " 'is_*_probably': 130125,\n",
       " 'move_*_.': 620,\n",
       " 'the_*_director_*_has': 621,\n",
       " 'to_*_scale_*_the': 622,\n",
       " 'popcorn_*_movies_*_with': 623,\n",
       " 'Ringu_*_,_*_it': 624,\n",
       " \"the_*_Canadian_*_'s\": 625,\n",
       " 'storytelling_*_that': 627,\n",
       " 'gets_*_girl': 218679,\n",
       " 'non-stop_*_funny': 629,\n",
       " 'it_*_otherwise': 630,\n",
       " 'has_*_conjured': 257871,\n",
       " 'two_*_or': 632,\n",
       " 'parachutes': 635,\n",
       " 'a_*_perfectly_*_acceptable': 634,\n",
       " 'subcultures_*_.': 637,\n",
       " 'make_*_Trouble_*_Every': 639,\n",
       " 'of_*_a_*_phony': 640,\n",
       " 'question': 641,\n",
       " 'some_*_movies_*_and': 643,\n",
       " 'not_*_the_*_first': 644,\n",
       " 'acting_*_talents': 645,\n",
       " 'calculated_*_to_*_provoke': 130129,\n",
       " 'does_*_such': 129064,\n",
       " 'as_*_much_*_as': 648,\n",
       " 'a_*_grisly': 649,\n",
       " 'Century_*_France_*_:': 651,\n",
       " 'puréed': 239943,\n",
       " 'person_*_,': 652,\n",
       " 'Westerners_*_are_*_unfamiliar': 87024,\n",
       " 'scores_*_a': 653,\n",
       " 'up_*_--': 654,\n",
       " 'Ralph': 655,\n",
       " ',_*_virulently': 656,\n",
       " ',_*_especially_*_ones': 216844,\n",
       " 'sensual_*_metaphorical': 659,\n",
       " 'inspires_*_trembling': 19505,\n",
       " 'Fulfills_*_the_*_minimum': 43477,\n",
       " 'it_*_borrows': 660,\n",
       " \"'s_*_calculated_*_events\": 661,\n",
       " 'inept_*_and': 662,\n",
       " 'CHiPs': 663,\n",
       " \"Abagnale_*_'s\": 664,\n",
       " \"'s_*_Hollywood_*_counterparts\": 665,\n",
       " 'Space_*_Station_*_3D': 666,\n",
       " 'clever_*_script_*_and': 43487,\n",
       " 'as_*_it_*_explores': 667,\n",
       " 'its_*_kids-in-peril': 668,\n",
       " 'what_*_is_*_otherwise': 670,\n",
       " 'and_*_has_*_decided': 671,\n",
       " 'just_*_as_*_I': 672,\n",
       " 'the_*_most_*_highly-praised': 673,\n",
       " 'style_*_,_*_structure': 676,\n",
       " 'Béart_*_..._*_continue': 675,\n",
       " 'up_*_its': 122985,\n",
       " 'look_*_as': 677,\n",
       " 'a_*_resonant_*_undertone': 678,\n",
       " 'and_*_the_*_Whale': 679,\n",
       " 'minded_*_patience': 680,\n",
       " 'of_*_colonics_*_,': 681,\n",
       " ',_*_and_*_motorcycles': 173493,\n",
       " 'hellish_*_,_*_numbing': 682,\n",
       " 'has_*_a_*_spirit': 683,\n",
       " 'event_*_movies': 684,\n",
       " 'female_*_camaraderie': 685,\n",
       " ',_*_brilliant_*_and': 686,\n",
       " 'sparking_*_debate_*_and': 105865,\n",
       " 'and_*_energy_*_it': 688,\n",
       " 'Greatest_*_Musicians': 689,\n",
       " 'treads_*_of': 87027,\n",
       " 'over_*_the_*_map': 690,\n",
       " 'fraction': 691,\n",
       " 'come_*_in': 693,\n",
       " 'we_*_believe_*_that': 694,\n",
       " 'paved_*_with_*_good': 697,\n",
       " 'DeNiro': 696,\n",
       " 'a_*_fierce_*_struggle': 698,\n",
       " 'creepy_*_and': 121908,\n",
       " 'cotton': 699,\n",
       " 'touching_*_as_*_The': 700,\n",
       " \"But_*_Toback_*_'s\": 130137,\n",
       " 'its_*_clunky_*_dialogue': 701,\n",
       " 'be_*_as_*_bored': 702,\n",
       " 'fresh_*_good_*_looks': 196738,\n",
       " 'ship_*_in_*_January': 703,\n",
       " 'her_*_husband_*_,': 704,\n",
       " 'pointless_*_French': 705,\n",
       " \"'s_*_a_*_buggy\": 706,\n",
       " 'contemplates': 708,\n",
       " 'of_*_a_*_puzzling': 709,\n",
       " 'male_*_hip_*_hop': 711,\n",
       " 'guessable': 87031,\n",
       " 'energy_*_to': 109315,\n",
       " 'how_*_thoroughly_*_unrewarding': 713,\n",
       " 'into_*_a_*_poem': 216857,\n",
       " 'lightweight_*_commercial': 715,\n",
       " 'on_*_a_*_job': 716,\n",
       " 'a_*_holiday': 717,\n",
       " 'their_*_Hollywood': 718,\n",
       " 'sophisticated_*_wit_*_and': 719,\n",
       " 'distinctly_*_mixed': 727,\n",
       " 'everything_*_its_*_fans': 722,\n",
       " 'epic_*_tale_*_into': 723,\n",
       " 'lofty_*_expectations_*_,': 726,\n",
       " 'goods': 229523,\n",
       " 'appeal_*_to_*_the': 728,\n",
       " 'timely_*_look': 731,\n",
       " 'first_*_starring_*_role': 730,\n",
       " 'to_*_show_*_for': 108,\n",
       " 'very_*_lively': 734,\n",
       " 'Reeks': 735,\n",
       " 'urges_*_and': 736,\n",
       " 'Stallone_*_flick_*_would': 737,\n",
       " 'anyone_*_more_*_central': 87036,\n",
       " 'to_*_the_*_point': 739,\n",
       " \",_*_it_*_'ll\": 741,\n",
       " 'of_*_Welcome_*_to': 742,\n",
       " 'bent_*_to_*_the': 743,\n",
       " 'curiously_*_stylized_*_,': 173507,\n",
       " 'into_*_their_*_mental': 745,\n",
       " 'freezers_*_.': 750,\n",
       " 'passable_*_enough': 751,\n",
       " ',_*_Sia_*_lacks': 748,\n",
       " 'of_*_Mr._*_Deeds': 749,\n",
       " 'very_*_graphic': 752,\n",
       " 'heart_*_to_*_venture': 753,\n",
       " 'education_*_and_*_good': 754,\n",
       " 'of_*_a_*_minimalist': 755,\n",
       " 'wanes_*_dramatically': 756,\n",
       " 'unmotivated_*_,': 757,\n",
       " \"''_*_movie\": 759,\n",
       " 'a_*_fierce': 109,\n",
       " ')_*_forgets': 761,\n",
       " 'to_*_enjoy_*_for': 762,\n",
       " ',_*_Frida_*_gets': 763,\n",
       " 'beloved-major_*_-': 764,\n",
       " 'on_*_chain_*_letters': 766,\n",
       " 'has_*_at_*_least': 767,\n",
       " 'or_*_care_*_about': 769,\n",
       " 'Sayles_*_has': 770,\n",
       " 'rediscovers_*_his': 216863,\n",
       " 'suck_*_up_*_to': 771,\n",
       " '..._*_strains_*_the': 775,\n",
       " 'attack': 773,\n",
       " 'on_*_glamour': 774,\n",
       " 'Confessions_*_is_*_without': 173509,\n",
       " 'broader_*_vision': 171609,\n",
       " 'sure_*_the': 112,\n",
       " \"director_*_'s_*_epitaph\": 182307,\n",
       " 'Though_*_Tom_*_Shadyac': 776,\n",
       " 'see_*_the_*_Hollywood': 43496,\n",
       " 'its_*_true-to-life_*_characters': 777,\n",
       " 'thud': 778,\n",
       " \"man_*_'s_*_body\": 87041,\n",
       " 'senseless_*_,': 779,\n",
       " 'britches_*_.': 783,\n",
       " 'you_*_look': 781,\n",
       " 'by_*_the_*_NBA': 782,\n",
       " 'symbolic_*_images_*_with': 216865,\n",
       " 'coming-of-age_*_story_*_we': 43499,\n",
       " 'the_*_third_*_ending': 785,\n",
       " '``_*_The_*_Dangerous': 173511,\n",
       " 'recommendation_*_.': 786,\n",
       " 'no_*_currency': 790,\n",
       " 'nothing_*_overtly_*_disagreeable': 788,\n",
       " 'ice_*_cold': 792,\n",
       " 'and_*_Speck': 251976,\n",
       " 'a_*_wild_*_ride': 794,\n",
       " 'tone_*_that_*_few': 795,\n",
       " 'Try_*_Hell': 797,\n",
       " \"terrible_*_,_*_''\": 799,\n",
       " 'moments_*_where': 800,\n",
       " 'the_*_same_*_name': 801,\n",
       " \"n't_*_dismiss_*_BarberShop\": 130153,\n",
       " 'thoroughly_*_unfaithful': 802,\n",
       " 'Ana': 220558,\n",
       " 'the_*_cruelties_*_experienced': 803,\n",
       " 'front_*_and': 804,\n",
       " 'for_*_its_*_story': 805,\n",
       " 'story_*_of_*_two': 806,\n",
       " 'how_*_similar_*_obsessions': 807,\n",
       " 'interdependence': 808,\n",
       " 'liner_*_as_*_well': 809,\n",
       " 'Rodriguez_*_adorns': 810,\n",
       " 'a_*_major_*_career': 812,\n",
       " 'of_*_inspired': 219232,\n",
       " 'courage_*_of': 813,\n",
       " 'done_*_before': 121,\n",
       " 'filmmaking_*_,': 14728,\n",
       " 'his_*_ingredients_*_is': 815,\n",
       " \"'d_*_expected_*_it\": 18625,\n",
       " 'The_*_screenplay_*_by': 817,\n",
       " 'plenty_*_fetching': 818,\n",
       " 'punched_*_through_*_by': 819,\n",
       " 'China': 820,\n",
       " 'his_*_cast_*_members': 822,\n",
       " '..._*_since_*_last': 255913,\n",
       " 'trots_*_out_*_the': 824,\n",
       " 'like_*_some_*_weird': 828,\n",
       " 'view_*_one': 826,\n",
       " 'ride_*_that_*_relies': 827,\n",
       " 'enjoyable_*_experience': 829,\n",
       " 'glumly_*_mishandle': 830,\n",
       " 'to_*_the_*_film': 216876,\n",
       " 'a_*_homage_*_to': 832,\n",
       " 'reminding_*_audiences_*_that': 216873,\n",
       " 'as_*_an_*_addictive': 173521,\n",
       " 'emotional_*_need': 833,\n",
       " 'publishing_*_giant': 837,\n",
       " 'this_*_sensuous': 173522,\n",
       " 'than_*_make': 838,\n",
       " ',_*_old-fashioned_*_monster': 839,\n",
       " 'A_*_mean-spirited': 840,\n",
       " 'strip': 199947,\n",
       " \"'s_*_Burns_*_'\": 841,\n",
       " 'concert_*_comedy': 843,\n",
       " 'above_*_similar': 844,\n",
       " 'changes_*_that_*_fit': 232369,\n",
       " 'seem_*_goofy': 43508,\n",
       " 'sense_*_of_*_fierce': 846,\n",
       " 'for_*_industrial-model_*_meat': 853,\n",
       " 'fish_*_that': 850,\n",
       " 'lies_*_in_*_an': 851,\n",
       " '--_*_at_*_least': 128,\n",
       " ',_*_cliche-ridden_*_endeavor': 852,\n",
       " 'ice_*_water_*_in': 247047,\n",
       " 'mood': 854,\n",
       " 'of_*_the_*_pitfalls': 173528,\n",
       " 'precise': 856,\n",
       " \"you_*_'re_*_one\": 43513,\n",
       " 'funnier_*_than_*_anything': 857,\n",
       " 'since_*_it_*_is': 174011,\n",
       " 'then_*_gives_*_us': 858,\n",
       " 'human_*_moments_*_.': 859,\n",
       " 'Prurient_*_playthings': 860,\n",
       " 'And_*_butterflies_*_that': 861,\n",
       " \"'s_*_never_*_too\": 862,\n",
       " 'climate': 864,\n",
       " 'to_*_slo-mo_*_gun': 865,\n",
       " 'comforting_*_jar_*_of': 867,\n",
       " 'A_*_marvelous': 216883,\n",
       " 'permits_*_laughter_*_.': 868,\n",
       " 'Imagine_*_Entertainment_*_to': 43515,\n",
       " \"'s_*_..._*_worth\": 870,\n",
       " 'warm_*_our': 871,\n",
       " 'goofball': 872,\n",
       " 'zeal_*_of': 149336,\n",
       " \"'s_*_abundant\": 130166,\n",
       " 'given_*_here_*_are': 87062,\n",
       " 'its_*_pedestrian': 873,\n",
       " 'up_*_out': 876,\n",
       " 'One': 875,\n",
       " 'the_*_playful': 87065,\n",
       " 'but_*_this_*_film': 877,\n",
       " 'He_*_nonetheless': 878,\n",
       " 'he_*_touches_*_to': 136,\n",
       " 'a_*_while': 880,\n",
       " 'quite_*_funny_*_,': 881,\n",
       " 'appealing_*_,_*_but': 883,\n",
       " 'and_*_Miller': 884,\n",
       " 'acceptance_*_to_*_each': 885,\n",
       " 'III': 887,\n",
       " 'states_*_at_*_one': 121084,\n",
       " 'and_*_painful': 888,\n",
       " 'mull': 889,\n",
       " 'a_*_hallucinatory': 130170,\n",
       " 'relentlessly_*_depressing_*_situation': 890,\n",
       " 'Pryce': 891,\n",
       " 'leaps_*_over': 892,\n",
       " 'experimental_*_in': 893,\n",
       " 'forgets_*_about_*_her': 894,\n",
       " 'Both_*_an_*_admirable': 895,\n",
       " 'with_*_moviegoers': 896,\n",
       " 'richer_*_and_*_deeper': 87070,\n",
       " 'movie_*_during': 897,\n",
       " 'Friend': 898,\n",
       " 'indeed_*_almost': 899,\n",
       " 'being_*_rewarded': 900,\n",
       " 'thought_*_.': 901,\n",
       " 'let_*_Crocodile': 902,\n",
       " 'terrific_*_and_*_bewilderingly': 903,\n",
       " 'sessions_*_are_*_intriguing': 904,\n",
       " 'merely_*_indulges': 905,\n",
       " 'love_*_has_*_never': 185120,\n",
       " 'laugh_*_if_*_a': 107545,\n",
       " 'Spall': 906,\n",
       " ',_*_disintegrating': 907,\n",
       " 'sense_*_of_*_real': 216887,\n",
       " 'sophomore_*_slump': 908,\n",
       " 'Chinese_*_society': 909,\n",
       " 'compelling_*_one': 910,\n",
       " 'hammering_*_home_*_his': 130174,\n",
       " 'backstage_*_drama_*_,': 911,\n",
       " 'documentary_*_subject_*_.': 912,\n",
       " 'episodic_*_choppiness': 913,\n",
       " 'no_*_brainer_*_.': 915,\n",
       " 'my_*_future': 916,\n",
       " 'ultimately_*_,_*_finding': 78481,\n",
       " 'cowardly_*_autocritique_*_.': 917,\n",
       " 'listless': 918,\n",
       " 'is_*_great_*_material': 919,\n",
       " 'Needs': 920,\n",
       " 'advance_*_screening_*_.': 921,\n",
       " 'minutes_*_or_*_so': 923,\n",
       " 'sense_*_,_*_such': 239128,\n",
       " 'and_*_violence_*_,': 130181,\n",
       " 'sick_*_sight': 926,\n",
       " 'Audrey_*_Tautou_*_with': 927,\n",
       " 'masochism_*_?': 928,\n",
       " 'as_*_the_*_grown': 929,\n",
       " 'mayhem_*_as_*_Cage': 930,\n",
       " 'engage_*_in_*_.': 931,\n",
       " 'show_*_that_*_hinges': 932,\n",
       " 'its_*_celeb-strewn': 934,\n",
       " 'such_*_as_*_``': 228275,\n",
       " 'the_*_a_*_\\\\*\\\\*': 935,\n",
       " 'the_*_art_*_of': 936,\n",
       " 'learned_*_from_*_watching': 937,\n",
       " 'a_*_consistent': 938,\n",
       " 'snaps_*_under_*_the': 939,\n",
       " 'promises_*_:_*_A': 940,\n",
       " 'pieces_*_do': 155419,\n",
       " 'Shallow_*_,': 941,\n",
       " 'Fisher_*_certainly': 942,\n",
       " 'in_*_Igby_*_come': 130185,\n",
       " 'several_*_themes': 943,\n",
       " 'Onion_*_have_*_proven': 945,\n",
       " 'the_*_right_*_place': 946,\n",
       " 'The_*_turntable': 947,\n",
       " 'recent_*_holiday': 948,\n",
       " 'sharp_*_and': 949,\n",
       " 'fundamentally_*_unknowable_*_even': 950,\n",
       " 'of_*_incendiary': 951,\n",
       " 'and_*_savage_*_full-bodied': 952,\n",
       " 'Goldman_*_,': 953,\n",
       " 'open-hearted_*_film_*_that': 954,\n",
       " 'Ordinary': 957,\n",
       " 'make_*_much_*_sense': 956,\n",
       " 'advised_*_to_*_take': 958,\n",
       " 'even_*_of_*_what': 257354,\n",
       " 'your_*_neck_*_long': 960,\n",
       " 'screenplay_*_of_*_what': 961,\n",
       " 'political_*_and': 962,\n",
       " 'thought_*_--_*_and': 963,\n",
       " 'Age_*_follows_*_most': 43530,\n",
       " 'camps_*_up_*_a': 965,\n",
       " 'movie_*_production_*_values': 230702,\n",
       " \"'s_*_rude\": 966,\n",
       " 'lead_*_you': 967,\n",
       " 'work_*_without': 970,\n",
       " 'regular_*_shocks_*_and': 969,\n",
       " 'evocative_*_film': 973,\n",
       " 'her_*_characters_*_.': 974,\n",
       " 'good_*_video': 43533,\n",
       " \"'s_*_stupid_*_.\": 65945,\n",
       " 'running_*_around': 136661,\n",
       " 'when_*_they_*_were': 976,\n",
       " 'and_*_stunt_*_cars': 977,\n",
       " 'rises_*_to': 980,\n",
       " 'of_*_way_*_--': 979,\n",
       " 'It_*_excels': 226835,\n",
       " 'self-esteem': 984,\n",
       " 'by_*_linking': 982,\n",
       " 'amateurish_*_filmmaking': 983,\n",
       " 'story_*_and_*_cautionary': 985,\n",
       " 'entertainment_*_standards': 986,\n",
       " 'grandly': 987,\n",
       " 'national_*_boundaries': 989,\n",
       " \",_*_I_*_'d\": 990,\n",
       " 'so_*_you_*_can': 992,\n",
       " 'disease-of': 994,\n",
       " 'Korea_*_through': 995,\n",
       " 'on_*_old': 996,\n",
       " 'approach_*_,': 999,\n",
       " 'swim_*_through': 1001,\n",
       " 'cheeky_*_charm': 1002,\n",
       " 'character_*_that_*_may': 216902,\n",
       " 'reeks_*_like_*_a': 160,\n",
       " 'head_*_and': 1003,\n",
       " 'a_*_bank_*_manager': 173549,\n",
       " 'change_*_of_*_mindless': 1006,\n",
       " ',_*_That_*_is': 1005,\n",
       " 'seen_*_City_*_by': 1008,\n",
       " 'their_*_hearts_*_in': 105139,\n",
       " 'General_*_Tso': 1009,\n",
       " 'Robert_*_Duvall': 1014,\n",
       " 'a_*_successful_*_career': 1013,\n",
       " 'reverberates': 211303,\n",
       " ':_*_A_*_look': 201667,\n",
       " 'considerable_*_aplomb': 1017,\n",
       " 'Bray_*_,_*_whose': 1016,\n",
       " 'and_*_goes_*_there': 1018,\n",
       " ')_*_peels_*_layers': 1019,\n",
       " 'sales': 1020,\n",
       " \"like_*_Scorsese_*_'s\": 1021,\n",
       " ...}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0935504 ,  1.47984476,  0.0935504 , ...,  0.0935504 ,\n",
       "        0.0935504 ,  1.47984476])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1231"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = svm_oneVsAll[0]\n",
    "np.sum(a.dual_coef_ == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13352.46"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pred_maj = np.sum(pred_oneVsAll, axis=1)\n",
    "print(pred_maj.shape)\n",
    "for j in range(np.size(x_train,0)):\n",
    "    count = 0\n",
    "    for i in np.arange(np.size(x_train,1)):\n",
    "        if x_train[0,i] != 0:\n",
    "            count += 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Computing $w^{T}x +b$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "category = 0\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    y_train[i] = (1) if y_train_org[i] == category else (-1)\n",
    "    \n",
    "supp_alpha = svm_oneVsAll[0].dual_coef_\n",
    "supp_vecs = svm_oneVsAll[0].support_vectors_\n",
    "supp_ind = svm_oneVsAll[0].support_\n",
    "b = svm_oneVsAll[0].intercept_\n",
    "# w = np.zeros( (1,np.size(supp_vecs,1)), np.float32)\n",
    "w = sp.csr_matrix((1, np.size(supp_vecs,1)))\n",
    "\n",
    "counter = 0\n",
    "for i in supp_ind:\n",
    "    w = w + (supp_alpha[0,counter]*y_train[i])*supp_vecs[counter,:]\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.sum(pred_maj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for j in range(np.size(x_train,0)):\n",
    "    count = 0\n",
    "    for i in np.arange(np.size(x_train,1)):\n",
    "        if x_train[0,i] != 0:\n",
    "            count += 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "supp_vecs[1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "supp_vecs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
