{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import numpy as np\n",
    "import argparse\n",
    "from collections import Counter\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading split information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11855\n"
     ]
    }
   ],
   "source": [
    "split_ind = []\n",
    "with open('../Datasets/SST1_dataset/datasetSplit.txt') as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        entry = line.split(',')\n",
    "        split_ind.append(int(entry[1]))\n",
    "\n",
    "print(len(split_ind))\n",
    "\n",
    "# Merging validation set to training data\n",
    "for i in range(len(split_ind)):\n",
    "    if split_ind[i] == 3:\n",
    "        split_ind[i] = 1\n",
    "        \n",
    "N_train = split_ind.count(1)\n",
    "N_test = split_ind.count(2)\n",
    "N_category = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Phrase -> Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239232 14058\n"
     ]
    }
   ],
   "source": [
    "phr_to_ind = dict()\n",
    "\n",
    "with open('../Datasets/SST1_dataset/dictionary.txt') as f:\n",
    "    for line in f:\n",
    "        entry = line.split('|')\n",
    "        phr_to_ind[entry[0]] = int(entry[1])\n",
    "\n",
    "keys = phr_to_ind.keys();\n",
    "\n",
    "print(len(phr_to_ind), phr_to_ind['Good'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9645 2210\n"
     ]
    }
   ],
   "source": [
    "# Without doing the below computation directly load the stored output\n",
    "x_train_sent = []\n",
    "x_test_sent = []\n",
    "sentiment = []\n",
    "\n",
    "counter = 0\n",
    "with open('../Datasets/SST1_dataset/SentenceWithCorrection.txt') as f:\n",
    "    for line in f:\n",
    "        sent = line[:-1]\n",
    "        if(split_ind[counter] == 1):\n",
    "            x_train_sent.append(sent)\n",
    "        else:\n",
    "            x_test_sent.append(sent)\n",
    "        \n",
    "        sentiment.append(phr_to_ind[sent])\n",
    "        counter += 1\n",
    "\n",
    "print(len(x_train_sent), len(x_test_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading sentiment information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9645 2210\n"
     ]
    }
   ],
   "source": [
    "ind_to_senti = dict()\n",
    "\n",
    "with open('../Datasets/SST1_dataset/sentiment_labels.txt') as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        entry = line.split('|')\n",
    "        ind_to_senti[int(entry[0])] = float(entry[1])\n",
    "\n",
    "y_label = []\n",
    "\n",
    "for ind in sentiment:\n",
    "    val = ind_to_senti[ind]\n",
    "    if val >= 0.0 and val <= 0.2:\n",
    "        y_label.append(0);\n",
    "    elif val > 0.2 and val <= 0.4:\n",
    "        y_label.append(1)\n",
    "    elif val > 0.4 and val <= 0.6:\n",
    "        y_label.append(2)\n",
    "    elif val > 0.6 and val <= 0.8:\n",
    "        y_label.append(3)\n",
    "    else:\n",
    "        y_label.append(4)\n",
    "\n",
    "y_train_org, y_test_org = [], []\n",
    "\n",
    "for i in range(len(y_label)):\n",
    "    label = y_label[i]\n",
    "    if split_ind[i] == 1:\n",
    "        y_train_org.append(label)\n",
    "    else:\n",
    "        y_test_org.append(label)\n",
    "        \n",
    "print(len(y_train_org), len(y_test_org))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Tokenize operation\n",
    "def tokenize(sentence, grams):\n",
    "    words = sentence.split()\n",
    "    tokens = []\n",
    "    for gram in grams:\n",
    "        for i in range(len(words) - gram + 1):\n",
    "            tokens += [\"_*_\".join(words[i:i+gram])]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def compute_ratio(poscounts, negcounts, alpha=1):\n",
    "    pos_keys = list(poscounts.keys())\n",
    "    neg_keys = list(negcounts.keys())\n",
    "    \n",
    "    alltokens = list(set( pos_keys + neg_keys))\n",
    "    dic = dict((t, i) for i, t in enumerate(alltokens))\n",
    "    d = len(dic)\n",
    "    p, q = np.ones(d) * alpha , np.ones(d) * alpha\n",
    "    for t in alltokens:\n",
    "        p[dic[t]] += poscounts[t]\n",
    "        q[dic[t]] += negcounts[t]\n",
    "    p /= abs(p).sum()\n",
    "    q /= abs(q).sum()\n",
    "    r = np.log(p/q)\n",
    "    return dic, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Creating train and test input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9645, 154) (2210, 154)\n"
     ]
    }
   ],
   "source": [
    "ngrams = [1,2,3]\n",
    "max_token_num = -1;\n",
    "\n",
    "for sent in x_train_sent:\n",
    "    tokens = list(set(tokenize(sent, ngrams)))\n",
    "    max_token_num = max(max_token_num, len(tokens))\n",
    "\n",
    "\n",
    "for sent in x_test_sent:\n",
    "    tokens = list(set(tokenize(sent, ngrams)))\n",
    "    max_token_num = max(max_token_num, len(tokens))\n",
    "\n",
    "X_train = np.zeros((len(x_train_sent), max_token_num), np.float64)\n",
    "X_test = np.zeros((len(x_test_sent), max_token_num), np.float64)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data class distribution: 1231 8414\n",
      "Test data class distribution: 279 1931\n",
      "Trained SVM for cateogory:  0\n",
      "Train Accuracy 0.996163815448\n",
      "Test Accuracy 0.871040723982\n",
      "------------------------------------------------\n",
      "Training data class distribution: 2507 7138\n",
      "Test data class distribution: 633 1577\n",
      "Trained SVM for cateogory:  1\n",
      "Train Accuracy 0.996993260757\n",
      "Test Accuracy 0.713574660633\n",
      "------------------------------------------------\n",
      "Training data class distribution: 1853 7792\n",
      "Test data class distribution: 389 1821\n",
      "Trained SVM for cateogory:  2\n",
      "Train Accuracy 0.99678589943\n",
      "Test Accuracy 0.819004524887\n",
      "------------------------------------------------\n",
      "Training data class distribution: 2601 7044\n",
      "Test data class distribution: 510 1700\n",
      "Trained SVM for cateogory:  3\n",
      "Train Accuracy 0.996889580093\n",
      "Test Accuracy 0.764705882353\n",
      "------------------------------------------------\n",
      "Training data class distribution: 1453 8192\n",
      "Test data class distribution: 399 1811\n",
      "Trained SVM for cateogory:  4\n",
      "Train Accuracy 0.99678589943\n",
      "Test Accuracy 0.825339366516\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ngrams = [1,2,3]\n",
    "Categories = [0,1,2,3,4]\n",
    "\n",
    "svm_oneVsAll = dict()\n",
    "for category in Categories:\n",
    "    svm_oneVsAll[category] = svm.SVC()\n",
    "\n",
    "y_train = np.zeros( (len(y_train_org),), np.int8)\n",
    "y_test = np.zeros( (len(y_test_org),), np.int8)\n",
    "    \n",
    "pred_oneVsAll = np.zeros((len(x_test_sent), len(Categories)), np.int8)\n",
    "\n",
    "for category in Categories:\n",
    "    \n",
    "    for i in range(len(y_train)):\n",
    "        y_train[i] = (0) if y_train_org[i] == category else (1)\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        y_test[i] = (0) if y_test_org[i] == category else (1)\n",
    "    \n",
    "    print( 'Training data class distribution:', np.sum(y_train == 0), np.sum(y_train == 1))\n",
    "    print( 'Test data class distribution:', np.sum(y_test == 0), np.sum(y_test == 1))\n",
    "    # Getting count of words belonging to positive and negative class\n",
    "    poscounts = Counter()\n",
    "    negcounts = Counter()\n",
    "\n",
    "    counter = 0\n",
    "    for sent in x_train_sent:\n",
    "        if y_train[counter] == 0:\n",
    "            poscounts.update(tokenize(sent, ngrams))\n",
    "        else:\n",
    "            negcounts.update(tokenize(sent, ngrams))\n",
    "        counter += 1\n",
    "\n",
    "    dic, r = compute_ratio(poscounts, negcounts)\n",
    "\n",
    "    x_train = []\n",
    "    for sent in x_train_sent:\n",
    "        tokens = tokenize(sent, ngrams)\n",
    "        indexes = []\n",
    "        for t in tokens:\n",
    "            try:\n",
    "                indexes += [dic[t]]\n",
    "            except KeyError:\n",
    "                pass\n",
    "        indexes = list(set(indexes))\n",
    "        indexes.sort()\n",
    "\n",
    "        data = []\n",
    "        for i in indexes:\n",
    "            data.append(r[i])\n",
    "        x_train.append(data)\n",
    "        \n",
    "    # Arrange test data\n",
    "    x_test = []\n",
    "\n",
    "    for sent in x_test_sent:\n",
    "        tokens = tokenize(sent, ngrams)\n",
    "        indexes = []\n",
    "        for t in tokens:\n",
    "            try:\n",
    "                indexes += [dic[t]]\n",
    "            except KeyError:\n",
    "                pass\n",
    "        indexes = list(set(indexes))\n",
    "        indexes.sort()\n",
    "\n",
    "        data = []\n",
    "        for i in indexes:\n",
    "            data.append(r[i])\n",
    "        x_test.append(data)\n",
    "    \n",
    "    for i in range(len(x_train)):\n",
    "        res = x_train[i]\n",
    "        X_train[i, :len(res)] = np.float64(res)\n",
    "        \n",
    "    for i in range(len(x_test)):\n",
    "        res = x_test[i]\n",
    "        X_test[i, :len(res)] = np.float64(res)\n",
    "\n",
    "    svm_oneVsAll[category].fit(X_train, y_train)\n",
    "    print('Trained SVM for cateogory: ', category)\n",
    "    \n",
    "    pred_train = svm_oneVsAll[category].predict(X_train)\n",
    "    print( 'Train Accuracy', np.sum(pred_train == y_train)/ len(y_train))\n",
    "\n",
    "    pred_test = svm_oneVsAll[category].predict(X_test)\n",
    "    print( 'Test Accuracy', np.sum(pred_test == y_test)/ len(y_test))\n",
    "    \n",
    "    pred_oneVsAll[:, category] = pred_test\n",
    "    \n",
    "    print('------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2210,)\n"
     ]
    }
   ],
   "source": [
    "pred_maj = np.sum(pred_oneVsAll, axis=1)\n",
    "print(pred_maj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_maj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
