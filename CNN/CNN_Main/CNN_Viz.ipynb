{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Embedding, regularizers\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras import backend as K\n",
    "from w2v import train_word2vec \n",
    "from keras.utils import np_utils\n",
    "import pickle, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import SnowballStemmer\n",
    "from w2v import train_word2vec \n",
    "import pickle, datetime\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, ..., 4, 3, 0])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Datasets/SST1_dataset/Processed_SST1.tsv', sep='\\t')\n",
    "train_df = pd.read_csv('../../Datasets/Kaggle_dataset/train.tsv', sep='\\t', header=0)\n",
    "\n",
    "raw_docs_train      = df[df.split_ind == 1]['Phrases'].values\n",
    "sentiment_train     = df[df.split_ind == 1]['Label'].values\n",
    "raw_docs_test       = df[df.split_ind == 2]['Phrases'].values\n",
    "sentiment_test      = df[df.split_ind == 2]['Label'].values\n",
    "raw_docs_test       = np.append(raw_docs_test, ['I hate this movie'])\n",
    "sentiment_test      = np.append(sentiment_test, [1])\n",
    "num_labels          = len(np.unique(sentiment_train))\n",
    "\n",
    "N_TRAIN = len(raw_docs_train)\n",
    "N_TEST = len(raw_docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-processing train docs...\n",
      "pre-processing test docs...\n",
      "converting to token ids...\n"
     ]
    }
   ],
   "source": [
    "#text pre-processing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['.', ',', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}'])\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "print (\"pre-processing train docs...\")\n",
    "processed_docs_train = []\n",
    "for doc in raw_docs_train:\n",
    "   tokens = word_tokenize(doc)\n",
    "   filtered = [word for word in tokens if word not in stop_words]\n",
    "   stemmed = [stemmer.stem(word) for word in filtered]\n",
    "   processed_docs_train.append(stemmed)\n",
    "\n",
    "print (\"pre-processing test docs...\")\n",
    "processed_docs_test = []\n",
    "for doc in raw_docs_test:\n",
    "   tokens = word_tokenize(doc)\n",
    "   filtered = [word for word in tokens if word not in stop_words]\n",
    "   stemmed = [stemmer.stem(word) for word in filtered]\n",
    "   processed_docs_test.append(stemmed)\n",
    "    \n",
    "processed_docs_all = np.concatenate((processed_docs_train, processed_docs_test), axis=0)\n",
    "\n",
    "dictionary = corpora.Dictionary(processed_docs_all)\n",
    "dictionary_size = len(dictionary.keys())\n",
    "\n",
    "print (\"converting to token ids...\")\n",
    "word_id_train, word_id_len = [], []\n",
    "for doc in processed_docs_train:\n",
    "    word_ids = [dictionary.token2id[word] for word in doc]\n",
    "    word_id_train.append(word_ids)\n",
    "    word_id_len.append(len(word_ids))\n",
    "\n",
    "word_id_test, word_ids = [], []\n",
    "for doc in processed_docs_test:\n",
    "    word_ids = [dictionary.token2id[word] for word in doc]\n",
    "    word_id_test.append(word_ids)\n",
    "    word_id_len.append(len(word_ids))\n",
    "        \n",
    "seq_len = np.round((np.mean(word_id_len) + 2*np.std(word_id_len))).astype(int)\n",
    "\n",
    "#pad sequences\n",
    "x_train = sequence.pad_sequences(np.array(word_id_train), maxlen=seq_len)\n",
    "x_test  = sequence.pad_sequences(np.array(word_id_test), maxlen=seq_len)\n",
    "y_train = np_utils.to_categorical(sentiment_train, num_labels)\n",
    "y_test  = np_utils.to_categorical(sentiment_test, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_9 (InputLayer)             (None, 21)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding (Embedding)            (None, 21, 100)       1380100                                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 21, 100)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)               (None, 19, 50)        15050                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)               (None, 18, 50)        20050                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)               (None, 17, 50)        25050                                        \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D)  (None, 1, 50)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D)  (None, 1, 50)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D)  (None, 1, 50)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)             (None, 50)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)             (None, 50)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)             (None, 50)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 150)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 150)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 50)            7550                                         \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 5)             255                                          \n",
      "====================================================================================================\n",
      "Total params: 1,448,055.0\n",
      "Trainable params: 1,448,055.0\n",
      "Non-trainable params: 0.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filename = '/home/shikhar/Dropbox/IISC/Machine_Learning/ML_Project/Images/sst_cnn_rand/sst_cnn_rand_3'\n",
    "\n",
    "out = []\n",
    "with open( filename, 'rb') as input:\n",
    "    out = pickle.load(input)\n",
    "    \n",
    "model = Model.from_config(out[0])\n",
    "model.set_weights(out[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 33.77%\n",
      "Accuracy: 28.18%\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(0.01), metrics=[\"accuracy\"])\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_9 (InputLayer)             (None, 21)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding (Embedding)            (None, 21, 100)       1380100                                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 21, 100)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)               (None, 19, 50)        15050                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)               (None, 18, 50)        20050                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)               (None, 17, 50)        25050                                        \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D)  (None, 1, 50)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D)  (None, 1, 50)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D)  (None, 1, 50)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)             (None, 50)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)             (None, 50)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)             (None, 50)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 150)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 150)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 50)            7550                                         \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 5)             255                                          \n",
      "====================================================================================================\n",
      "Total params: 1,448,055.0\n",
      "Trainable params: 1,448,055.0\n",
      "Non-trainable params: 0.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occlusion Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = word_id_test[0]\n",
    "x_test1 = sequence.pad_sequences([vec], maxlen=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.token2id\n",
    "dictionary.id2token = dict((v, k) for k, v in dictionary.token2id.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.argmax(test_pred, axis=1)\n",
    "y_actual = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.304387155133\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(test_pred == y_actual)*1.0 / y_actual.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "crct_pred = (test_pred == y_actual)\n",
    "ind = []\n",
    "for i in range(crct_pred.shape[0]):\n",
    "    if crct_pred[i] == 1:\n",
    "        ind.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, ..., 3, 0, 1])"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Original Prediction [[ 0.15741763  0.27602369  0.24537784  0.21322405  0.10795683]]\n",
      "i\n",
      "[[ 0.1766758   0.3095786   0.24850512  0.17698482  0.08825567]]\n",
      "movi\n",
      "[[ 0.17958815  0.31474501  0.24892661  0.17189257  0.08484766]]\n",
      "hate\n",
      "[[ 0.17677309  0.31203997  0.249431    0.17556125  0.08619471]]\n"
     ]
    }
   ],
   "source": [
    "k = -1\n",
    "print(y_actual[ind[k]])\n",
    "vec = word_id_test[ind[k]]\n",
    "\n",
    "org_pred =  model.predict(x_test[ind[k]:ind[k]+1, :])\n",
    "print('Original Prediction', org_pred)\n",
    "\n",
    "for ele in list(set(vec)):\n",
    "    vec_temp = [i for i in vec if i != ele]    \n",
    "    x_test1 = sequence.pad_sequences([vec_temp], maxlen=seq_len, padding=\"post\", truncating=\"post\")\n",
    "    pred = model.predict(x_test1)\n",
    "    print(dictionary.id2token[ele])\n",
    "    print(pred)\n",
    "#     print(dictionary.id2token[ele], '\\t', pred )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For layer 0 -----------------\n",
      "{'batch_input_shape': (None, 21), 'sparse': False, 'dtype': 'float32', 'name': 'input_9'}\n",
      "Input shape (None, 21)\n",
      "Ouput shape (None, 21)\n",
      "\n",
      "For layer 1 -----------------\n",
      "{'input_length': 21, 'embeddings_regularizer': None, 'dtype': 'int32', 'batch_input_shape': (None, 21), 'trainable': True, 'embeddings_constraint': None, 'mask_zero': False, 'output_dim': 100, 'name': 'embedding', 'embeddings_initializer': {'class_name': 'RandomUniform', 'config': {'seed': None, 'minval': -0.05, 'maxval': 0.05}}, 'activity_regularizer': None, 'input_dim': 13801}\n",
      "Input shape (None, 21)\n",
      "Ouput shape (None, 21, 100)\n",
      "\n",
      "For layer 2 -----------------\n",
      "{'trainable': True, 'rate': 0.5, 'name': 'dropout_12'}\n",
      "Input shape (None, 21, 100)\n",
      "Ouput shape (None, 21, 100)\n",
      "\n",
      "For layer 3 -----------------\n",
      "{'bias_constraint': None, 'kernel_size': (3,), 'padding': 'valid', 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'seed': None, 'mode': 'fan_avg', 'scale': 1.0}}, 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'trainable': True, 'strides': (1,), 'bias_regularizer': None, 'name': 'conv1d_16', 'filters': 50, 'activation': 'relu', 'kernel_constraint': None, 'activity_regularizer': None, 'dilation_rate': (1,)}\n",
      "Input shape (None, 21, 100)\n",
      "Ouput shape (None, 19, 50)\n",
      "\n",
      "For layer 4 -----------------\n",
      "{'bias_constraint': None, 'kernel_size': (4,), 'padding': 'valid', 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'seed': None, 'mode': 'fan_avg', 'scale': 1.0}}, 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'trainable': True, 'strides': (1,), 'bias_regularizer': None, 'name': 'conv1d_17', 'filters': 50, 'activation': 'relu', 'kernel_constraint': None, 'activity_regularizer': None, 'dilation_rate': (1,)}\n",
      "Input shape (None, 21, 100)\n",
      "Ouput shape (None, 18, 50)\n",
      "\n",
      "For layer 5 -----------------\n",
      "{'bias_constraint': None, 'kernel_size': (5,), 'padding': 'valid', 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'seed': None, 'mode': 'fan_avg', 'scale': 1.0}}, 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'trainable': True, 'strides': (1,), 'bias_regularizer': None, 'name': 'conv1d_18', 'filters': 50, 'activation': 'relu', 'kernel_constraint': None, 'activity_regularizer': None, 'dilation_rate': (1,)}\n",
      "Input shape (None, 21, 100)\n",
      "Ouput shape (None, 17, 50)\n",
      "\n",
      "For layer 6 -----------------\n",
      "{'trainable': True, 'strides': (19,), 'pool_size': (19,), 'padding': 'valid', 'name': 'max_pooling1d_16'}\n",
      "Input shape (None, 19, 50)\n",
      "Ouput shape (None, 1, 50)\n",
      "\n",
      "For layer 7 -----------------\n",
      "{'trainable': True, 'strides': (18,), 'pool_size': (18,), 'padding': 'valid', 'name': 'max_pooling1d_17'}\n",
      "Input shape (None, 18, 50)\n",
      "Ouput shape (None, 1, 50)\n",
      "\n",
      "For layer 8 -----------------\n",
      "{'trainable': True, 'strides': (17,), 'pool_size': (17,), 'padding': 'valid', 'name': 'max_pooling1d_18'}\n",
      "Input shape (None, 17, 50)\n",
      "Ouput shape (None, 1, 50)\n",
      "\n",
      "For layer 9 -----------------\n",
      "{'trainable': True, 'name': 'flatten_11'}\n",
      "Input shape (None, 1, 50)\n",
      "Ouput shape (None, 50)\n",
      "\n",
      "For layer 10 -----------------\n",
      "{'trainable': True, 'name': 'flatten_12'}\n",
      "Input shape (None, 1, 50)\n",
      "Ouput shape (None, 50)\n",
      "\n",
      "For layer 11 -----------------\n",
      "{'trainable': True, 'name': 'flatten_13'}\n",
      "Input shape (None, 1, 50)\n",
      "Ouput shape (None, 50)\n",
      "\n",
      "For layer 12 -----------------\n",
      "{'trainable': True, 'axis': -1, 'name': 'concatenate_4'}\n",
      "Input shape [(None, 50), (None, 50), (None, 50)]\n",
      "Ouput shape (None, 150)\n",
      "\n",
      "For layer 13 -----------------\n",
      "{'trainable': True, 'rate': 0.8, 'name': 'dropout_13'}\n",
      "Input shape (None, 150)\n",
      "Ouput shape (None, 150)\n",
      "\n",
      "For layer 14 -----------------\n",
      "{'bias_constraint': None, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'seed': None, 'mode': 'fan_avg', 'scale': 1.0}}, 'units': 50, 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'trainable': True, 'bias_regularizer': None, 'name': 'dense_7', 'activation': 'relu', 'kernel_constraint': None, 'activity_regularizer': None}\n",
      "Input shape (None, 150)\n",
      "Ouput shape (None, 50)\n",
      "\n",
      "For layer 15 -----------------\n",
      "{'bias_constraint': None, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'distribution': 'uniform', 'seed': None, 'mode': 'fan_avg', 'scale': 1.0}}, 'units': 5, 'kernel_regularizer': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'trainable': True, 'bias_regularizer': None, 'name': 'dense_8', 'activation': 'softmax', 'kernel_constraint': None, 'activity_regularizer': None}\n",
      "Input shape (None, 50)\n",
      "Ouput shape (None, 5)\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for layer in model.layers:\n",
    "    print('\\nFor layer %d -----------------' % counter)\n",
    "    print(layer.get_config())\n",
    "    print('Input shape', layer.input_shape)\n",
    "    print('Ouput shape', layer.output_shape)\n",
    "#     print(layer.compute_output_shape())\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13801, 100)\n",
      "(3, 100, 50)\n",
      "(50,)\n",
      "(4, 100, 50)\n",
      "(50,)\n",
      "(5, 100, 50)\n",
      "(50,)\n",
      "(150, 50)\n",
      "(50,)\n",
      "(50, 5)\n",
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "# Final Res\n",
    "y_out = np.eye(5)\n",
    "for i in range(len(out[1])):\n",
    "    print(out[1][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2211"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I hate this movie'"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_docs_test[2210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 8,\n",
       " 10,\n",
       " 11,\n",
       " 14,\n",
       " 17,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 28,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 36,\n",
       " 37,\n",
       " 44,\n",
       " 50,\n",
       " 51,\n",
       " 56,\n",
       " 58,\n",
       " 61,\n",
       " 62,\n",
       " 64,\n",
       " 74,\n",
       " 75,\n",
       " 77,\n",
       " 78,\n",
       " 82,\n",
       " 83,\n",
       " 88,\n",
       " 89,\n",
       " 91,\n",
       " 100,\n",
       " 106,\n",
       " 109,\n",
       " 113,\n",
       " 118,\n",
       " 120,\n",
       " 128,\n",
       " 130,\n",
       " 133,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 145,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 152,\n",
       " 153,\n",
       " 160,\n",
       " 162,\n",
       " 163,\n",
       " 165,\n",
       " 169,\n",
       " 170,\n",
       " 175,\n",
       " 178,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 187,\n",
       " 191,\n",
       " 193,\n",
       " 198,\n",
       " 199,\n",
       " 201,\n",
       " 205,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 214,\n",
       " 217,\n",
       " 219,\n",
       " 222,\n",
       " 225,\n",
       " 227,\n",
       " 228,\n",
       " 231,\n",
       " 235,\n",
       " 245,\n",
       " 246,\n",
       " 249,\n",
       " 252,\n",
       " 255,\n",
       " 256,\n",
       " 260,\n",
       " 267,\n",
       " 275,\n",
       " 280,\n",
       " 285,\n",
       " 291,\n",
       " 296,\n",
       " 298,\n",
       " 307,\n",
       " 314,\n",
       " 316,\n",
       " 318,\n",
       " 320,\n",
       " 327,\n",
       " 331,\n",
       " 335,\n",
       " 337,\n",
       " 339,\n",
       " 346,\n",
       " 349,\n",
       " 350,\n",
       " 353,\n",
       " 358,\n",
       " 375,\n",
       " 382,\n",
       " 383,\n",
       " 391,\n",
       " 392,\n",
       " 397,\n",
       " 399,\n",
       " 406,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 418,\n",
       " 419,\n",
       " 424,\n",
       " 426,\n",
       " 428,\n",
       " 430,\n",
       " 439,\n",
       " 442,\n",
       " 444,\n",
       " 452,\n",
       " 457,\n",
       " 459,\n",
       " 463,\n",
       " 468,\n",
       " 473,\n",
       " 475,\n",
       " 477,\n",
       " 479,\n",
       " 481,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 489,\n",
       " 490,\n",
       " 501,\n",
       " 505,\n",
       " 507,\n",
       " 510,\n",
       " 512,\n",
       " 517,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 533,\n",
       " 535,\n",
       " 537,\n",
       " 546,\n",
       " 547,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 559,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 567,\n",
       " 574,\n",
       " 577,\n",
       " 583,\n",
       " 589,\n",
       " 597,\n",
       " 598,\n",
       " 601,\n",
       " 606,\n",
       " 607,\n",
       " 609,\n",
       " 614,\n",
       " 617,\n",
       " 620,\n",
       " 621,\n",
       " 624,\n",
       " 626,\n",
       " 628,\n",
       " 630,\n",
       " 631,\n",
       " 633,\n",
       " 640,\n",
       " 643,\n",
       " 648,\n",
       " 652,\n",
       " 653,\n",
       " 655,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 668,\n",
       " 673,\n",
       " 674,\n",
       " 681,\n",
       " 683,\n",
       " 685,\n",
       " 689,\n",
       " 691,\n",
       " 692,\n",
       " 694,\n",
       " 695,\n",
       " 697,\n",
       " 698,\n",
       " 701,\n",
       " 705,\n",
       " 707,\n",
       " 708,\n",
       " 711,\n",
       " 712,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 730,\n",
       " 733,\n",
       " 737,\n",
       " 742,\n",
       " 745,\n",
       " 746,\n",
       " 751,\n",
       " 759,\n",
       " 763,\n",
       " 767,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 773,\n",
       " 781,\n",
       " 784,\n",
       " 786,\n",
       " 791,\n",
       " 795,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 810,\n",
       " 814,\n",
       " 817,\n",
       " 821,\n",
       " 824,\n",
       " 826,\n",
       " 827,\n",
       " 828,\n",
       " 831,\n",
       " 832,\n",
       " 844,\n",
       " 845,\n",
       " 860,\n",
       " 862,\n",
       " 866,\n",
       " 869,\n",
       " 872,\n",
       " 876,\n",
       " 890,\n",
       " 892,\n",
       " 895,\n",
       " 912,\n",
       " 914,\n",
       " 915,\n",
       " 919,\n",
       " 930,\n",
       " 934,\n",
       " 935,\n",
       " 940,\n",
       " 944,\n",
       " 952,\n",
       " 956,\n",
       " 964,\n",
       " 965,\n",
       " 968,\n",
       " 973,\n",
       " 974,\n",
       " 975,\n",
       " 985,\n",
       " 988,\n",
       " 996,\n",
       " 999,\n",
       " 1002,\n",
       " 1008,\n",
       " 1013,\n",
       " 1020,\n",
       " 1023,\n",
       " 1025,\n",
       " 1032,\n",
       " 1042,\n",
       " 1045,\n",
       " 1046,\n",
       " 1048,\n",
       " 1051,\n",
       " 1053,\n",
       " 1055,\n",
       " 1059,\n",
       " 1063,\n",
       " 1064,\n",
       " 1066,\n",
       " 1068,\n",
       " 1069,\n",
       " 1077,\n",
       " 1079,\n",
       " 1083,\n",
       " 1084,\n",
       " 1085,\n",
       " 1091,\n",
       " 1096,\n",
       " 1097,\n",
       " 1098,\n",
       " 1101,\n",
       " 1102,\n",
       " 1114,\n",
       " 1115,\n",
       " 1116,\n",
       " 1119,\n",
       " 1120,\n",
       " 1128,\n",
       " 1134,\n",
       " 1136,\n",
       " 1141,\n",
       " 1143,\n",
       " 1150,\n",
       " 1152,\n",
       " 1153,\n",
       " 1163,\n",
       " 1166,\n",
       " 1172,\n",
       " 1173,\n",
       " 1180,\n",
       " 1185,\n",
       " 1186,\n",
       " 1188,\n",
       " 1189,\n",
       " 1191,\n",
       " 1195,\n",
       " 1196,\n",
       " 1197,\n",
       " 1198,\n",
       " 1199,\n",
       " 1203,\n",
       " 1211,\n",
       " 1212,\n",
       " 1215,\n",
       " 1216,\n",
       " 1221,\n",
       " 1223,\n",
       " 1227,\n",
       " 1228,\n",
       " 1236,\n",
       " 1242,\n",
       " 1244,\n",
       " 1245,\n",
       " 1247,\n",
       " 1249,\n",
       " 1253,\n",
       " 1254,\n",
       " 1255,\n",
       " 1261,\n",
       " 1262,\n",
       " 1266,\n",
       " 1267,\n",
       " 1271,\n",
       " 1272,\n",
       " 1278,\n",
       " 1279,\n",
       " 1284,\n",
       " 1285,\n",
       " 1296,\n",
       " 1304,\n",
       " 1305,\n",
       " 1310,\n",
       " 1311,\n",
       " 1312,\n",
       " 1313,\n",
       " 1316,\n",
       " 1322,\n",
       " 1329,\n",
       " 1337,\n",
       " 1338,\n",
       " 1342,\n",
       " 1346,\n",
       " 1348,\n",
       " 1351,\n",
       " 1353,\n",
       " 1354,\n",
       " 1361,\n",
       " 1365,\n",
       " 1366,\n",
       " 1367,\n",
       " 1369,\n",
       " 1370,\n",
       " 1372,\n",
       " 1375,\n",
       " 1376,\n",
       " 1378,\n",
       " 1380,\n",
       " 1381,\n",
       " 1386,\n",
       " 1390,\n",
       " 1392,\n",
       " 1395,\n",
       " 1403,\n",
       " 1406,\n",
       " 1408,\n",
       " 1412,\n",
       " 1422,\n",
       " 1428,\n",
       " 1429,\n",
       " 1430,\n",
       " 1436,\n",
       " 1437,\n",
       " 1441,\n",
       " 1444,\n",
       " 1445,\n",
       " 1446,\n",
       " 1447,\n",
       " 1448,\n",
       " 1451,\n",
       " 1456,\n",
       " 1457,\n",
       " 1459,\n",
       " 1461,\n",
       " 1476,\n",
       " 1483,\n",
       " 1484,\n",
       " 1491,\n",
       " 1494,\n",
       " 1495,\n",
       " 1496,\n",
       " 1505,\n",
       " 1508,\n",
       " 1510,\n",
       " 1514,\n",
       " 1515,\n",
       " 1520,\n",
       " 1521,\n",
       " 1528,\n",
       " 1530,\n",
       " 1531,\n",
       " 1532,\n",
       " 1534,\n",
       " 1535,\n",
       " 1536,\n",
       " 1537,\n",
       " 1541,\n",
       " 1544,\n",
       " 1548,\n",
       " 1551,\n",
       " 1554,\n",
       " 1556,\n",
       " 1557,\n",
       " 1558,\n",
       " 1559,\n",
       " 1562,\n",
       " 1564,\n",
       " 1568,\n",
       " 1570,\n",
       " 1571,\n",
       " 1573,\n",
       " 1575,\n",
       " 1576,\n",
       " 1580,\n",
       " 1581,\n",
       " 1582,\n",
       " 1584,\n",
       " 1585,\n",
       " 1586,\n",
       " 1591,\n",
       " 1595,\n",
       " 1596,\n",
       " 1598,\n",
       " 1599,\n",
       " 1605,\n",
       " 1614,\n",
       " 1616,\n",
       " 1623,\n",
       " 1630,\n",
       " 1633,\n",
       " 1638,\n",
       " 1644,\n",
       " 1645,\n",
       " 1646,\n",
       " 1649,\n",
       " 1661,\n",
       " 1662,\n",
       " 1663,\n",
       " 1664,\n",
       " 1665,\n",
       " 1672,\n",
       " 1676,\n",
       " 1683,\n",
       " 1685,\n",
       " 1690,\n",
       " 1691,\n",
       " 1694,\n",
       " 1701,\n",
       " 1703,\n",
       " 1711,\n",
       " 1713,\n",
       " 1714,\n",
       " 1715,\n",
       " 1719,\n",
       " 1722,\n",
       " 1727,\n",
       " 1728,\n",
       " 1730,\n",
       " 1733,\n",
       " 1734,\n",
       " 1736,\n",
       " 1738,\n",
       " 1739,\n",
       " 1740,\n",
       " 1742,\n",
       " 1745,\n",
       " 1749,\n",
       " 1752,\n",
       " 1758,\n",
       " 1760,\n",
       " 1763,\n",
       " 1766,\n",
       " 1768,\n",
       " 1769,\n",
       " 1770,\n",
       " 1774,\n",
       " 1775,\n",
       " 1776,\n",
       " 1778,\n",
       " 1779,\n",
       " 1786,\n",
       " 1801,\n",
       " 1802,\n",
       " 1803,\n",
       " 1805,\n",
       " 1806,\n",
       " 1807,\n",
       " 1823,\n",
       " 1824,\n",
       " 1827,\n",
       " 1828,\n",
       " 1832,\n",
       " 1833,\n",
       " 1834,\n",
       " 1836,\n",
       " 1838,\n",
       " 1840,\n",
       " 1844,\n",
       " 1846,\n",
       " 1848,\n",
       " 1850,\n",
       " 1860,\n",
       " 1862,\n",
       " 1867,\n",
       " 1876,\n",
       " 1881,\n",
       " 1883,\n",
       " 1888,\n",
       " 1889,\n",
       " 1893,\n",
       " 1894,\n",
       " 1898,\n",
       " 1899,\n",
       " 1905,\n",
       " 1907,\n",
       " 1912,\n",
       " 1919,\n",
       " 1920,\n",
       " 1921,\n",
       " 1935,\n",
       " 1936,\n",
       " 1938,\n",
       " 1940,\n",
       " 1946,\n",
       " 1948,\n",
       " 1949,\n",
       " 1950,\n",
       " 1954,\n",
       " 1957,\n",
       " 1971,\n",
       " 1972,\n",
       " 1974,\n",
       " 1975,\n",
       " 1976,\n",
       " 1977,\n",
       " 1978,\n",
       " 1981,\n",
       " 1983,\n",
       " 1985,\n",
       " 1986,\n",
       " 1987,\n",
       " 1988,\n",
       " 1989,\n",
       " 1992,\n",
       " 1994,\n",
       " 1999,\n",
       " 2001,\n",
       " 2002,\n",
       " 2003,\n",
       " 2006,\n",
       " 2009,\n",
       " 2013,\n",
       " 2015,\n",
       " 2017,\n",
       " 2021,\n",
       " 2023,\n",
       " 2027,\n",
       " 2036,\n",
       " 2038,\n",
       " 2041,\n",
       " 2043,\n",
       " 2044,\n",
       " 2048,\n",
       " 2049,\n",
       " 2055,\n",
       " 2056,\n",
       " 2058,\n",
       " 2059,\n",
       " 2064,\n",
       " 2065,\n",
       " 2066,\n",
       " 2067,\n",
       " 2073,\n",
       " 2074,\n",
       " 2076,\n",
       " 2077,\n",
       " 2079,\n",
       " 2080,\n",
       " 2083,\n",
       " 2085,\n",
       " 2087,\n",
       " 2091,\n",
       " 2098,\n",
       " 2114,\n",
       " 2119,\n",
       " 2122,\n",
       " 2124,\n",
       " 2131,\n",
       " 2133,\n",
       " 2135,\n",
       " 2136,\n",
       " 2142,\n",
       " 2147,\n",
       " 2148,\n",
       " 2149,\n",
       " 2150,\n",
       " 2158,\n",
       " 2159,\n",
       " 2160,\n",
       " 2165,\n",
       " 2167,\n",
       " 2169,\n",
       " 2172,\n",
       " 2174,\n",
       " 2175,\n",
       " 2178,\n",
       " 2181,\n",
       " 2183,\n",
       " 2184,\n",
       " 2186,\n",
       " 2191,\n",
       " 2193,\n",
       " 2195,\n",
       " 2197,\n",
       " 2200,\n",
       " 2203,\n",
       " 2204,\n",
       " 2205,\n",
       " 2210]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.,  0.])"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_wt = out[1][0]\n",
    "# 0 456 134 CNN rand\n",
    "k = 0\n",
    "list_ind = word_id_test[ind[k]]\n",
    "x_input = embed_wt[list_ind, :]\n",
    "y_final = y_out[:,y_actual[ind[k]]]\n",
    "y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n",
      "(3, 100, 50) (4, 100, 50) (5, 100, 50)\n",
      "(50,) (50,) (50,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = out[1][9]\n",
    "y1 = w1 @ y_final\n",
    "y1 = y1 * (y1 > 0)\n",
    "\n",
    "w2 = out[1][7]\n",
    "y2 = w2 @ y1\n",
    "y2 = y2 * (y2 > 0) # Guided backward pass: backprop\n",
    "print(y2.shape)\n",
    "\n",
    "z1 = y2[0:50,]\n",
    "z2 = y2[50:100,]\n",
    "z3 = y2[100:150,]\n",
    "\n",
    "W1 = out[1][1]\n",
    "W2 = out[1][3]\n",
    "W3 = out[1][5]\n",
    "print(W1.shape, W2.shape, W3.shape)\n",
    "\n",
    "x_viz = x_input\n",
    "\n",
    "\n",
    "o1 = np.empty((50, ), np.float32)\n",
    "\n",
    "i1 = np.empty((50, ), np.int32)\n",
    "for i in range(50):\n",
    "    output = convolve2d(x_viz, W1[:,:,i], mode='valid')\n",
    "    output = output * (output > 0) \n",
    "    o1[i] = np.max(output, axis = 0)\n",
    "    i1[i] = np.argmax(output, axis = 0)\n",
    "    \n",
    "o2 = np.empty((50, ), np.float32)\n",
    "i2 = np.empty((50, ), np.int32)\n",
    "for i in range(50):\n",
    "    output = convolve2d(x_viz, W2[:,:,i], mode='valid')\n",
    "    output = output * (output > 0) \n",
    "    o2[i] = np.max(output, axis=0)\n",
    "    i2[i] = np.argmax(output, axis=0)\n",
    "    \n",
    "o3 = np.empty((50, ), np.float32)\n",
    "i3 = np.empty((50, ), np.int32)\n",
    "for i in range(50):\n",
    "    output = convolve2d(x_viz, W3[:,:,i], mode='valid')\n",
    "    output = output * (output > 0) \n",
    "    o3[i] = np.max(output, axis=0)\n",
    "    i3[i] = np.argmax(output, axis=0)\n",
    "    \n",
    "print(o1.shape, o2.shape, o3.shape)\n",
    "\n",
    "# Backward pass guided backpropogation (backprop)\n",
    "t1 = o1 * z1\n",
    "t2 = o2 * z2\n",
    "t3 = o3 * z3\n",
    "\n",
    "# Backward pass guided backpropogation\n",
    "# t1 = z1\n",
    "# t2 = z2\n",
    "# t3 = z3\n",
    "\n",
    "# t1 = o1 \n",
    "# t2 = o2 \n",
    "# t3 = o3 \n",
    "\n",
    "tsum = np.sum(t1) + np.sum(t2) + np.sum(t3)\n",
    "\n",
    "c = np.zeros((21,), np.float32)\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    for j in range(3):\n",
    "        c[i1[i] + j] += 1/3*t1[i]/tsum\n",
    "        \n",
    "for i in range(50):\n",
    "    for j in range(4):\n",
    "        c[i2[i] + j] += 1/4*t2[i]/tsum\n",
    "\n",
    "for i in range(50):\n",
    "    for j in range(5):\n",
    "        c[i3[i] + j] += 1/5*t3[i]/tsum\n",
    "        \n",
    "c\n",
    "np.sum(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If you sometimes like to go to the movies to have fun , Wasabi is a good place to start .'"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_docs_test[ind[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wasabi', 0.23152487),\n",
       " ('good', 0.2180485),\n",
       " ('fun', 0.17998767),\n",
       " ('movi', 0.15142322),\n",
       " ('place', 0.12892881),\n",
       " ('go', 0.056666099),\n",
       " ('start', 0.020311475),\n",
       " ('like', 0.0084058866),\n",
       " ('sometim', 0.0033888198),\n",
       " ('if', 0.001314683)]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrds = []\n",
    "sent = processed_docs_test[ind[k]]\n",
    "wrd_prob = dict()\n",
    "\n",
    "counter = 0\n",
    "for i in sent:\n",
    "    wrd_prob[i] = c[counter]\n",
    "    counter += 1\n",
    "    \n",
    "import operator\n",
    "# srt_list = sorted(wrd_prob.items())\n",
    "sorted_x = sorted(wrd_prob.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00131468,  0.00338882,  0.00840589,  0.0566661 ,  0.15142322,\n",
       "        0.17998767,  0.23152487,  0.2180485 ,  0.12892881,  0.02031147,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
