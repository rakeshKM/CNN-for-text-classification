batch_size   = 50
filter_sizes = [3,4,5]
num_filters  = 100
dropout_prob = (0.5, 0.8)
hidden_dims  = 50

l2_reg = 0.3
embedding_dim = 300

# Deciding dimension of input based on the model
input_shape = (max_sent_len, embedding_dim) if model_type == "CNN-static" else (max_sent_len,)
model_input = Input(shape = input_shape)

# Static model do not have embedding layer
if model_type == "CNN-static":
    z = Dropout(dropout_prob[0])(model_input)
else:
    z = Embedding(vocab_size, embedding_dim, input_length = max_sent_len, name="embedding")(model_input)
    z = Dropout(dropout_prob[0])(z)

# Convolution layers
z1 = Conv1D(    filters=100, kernel_size=3, 
                padding="valid", activation="relu", 
                strides=1)(z)
z1 = MaxPooling1D(pool_size=2)(z1)
z1 = Flatten()(z1)

z2 = Conv1D(    filters=100, kernel_size=4, 
                padding="valid", activation="relu", 
                strides=1)(z)
z2 = MaxPooling1D(pool_size=2)(z2)
z2 = Flatten()(z2)

z3 = Conv1D(    filters=100, kernel_size=5, 
                padding="valid", activation="relu",
                strides=1)(z)
z3 = MaxPooling1D(pool_size=2)(z3)
z3 = Flatten()(z3)

# Concatenate the output of all convolution layers
z = Concatenate()([z1, z2, z3])
z = Dropout(dropout_prob[1])(z)

# Dense(64, input_dim=64, kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.01))

z = Dense(hidden_dims, activation="relu", kernel_regularizer=regularizers.l2(0.01))(z)
model_output = Dense(N_category, activation="sigmoid")(z)
    
model = Model(model_input, model_output)
model.compile(loss="categorical_crossentropy", optimizer=optimizers.Adadelta(lr=1), metrics=["accuracy"])
model.summary()


Training Accuracy 92.4157303371
Validation Accuracy 35.7856494096
Testing Accuracy 40.0

Train on 8544 samples, validate on 1101 samples
Epoch 1/100
37s - loss: 1.8536 - acc: 0.2691 - val_loss: 1.6258 - val_acc: 0.2552
Epoch 2/100
28s - loss: 1.5983 - acc: 0.2701 - val_loss: 1.5924 - val_acc: 0.2698
Epoch 3/100
28s - loss: 1.5839 - acc: 0.2753 - val_loss: 1.5862 - val_acc: 0.2761
Epoch 4/100
28s - loss: 1.5783 - acc: 0.2719 - val_loss: 1.5848 - val_acc: 0.2525
Epoch 5/100
28s - loss: 1.5696 - acc: 0.2899 - val_loss: 1.5803 - val_acc: 0.3015
Epoch 6/100
28s - loss: 1.5602 - acc: 0.2945 - val_loss: 1.5766 - val_acc: 0.2870
Epoch 7/100
28s - loss: 1.5521 - acc: 0.3062 - val_loss: 1.5720 - val_acc: 0.3188
Epoch 8/100
28s - loss: 1.5424 - acc: 0.3157 - val_loss: 1.5695 - val_acc: 0.3088
Epoch 9/100
28s - loss: 1.5354 - acc: 0.3261 - val_loss: 1.5652 - val_acc: 0.3206
Epoch 10/100
28s - loss: 1.5163 - acc: 0.3420 - val_loss: 1.5634 - val_acc: 0.3188
Epoch 11/100
28s - loss: 1.4981 - acc: 0.3625 - val_loss: 1.5760 - val_acc: 0.3106
Epoch 12/100
28s - loss: 1.4845 - acc: 0.3731 - val_loss: 1.5623 - val_acc: 0.3224
Epoch 13/100
28s - loss: 1.4681 - acc: 0.3851 - val_loss: 1.5554 - val_acc: 0.3297
Epoch 14/100
28s - loss: 1.4524 - acc: 0.3983 - val_loss: 1.5474 - val_acc: 0.3415
Epoch 15/100
28s - loss: 1.4279 - acc: 0.4129 - val_loss: 1.5460 - val_acc: 0.3479
Epoch 16/100
28s - loss: 1.4088 - acc: 0.4336 - val_loss: 1.5437 - val_acc: 0.3424
Epoch 17/100
27s - loss: 1.3972 - acc: 0.4356 - val_loss: 1.5377 - val_acc: 0.3470
Epoch 18/100
28s - loss: 1.3816 - acc: 0.4404 - val_loss: 1.5409 - val_acc: 0.3470
Epoch 19/100
27s - loss: 1.3606 - acc: 0.4545 - val_loss: 1.5390 - val_acc: 0.3470
Epoch 20/100
28s - loss: 1.3475 - acc: 0.4602 - val_loss: 1.5409 - val_acc: 0.3515
Epoch 21/100
28s - loss: 1.3271 - acc: 0.4773 - val_loss: 1.5459 - val_acc: 0.3497
Epoch 22/100
27s - loss: 1.3102 - acc: 0.4875 - val_loss: 1.5433 - val_acc: 0.3651
Epoch 23/100
29s - loss: 1.2985 - acc: 0.4896 - val_loss: 1.5382 - val_acc: 0.3579
Epoch 24/100
27s - loss: 1.2787 - acc: 0.5050 - val_loss: 1.5458 - val_acc: 0.3433
Epoch 25/100
28s - loss: 1.2634 - acc: 0.5157 - val_loss: 1.5390 - val_acc: 0.3715
Epoch 26/100
27s - loss: 1.2452 - acc: 0.5211 - val_loss: 1.5512 - val_acc: 0.3706
Epoch 27/100
28s - loss: 1.2273 - acc: 0.5316 - val_loss: 1.5484 - val_acc: 0.3660
Epoch 28/100
27s - loss: 1.2262 - acc: 0.5390 - val_loss: 1.5536 - val_acc: 0.3633
Epoch 29/100
28s - loss: 1.1980 - acc: 0.5536 - val_loss: 1.5496 - val_acc: 0.3651
Epoch 30/100
27s - loss: 1.1855 - acc: 0.5495 - val_loss: 1.5571 - val_acc: 0.3542
Epoch 31/100
28s - loss: 1.1771 - acc: 0.5664 - val_loss: 1.5541 - val_acc: 0.3560
Epoch 32/100
27s - loss: 1.1582 - acc: 0.5715 - val_loss: 1.5633 - val_acc: 0.3660
Epoch 33/100
28s - loss: 1.1407 - acc: 0.5823 - val_loss: 1.5714 - val_acc: 0.3642
Epoch 34/100
27s - loss: 1.1348 - acc: 0.5789 - val_loss: 1.5719 - val_acc: 0.3579
Epoch 35/100
27s - loss: 1.1289 - acc: 0.5812 - val_loss: 1.5736 - val_acc: 0.3579
Epoch 36/100
28s - loss: 1.1100 - acc: 0.5947 - val_loss: 1.5610 - val_acc: 0.3669
Epoch 37/100
29s - loss: 1.1017 - acc: 0.5954 - val_loss: 1.5730 - val_acc: 0.3597
Epoch 38/100
28s - loss: 1.0761 - acc: 0.6072 - val_loss: 1.5732 - val_acc: 0.3506
Epoch 39/100
27s - loss: 1.0671 - acc: 0.6128 - val_loss: 1.5796 - val_acc: 0.3551
Epoch 40/100
28s - loss: 1.0625 - acc: 0.6125 - val_loss: 1.5863 - val_acc: 0.3569
Epoch 41/100
27s - loss: 1.0502 - acc: 0.6177 - val_loss: 1.5834 - val_acc: 0.3615
Epoch 42/100
29s - loss: 1.0260 - acc: 0.6369 - val_loss: 1.5893 - val_acc: 0.3551
Epoch 43/100
29s - loss: 1.0200 - acc: 0.6401 - val_loss: 1.5948 - val_acc: 0.3651
Epoch 44/100
30s - loss: 1.0015 - acc: 0.6419 - val_loss: 1.6115 - val_acc: 0.3624
Epoch 45/100
29s - loss: 0.9955 - acc: 0.6469 - val_loss: 1.5977 - val_acc: 0.3706
Epoch 46/100
29s - loss: 0.9894 - acc: 0.6500 - val_loss: 1.6032 - val_acc: 0.3597
Epoch 47/100
27s - loss: 0.9589 - acc: 0.6651 - val_loss: 1.6142 - val_acc: 0.3479
Epoch 48/100
28s - loss: 0.9646 - acc: 0.6641 - val_loss: 1.6069 - val_acc: 0.3606
Epoch 49/100
29s - loss: 0.9545 - acc: 0.6708 - val_loss: 1.6055 - val_acc: 0.3660
Epoch 50/100
28s - loss: 0.9336 - acc: 0.6737 - val_loss: 1.6096 - val_acc: 0.3551
Epoch 51/100
27s - loss: 0.9204 - acc: 0.6821 - val_loss: 1.6214 - val_acc: 0.3579
Epoch 52/100
28s - loss: 0.9149 - acc: 0.6813 - val_loss: 1.6192 - val_acc: 0.3569
Epoch 53/100
27s - loss: 0.9086 - acc: 0.6918 - val_loss: 1.6214 - val_acc: 0.3579
Epoch 54/100
28s - loss: 0.9068 - acc: 0.6808 - val_loss: 1.6356 - val_acc: 0.3579
Epoch 55/100
28s - loss: 0.8846 - acc: 0.6977 - val_loss: 1.6314 - val_acc: 0.3579
Epoch 56/100