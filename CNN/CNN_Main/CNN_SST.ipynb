{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Embedding, regularizers\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from w2v import train_word2vec \n",
    "import pickle, datetime\n",
    "import numpy as np\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ------------------------------- Data Preprocessing -----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Phrase -> index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239232 14058\n"
     ]
    }
   ],
   "source": [
    "phr_to_ind = dict()\n",
    "\n",
    "with open('../../Datasets/SST1_dataset/dictionary.txt') as f:\n",
    "    for line in f:\n",
    "        entry = line.split('|')\n",
    "        phr_to_ind[entry[0]] = int(entry[1])\n",
    "\n",
    "keys = phr_to_ind.keys();\n",
    "\n",
    "print(len(phr_to_ind), phr_to_ind['Good'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Getting Index corresponding to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11855\n"
     ]
    }
   ],
   "source": [
    "# Without doing the below computation directly load the stored output\n",
    "sentence_list = []\n",
    "sentiment = []\n",
    "\n",
    "with open('../../Datasets/SST1_dataset/SentenceWithCorrection.txt') as f:\n",
    "    for line in f:\n",
    "        sent = line[:-1]\n",
    "        sentence_list.append(sent)\n",
    "        sentiment.append(phr_to_ind[sent])\n",
    "\n",
    "print(len(sentence_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# sentence_list = []\n",
    "# sentiment = []\n",
    "\n",
    "# with open('../../Datasets/SST1_dataset/datasetSentences.txt') as f:\n",
    "#     f.readline()\n",
    "#     for line in f:\n",
    "#         entry = line.split('\\t')\n",
    "#         sent = entry[1][:-1]\n",
    "#         sent = sent.replace('-LRB-', '(')\n",
    "#         sent = sent.replace('-RRB-', ')')\n",
    "    \n",
    "#         if sent in phr_to_ind.keys():\n",
    "#             sentiment.append(phr_to_ind[sent])\n",
    "#         else:\n",
    "#             print('.', end=\"\")\n",
    "#             keys_subset = [k for k in keys if (k[0] == sent[0])]\n",
    "#             key = difflib.get_close_matches(sent, keys_subset, n=1);\n",
    "#             sent = key[0]\n",
    "#             sentiment.append(phr_to_ind[sent])\n",
    "            \n",
    "#         sentence_list.append(sent)\n",
    "        \n",
    "# print(len(sentence_list))\n",
    "\n",
    "# # Written the output in a file\n",
    "# f = open('../../Datasets/SST1_dataset/SentenceWithCorrection.txt', 'w')\n",
    "# for sent in sentence_list:\n",
    "#     f.write(sent + '\\n')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Phrase Index -> Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239232\n"
     ]
    }
   ],
   "source": [
    "ind_to_senti = dict()\n",
    "\n",
    "with open('../../Datasets/SST1_dataset/sentiment_labels.txt') as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        entry = line.split('|')\n",
    "        ind_to_senti[int(entry[0])] = float(entry[1])\n",
    "\n",
    "print(len(ind_to_senti))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading train, test and valid split info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11855\n",
      "9645 2210 0\n"
     ]
    }
   ],
   "source": [
    "split_ind = []\n",
    "with open('../../Datasets/SST1_dataset/datasetSplit.txt') as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        entry = line.split(',')\n",
    "        split_ind.append(int(entry[1]))\n",
    "\n",
    "print(len(split_ind))\n",
    "\n",
    "for i in range(len(split_ind)):\n",
    "    if split_ind[i] == 3:\n",
    "        split_ind[i] = 1\n",
    "        \n",
    "N_train = split_ind.count(1)\n",
    "N_test = split_ind.count(2)\n",
    "N_valid = split_ind.count(3)\n",
    "print (N_train, N_test, N_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Assigning label to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510 3140 2242 3111\n"
     ]
    }
   ],
   "source": [
    "N_sent = len(sentence_list);\n",
    "N_category = 5\n",
    "\n",
    "y_label = []\n",
    "\n",
    "for ind in sentiment:\n",
    "    val = ind_to_senti[ind]\n",
    "    if val >= 0.0 and val <= 0.2:\n",
    "        y_label.append(0);\n",
    "    elif val > 0.2 and val <= 0.4:\n",
    "        y_label.append(1)\n",
    "    elif val > 0.4 and val <= 0.6:\n",
    "        y_label.append(2)\n",
    "    elif val > 0.6 and val <= 0.8:\n",
    "        y_label.append(3)\n",
    "    else:\n",
    "        y_label.append(4)\n",
    "\n",
    "print(y_label.count(0), y_label.count(1), y_label.count(2), y_label.count(3))\n",
    "\n",
    "# Labels in one-hot encoding\n",
    "y_train = np.zeros((N_train, N_category), np.uint8)\n",
    "y_test  = np.zeros((N_test , N_category), np.uint8)\n",
    "y_valid = np.zeros((N_valid, N_category), np.uint8)\n",
    "\n",
    "c1,c2,c3 = 0,0,0\n",
    "for i in range(len(y_label)):\n",
    "    label = y_label[i]\n",
    "    if split_ind[i] == 1:\n",
    "        y_train[c1, label] = 1;  c1 += 1\n",
    "    elif split_ind[i] == 2:\n",
    "        y_test [c2, label] = 1;  c2 += 1\n",
    "    else:\n",
    "        y_valid[c3, label] = 1;  c3 += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Reducing the size of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239232 21699\n"
     ]
    }
   ],
   "source": [
    "x_all = []\n",
    "max_sent_len = -1;\n",
    "max_wrd_len = -1\n",
    "wrd_to_ind = dict()\n",
    "\n",
    "ind_new = 1;\n",
    "for sent in sentence_list:\n",
    "    wrds = sent.split()\n",
    "    vec = []\n",
    "    for wrd in wrds:\n",
    "        if wrd not in wrd_to_ind.keys():\n",
    "            wrd_to_ind[wrd] = ind_new\n",
    "            ind_new += 1\n",
    "            \n",
    "        ind = wrd_to_ind[wrd]\n",
    "        vec.append(ind)\n",
    "            \n",
    "    max_sent_len = max(len(vec), max_sent_len)\n",
    "    x_all.append(vec)\n",
    "\n",
    "# Get inverse dictionary\n",
    "ind_to_wrd = dict((v, k) for k, v in wrd_to_ind.items())\n",
    "ind_to_wrd[0] = \"<PAD/>\"\n",
    "\n",
    "print(len(phr_to_ind), len(wrd_to_ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9645 2210 0\n"
     ]
    }
   ],
   "source": [
    "x_train = np.zeros((N_train, max_sent_len), np.int32)\n",
    "x_test  = np.zeros((N_test,  max_sent_len), np.int32)\n",
    "x_valid = np.zeros((N_valid, max_sent_len), np.int32)\n",
    "\n",
    "c1, c2, c3 = 0,0,0\n",
    "for i in range(len(x_all)):\n",
    "    vec = x_all[i]\n",
    "    if split_ind[i] == 1:\n",
    "        x_train[c1,0:len(vec)] = np.int32(vec); \n",
    "        c1 += 1\n",
    "    elif split_ind[i] == 2:\n",
    "        x_test [c2,0:len(vec)] = np.int32(vec); \n",
    "        c2 += 1\n",
    "    else:\n",
    "        x_valid[c3,0:len(vec)] = np.int32(vec); \n",
    "        c3 += 1\n",
    "\n",
    "print(c1, c2, c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -------------------------------- Training model  -----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Paremeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_type    = 'CNN-static'  # CNN-rand|CNN-non-static|CNN-static\n",
    "embedding_dim = 300         # word2vec dim\n",
    "vocab_size    = len(ind_to_wrd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Generate word2vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load existing Word2Vec model '300features_1minwords_10context'\n"
     ]
    }
   ],
   "source": [
    "if model_type in ['CNN-non-static', 'CNN-static']:\n",
    "    embedding_wts = train_word2vec( np.vstack((x_train, x_test, x_valid)), \n",
    "                                    ind_to_wrd, num_features = embedding_dim)\n",
    "    if model_type == 'CNN-static':\n",
    "        x_train = embedding_wts[0][x_train]\n",
    "        x_test  = embedding_wts[0][x_test]\n",
    "#         x_valid = embedding_wts[0][x_valid]\n",
    "        \n",
    "elif model_type == 'CNN-rand':\n",
    "    embedding_wts = None\n",
    "    \n",
    "else:\n",
    "    raise ValueError(\"Unknown model type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 56, 300)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 56, 300)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)                (None, 54, 100)       90100                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)                (None, 53, 100)       120100                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)                (None, 52, 100)       150100                                       \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)   (None, 1, 100)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)   (None, 1, 100)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)   (None, 1, 100)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           30100                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 5)             505                                          \n",
      "====================================================================================================\n",
      "Total params: 390,905.0\n",
      "Trainable params: 390,905.0\n",
      "Non-trainable params: 0.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size   = 50\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters  = 100\n",
    "dropout_prob = (0.5, 0.8)\n",
    "hidden_dims  = 100\n",
    "\n",
    "l2_reg = 0.3\n",
    "\n",
    "# Deciding dimension of input based on the model\n",
    "input_shape = (max_sent_len, embedding_dim) if model_type == \"CNN-static\" else (max_sent_len,)\n",
    "model_input = Input(shape = input_shape)\n",
    "\n",
    "# Static model do not have embedding layer\n",
    "if model_type == \"CNN-static\":\n",
    "    z = Dropout(dropout_prob[0])(model_input)\n",
    "else:\n",
    "    z = Embedding(vocab_size, embedding_dim, input_length = max_sent_len, name=\"embedding\", trainable=True)(model_input)\n",
    "    z = Dropout(dropout_prob[0])(z)\n",
    "\n",
    "# Convolution layers\n",
    "z1 = Conv1D(    filters=num_filters, kernel_size=filter_sizes[0], \n",
    "                padding=\"valid\", activation=\"relu\", \n",
    "                strides=1)(z)\n",
    "z1 = MaxPooling1D(pool_size = max_sent_len - filter_sizes[0] +1)(z1)\n",
    "z1 = Flatten()(z1)\n",
    "\n",
    "z2 = Conv1D(    filters=num_filters, kernel_size=filter_sizes[1], \n",
    "                padding=\"valid\", activation=\"relu\", \n",
    "                strides=1)(z)\n",
    "z2 = MaxPooling1D(pool_size=max_sent_len - filter_sizes[1] +1)(z2)\n",
    "z2 = Flatten()(z2)\n",
    "\n",
    "z3 = Conv1D(    filters=num_filters, kernel_size=filter_sizes[2], \n",
    "                padding=\"valid\", activation=\"relu\",\n",
    "                strides=1)(z)\n",
    "z3 = MaxPooling1D(pool_size=max_sent_len - filter_sizes[2] +1)(z3)\n",
    "z3 = Flatten()(z3)\n",
    "\n",
    "# Concatenate the output of all convolution layers\n",
    "z = Concatenate()([z1, z2, z3])\n",
    "z = Dropout(dropout_prob[1])(z)\n",
    "\n",
    "z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "model_output = Dense(N_category, activation=\"softmax\")(z)\n",
    "    \n",
    "model = Model(model_input, model_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9645 samples, validate on 2210 samples\n",
      "Epoch 1/3000\n",
      "13s - loss: 1.5956 - acc: 0.2583 - val_loss: 1.5883 - val_acc: 0.2520\n",
      "Epoch 2/3000\n",
      "8s - loss: 1.5726 - acc: 0.2734 - val_loss: 1.5761 - val_acc: 0.2760\n",
      "Epoch 3/3000\n",
      "9s - loss: 1.5637 - acc: 0.2836 - val_loss: 1.5665 - val_acc: 0.3063\n",
      "Epoch 4/3000\n",
      "8s - loss: 1.5573 - acc: 0.2823 - val_loss: 1.5574 - val_acc: 0.3041\n",
      "Epoch 5/3000\n",
      "8s - loss: 1.5501 - acc: 0.2943 - val_loss: 1.5456 - val_acc: 0.3086\n",
      "Epoch 6/3000\n",
      "8s - loss: 1.5418 - acc: 0.3006 - val_loss: 1.5392 - val_acc: 0.3136\n",
      "Epoch 7/3000\n",
      "8s - loss: 1.5417 - acc: 0.3031 - val_loss: 1.5347 - val_acc: 0.3262\n",
      "Epoch 8/3000\n",
      "8s - loss: 1.5299 - acc: 0.3099 - val_loss: 1.5265 - val_acc: 0.3190\n",
      "Epoch 9/3000\n",
      "8s - loss: 1.5303 - acc: 0.3082 - val_loss: 1.5316 - val_acc: 0.3090\n",
      "Epoch 10/3000\n",
      "8s - loss: 1.5222 - acc: 0.3125 - val_loss: 1.5211 - val_acc: 0.3190\n",
      "Epoch 11/3000\n",
      "8s - loss: 1.5187 - acc: 0.3191 - val_loss: 1.5133 - val_acc: 0.3285\n",
      "Epoch 12/3000\n",
      "8s - loss: 1.5103 - acc: 0.3273 - val_loss: 1.5106 - val_acc: 0.3190\n",
      "Epoch 13/3000\n",
      "8s - loss: 1.5070 - acc: 0.3256 - val_loss: 1.5091 - val_acc: 0.3181\n",
      "Epoch 14/3000\n",
      "8s - loss: 1.4993 - acc: 0.3336 - val_loss: 1.5007 - val_acc: 0.3231\n",
      "Epoch 15/3000\n",
      "8s - loss: 1.4975 - acc: 0.3357 - val_loss: 1.4976 - val_acc: 0.3416\n",
      "Epoch 16/3000\n",
      "8s - loss: 1.4922 - acc: 0.3327 - val_loss: 1.4969 - val_acc: 0.3285\n",
      "Epoch 17/3000\n",
      "8s - loss: 1.4866 - acc: 0.3418 - val_loss: 1.4900 - val_acc: 0.3425\n",
      "Epoch 18/3000\n",
      "8s - loss: 1.4828 - acc: 0.3442 - val_loss: 1.4901 - val_acc: 0.3489\n",
      "Epoch 19/3000\n",
      "8s - loss: 1.4823 - acc: 0.3449 - val_loss: 1.4851 - val_acc: 0.3516\n",
      "Epoch 20/3000\n",
      "8s - loss: 1.4816 - acc: 0.3438 - val_loss: 1.4905 - val_acc: 0.3299\n",
      "Epoch 21/3000\n",
      "8s - loss: 1.4778 - acc: 0.3418 - val_loss: 1.4893 - val_acc: 0.3439\n",
      "Epoch 22/3000\n",
      "8s - loss: 1.4669 - acc: 0.3548 - val_loss: 1.4820 - val_acc: 0.3353\n",
      "Epoch 23/3000\n",
      "8s - loss: 1.4685 - acc: 0.3532 - val_loss: 1.4770 - val_acc: 0.3466\n",
      "Epoch 24/3000\n",
      "8s - loss: 1.4640 - acc: 0.3588 - val_loss: 1.4810 - val_acc: 0.3376\n",
      "Epoch 25/3000\n",
      "8s - loss: 1.4569 - acc: 0.3560 - val_loss: 1.4748 - val_acc: 0.3457\n",
      "Epoch 26/3000\n",
      "8s - loss: 1.4601 - acc: 0.3560 - val_loss: 1.4777 - val_acc: 0.3403\n",
      "Epoch 27/3000\n",
      "8s - loss: 1.4526 - acc: 0.3630 - val_loss: 1.4722 - val_acc: 0.3588\n",
      "Epoch 28/3000\n",
      "8s - loss: 1.4493 - acc: 0.3622 - val_loss: 1.4755 - val_acc: 0.3330\n",
      "Epoch 29/3000\n",
      "8s - loss: 1.4406 - acc: 0.3758 - val_loss: 1.4663 - val_acc: 0.3516\n",
      "Epoch 30/3000\n",
      "8s - loss: 1.4372 - acc: 0.3679 - val_loss: 1.4625 - val_acc: 0.3570\n",
      "Epoch 31/3000\n",
      "8s - loss: 1.4321 - acc: 0.3671 - val_loss: 1.4620 - val_acc: 0.3606\n",
      "Epoch 32/3000\n",
      "8s - loss: 1.4359 - acc: 0.3756 - val_loss: 1.4635 - val_acc: 0.3597\n",
      "Epoch 33/3000\n",
      "8s - loss: 1.4233 - acc: 0.3806 - val_loss: 1.4607 - val_acc: 0.3701\n",
      "Epoch 34/3000\n",
      "8s - loss: 1.4279 - acc: 0.3752 - val_loss: 1.4632 - val_acc: 0.3516\n",
      "Epoch 35/3000\n",
      "8s - loss: 1.4225 - acc: 0.3760 - val_loss: 1.4586 - val_acc: 0.3661\n",
      "Epoch 36/3000\n",
      "8s - loss: 1.4191 - acc: 0.3824 - val_loss: 1.4584 - val_acc: 0.3548\n",
      "Epoch 37/3000\n",
      "8s - loss: 1.4107 - acc: 0.3876 - val_loss: 1.4560 - val_acc: 0.3579\n",
      "Epoch 38/3000\n",
      "8s - loss: 1.4135 - acc: 0.3831 - val_loss: 1.4634 - val_acc: 0.3557\n",
      "Epoch 39/3000\n",
      "8s - loss: 1.4122 - acc: 0.3770 - val_loss: 1.4546 - val_acc: 0.3665\n",
      "Epoch 40/3000\n",
      "8s - loss: 1.4093 - acc: 0.3858 - val_loss: 1.4638 - val_acc: 0.3548\n",
      "Epoch 41/3000\n",
      "8s - loss: 1.4073 - acc: 0.3960 - val_loss: 1.4580 - val_acc: 0.3593\n",
      "Epoch 42/3000\n",
      "8s - loss: 1.4018 - acc: 0.3890 - val_loss: 1.4539 - val_acc: 0.3643\n",
      "Epoch 43/3000\n",
      "8s - loss: 1.4003 - acc: 0.3820 - val_loss: 1.4543 - val_acc: 0.3652\n",
      "Epoch 44/3000\n",
      "8s - loss: 1.3980 - acc: 0.3973 - val_loss: 1.4559 - val_acc: 0.3665\n",
      "Epoch 45/3000\n",
      "8s - loss: 1.3911 - acc: 0.4024 - val_loss: 1.4537 - val_acc: 0.3588\n",
      "Epoch 46/3000\n",
      "8s - loss: 1.3870 - acc: 0.4017 - val_loss: 1.4545 - val_acc: 0.3652\n",
      "Epoch 47/3000\n",
      "8s - loss: 1.3896 - acc: 0.4001 - val_loss: 1.4546 - val_acc: 0.3570\n",
      "Epoch 48/3000\n",
      "8s - loss: 1.3885 - acc: 0.3948 - val_loss: 1.4548 - val_acc: 0.3561\n",
      "Epoch 49/3000\n",
      "8s - loss: 1.3747 - acc: 0.4003 - val_loss: 1.4550 - val_acc: 0.3652\n",
      "Epoch 50/3000\n",
      "8s - loss: 1.3826 - acc: 0.4018 - val_loss: 1.4502 - val_acc: 0.3643\n",
      "Epoch 51/3000\n",
      "8s - loss: 1.3724 - acc: 0.3996 - val_loss: 1.4539 - val_acc: 0.3566\n",
      "Epoch 52/3000\n",
      "8s - loss: 1.3750 - acc: 0.4082 - val_loss: 1.4460 - val_acc: 0.3706\n",
      "Epoch 53/3000\n",
      "8s - loss: 1.3678 - acc: 0.4131 - val_loss: 1.4555 - val_acc: 0.3588\n",
      "Epoch 54/3000\n",
      "8s - loss: 1.3713 - acc: 0.4069 - val_loss: 1.4488 - val_acc: 0.3570\n",
      "Epoch 55/3000\n",
      "8s - loss: 1.3679 - acc: 0.4094 - val_loss: 1.4513 - val_acc: 0.3493\n",
      "Epoch 56/3000\n",
      "8s - loss: 1.3679 - acc: 0.4137 - val_loss: 1.4509 - val_acc: 0.3570\n",
      "Epoch 57/3000\n",
      "8s - loss: 1.3676 - acc: 0.4080 - val_loss: 1.4493 - val_acc: 0.3602\n",
      "Epoch 58/3000\n",
      "8s - loss: 1.3588 - acc: 0.4188 - val_loss: 1.4514 - val_acc: 0.3525\n",
      "Epoch 59/3000\n",
      "8s - loss: 1.3553 - acc: 0.4200 - val_loss: 1.4528 - val_acc: 0.3615\n",
      "Epoch 60/3000\n",
      "8s - loss: 1.3622 - acc: 0.4094 - val_loss: 1.4584 - val_acc: 0.3606\n",
      "Epoch 61/3000\n",
      "8s - loss: 1.3481 - acc: 0.4193 - val_loss: 1.4495 - val_acc: 0.3561\n",
      "Epoch 62/3000\n",
      "8s - loss: 1.3493 - acc: 0.4203 - val_loss: 1.4522 - val_acc: 0.3498\n",
      "Epoch 63/3000\n",
      "8s - loss: 1.3444 - acc: 0.4196 - val_loss: 1.4510 - val_acc: 0.3624\n",
      "Epoch 64/3000\n",
      "8s - loss: 1.3409 - acc: 0.4230 - val_loss: 1.4464 - val_acc: 0.3620\n",
      "Epoch 65/3000\n",
      "8s - loss: 1.3448 - acc: 0.4185 - val_loss: 1.4457 - val_acc: 0.3747\n",
      "Epoch 66/3000\n",
      "8s - loss: 1.3363 - acc: 0.4198 - val_loss: 1.4420 - val_acc: 0.3674\n",
      "Epoch 67/3000\n",
      "8s - loss: 1.3420 - acc: 0.4223 - val_loss: 1.4478 - val_acc: 0.3670\n",
      "Epoch 68/3000\n",
      "8s - loss: 1.3407 - acc: 0.4257 - val_loss: 1.4435 - val_acc: 0.3670\n",
      "Epoch 69/3000\n",
      "8s - loss: 1.3256 - acc: 0.4300 - val_loss: 1.4484 - val_acc: 0.3665\n",
      "Epoch 70/3000\n",
      "8s - loss: 1.3295 - acc: 0.4358 - val_loss: 1.4483 - val_acc: 0.3665\n",
      "Epoch 71/3000\n",
      "8s - loss: 1.3315 - acc: 0.4315 - val_loss: 1.4439 - val_acc: 0.3688\n",
      "Epoch 72/3000\n",
      "8s - loss: 1.3239 - acc: 0.4333 - val_loss: 1.4389 - val_acc: 0.3697\n",
      "Epoch 73/3000\n",
      "8s - loss: 1.3267 - acc: 0.4323 - val_loss: 1.4413 - val_acc: 0.3697\n",
      "Epoch 74/3000\n",
      "8s - loss: 1.3253 - acc: 0.4282 - val_loss: 1.4395 - val_acc: 0.3710\n",
      "Epoch 75/3000\n",
      "8s - loss: 1.3186 - acc: 0.4365 - val_loss: 1.4517 - val_acc: 0.3670\n",
      "Epoch 76/3000\n",
      "8s - loss: 1.3192 - acc: 0.4334 - val_loss: 1.4382 - val_acc: 0.3661\n",
      "Epoch 77/3000\n",
      "8s - loss: 1.3171 - acc: 0.4290 - val_loss: 1.4472 - val_acc: 0.3697\n",
      "Epoch 78/3000\n",
      "8s - loss: 1.3184 - acc: 0.4340 - val_loss: 1.4457 - val_acc: 0.3647\n",
      "Epoch 79/3000\n",
      "8s - loss: 1.3219 - acc: 0.4369 - val_loss: 1.4425 - val_acc: 0.3679\n",
      "Epoch 80/3000\n",
      "8s - loss: 1.3111 - acc: 0.4345 - val_loss: 1.4348 - val_acc: 0.3602\n",
      "Epoch 81/3000\n",
      "8s - loss: 1.3152 - acc: 0.4366 - val_loss: 1.4416 - val_acc: 0.3692\n",
      "Epoch 82/3000\n",
      "8s - loss: 1.3049 - acc: 0.4410 - val_loss: 1.4390 - val_acc: 0.3719\n",
      "Epoch 83/3000\n",
      "8s - loss: 1.3071 - acc: 0.4457 - val_loss: 1.4405 - val_acc: 0.3688\n",
      "Epoch 84/3000\n",
      "8s - loss: 1.3056 - acc: 0.4410 - val_loss: 1.4384 - val_acc: 0.3647\n",
      "Epoch 85/3000\n",
      "8s - loss: 1.2975 - acc: 0.4494 - val_loss: 1.4410 - val_acc: 0.3710\n",
      "Epoch 86/3000\n",
      "8s - loss: 1.3063 - acc: 0.4459 - val_loss: 1.4418 - val_acc: 0.3647\n",
      "Epoch 87/3000\n",
      "8s - loss: 1.2924 - acc: 0.4511 - val_loss: 1.4403 - val_acc: 0.3683\n",
      "Epoch 88/3000\n",
      "8s - loss: 1.2845 - acc: 0.4539 - val_loss: 1.4361 - val_acc: 0.3706\n",
      "Epoch 89/3000\n",
      "8s - loss: 1.3003 - acc: 0.4453 - val_loss: 1.4364 - val_acc: 0.3733\n",
      "Epoch 90/3000\n",
      "8s - loss: 1.2833 - acc: 0.4475 - val_loss: 1.4364 - val_acc: 0.3765\n",
      "Epoch 91/3000\n",
      "8s - loss: 1.2905 - acc: 0.4525 - val_loss: 1.4394 - val_acc: 0.3751\n",
      "Epoch 92/3000\n",
      "8s - loss: 1.2862 - acc: 0.4550 - val_loss: 1.4398 - val_acc: 0.3729\n",
      "Epoch 93/3000\n",
      "8s - loss: 1.2872 - acc: 0.4556 - val_loss: 1.4354 - val_acc: 0.3688\n",
      "Epoch 94/3000\n",
      "8s - loss: 1.2901 - acc: 0.4454 - val_loss: 1.4364 - val_acc: 0.3742\n",
      "Epoch 95/3000\n",
      "8s - loss: 1.2785 - acc: 0.4554 - val_loss: 1.4321 - val_acc: 0.3783\n",
      "Epoch 96/3000\n",
      "8s - loss: 1.2883 - acc: 0.4468 - val_loss: 1.4379 - val_acc: 0.3738\n",
      "Epoch 97/3000\n",
      "8s - loss: 1.2820 - acc: 0.4561 - val_loss: 1.4393 - val_acc: 0.3724\n",
      "Epoch 98/3000\n",
      "8s - loss: 1.2808 - acc: 0.4564 - val_loss: 1.4397 - val_acc: 0.3719\n",
      "Epoch 99/3000\n",
      "8s - loss: 1.2822 - acc: 0.4517 - val_loss: 1.4373 - val_acc: 0.3729\n",
      "Epoch 100/3000\n",
      "8s - loss: 1.2726 - acc: 0.4612 - val_loss: 1.4391 - val_acc: 0.3769\n",
      "Epoch 101/3000\n",
      "8s - loss: 1.2729 - acc: 0.4658 - val_loss: 1.4390 - val_acc: 0.3670\n",
      "Epoch 102/3000\n",
      "8s - loss: 1.2706 - acc: 0.4570 - val_loss: 1.4341 - val_acc: 0.3801\n",
      "Epoch 103/3000\n",
      "8s - loss: 1.2803 - acc: 0.4553 - val_loss: 1.4291 - val_acc: 0.3688\n",
      "Epoch 104/3000\n",
      "8s - loss: 1.2643 - acc: 0.4636 - val_loss: 1.4349 - val_acc: 0.3683\n",
      "Epoch 105/3000\n",
      "8s - loss: 1.2624 - acc: 0.4711 - val_loss: 1.4314 - val_acc: 0.3769\n",
      "Epoch 106/3000\n",
      "8s - loss: 1.2722 - acc: 0.4708 - val_loss: 1.4360 - val_acc: 0.3710\n",
      "Epoch 107/3000\n",
      "8s - loss: 1.2643 - acc: 0.4684 - val_loss: 1.4346 - val_acc: 0.3742\n",
      "Epoch 108/3000\n",
      "8s - loss: 1.2647 - acc: 0.4700 - val_loss: 1.4340 - val_acc: 0.3706\n",
      "Epoch 109/3000\n",
      "8s - loss: 1.2559 - acc: 0.4679 - val_loss: 1.4330 - val_acc: 0.3864\n",
      "Epoch 110/3000\n",
      "8s - loss: 1.2587 - acc: 0.4706 - val_loss: 1.4364 - val_acc: 0.3783\n",
      "Epoch 111/3000\n",
      "8s - loss: 1.2576 - acc: 0.4686 - val_loss: 1.4338 - val_acc: 0.3783\n",
      "Epoch 112/3000\n",
      "8s - loss: 1.2564 - acc: 0.4707 - val_loss: 1.4328 - val_acc: 0.3715\n",
      "Epoch 113/3000\n",
      "8s - loss: 1.2628 - acc: 0.4646 - val_loss: 1.4366 - val_acc: 0.3769\n",
      "Epoch 114/3000\n",
      "8s - loss: 1.2515 - acc: 0.4703 - val_loss: 1.4412 - val_acc: 0.3792\n",
      "Epoch 115/3000\n",
      "8s - loss: 1.2414 - acc: 0.4711 - val_loss: 1.4389 - val_acc: 0.3638\n",
      "Epoch 116/3000\n",
      "8s - loss: 1.2469 - acc: 0.4780 - val_loss: 1.4381 - val_acc: 0.3697\n",
      "Epoch 117/3000\n",
      "8s - loss: 1.2525 - acc: 0.4737 - val_loss: 1.4420 - val_acc: 0.3611\n",
      "Epoch 118/3000\n",
      "8s - loss: 1.2517 - acc: 0.4664 - val_loss: 1.4352 - val_acc: 0.3783\n",
      "Epoch 119/3000\n",
      "8s - loss: 1.2428 - acc: 0.4711 - val_loss: 1.4374 - val_acc: 0.3701\n",
      "Epoch 120/3000\n",
      "8s - loss: 1.2468 - acc: 0.4753 - val_loss: 1.4390 - val_acc: 0.3765\n",
      "Epoch 121/3000\n",
      "8s - loss: 1.2315 - acc: 0.4754 - val_loss: 1.4327 - val_acc: 0.3792\n",
      "Epoch 122/3000\n",
      "8s - loss: 1.2390 - acc: 0.4816 - val_loss: 1.4325 - val_acc: 0.3900\n",
      "Epoch 123/3000\n",
      "8s - loss: 1.2404 - acc: 0.4765 - val_loss: 1.4353 - val_acc: 0.3846\n",
      "Epoch 124/3000\n",
      "8s - loss: 1.2414 - acc: 0.4801 - val_loss: 1.4358 - val_acc: 0.3778\n",
      "Epoch 125/3000\n",
      "8s - loss: 1.2445 - acc: 0.4733 - val_loss: 1.4399 - val_acc: 0.3828\n",
      "Epoch 126/3000\n",
      "8s - loss: 1.2254 - acc: 0.4841 - val_loss: 1.4392 - val_acc: 0.3787\n",
      "Epoch 127/3000\n",
      "8s - loss: 1.2386 - acc: 0.4788 - val_loss: 1.4413 - val_acc: 0.3819\n",
      "Epoch 128/3000\n",
      "8s - loss: 1.2348 - acc: 0.4802 - val_loss: 1.4447 - val_acc: 0.3719\n",
      "Epoch 129/3000\n",
      "8s - loss: 1.2316 - acc: 0.4796 - val_loss: 1.4430 - val_acc: 0.3819\n",
      "Epoch 130/3000\n",
      "8s - loss: 1.2301 - acc: 0.4814 - val_loss: 1.4343 - val_acc: 0.3837\n",
      "Epoch 131/3000\n",
      "8s - loss: 1.2270 - acc: 0.4853 - val_loss: 1.4482 - val_acc: 0.3747\n",
      "Epoch 132/3000\n",
      "8s - loss: 1.2280 - acc: 0.4837 - val_loss: 1.4379 - val_acc: 0.3778\n",
      "Epoch 133/3000\n",
      "8s - loss: 1.2366 - acc: 0.4743 - val_loss: 1.4414 - val_acc: 0.3824\n",
      "Epoch 134/3000\n",
      "8s - loss: 1.2278 - acc: 0.4853 - val_loss: 1.4407 - val_acc: 0.3801\n",
      "Epoch 135/3000\n",
      "8s - loss: 1.2290 - acc: 0.4799 - val_loss: 1.4372 - val_acc: 0.3810\n",
      "Epoch 136/3000\n",
      "8s - loss: 1.2256 - acc: 0.4784 - val_loss: 1.4380 - val_acc: 0.3774\n",
      "Epoch 137/3000\n",
      "8s - loss: 1.2312 - acc: 0.4841 - val_loss: 1.4366 - val_acc: 0.3905\n",
      "Epoch 138/3000\n",
      "8s - loss: 1.2181 - acc: 0.4905 - val_loss: 1.4323 - val_acc: 0.3846\n",
      "Epoch 139/3000\n",
      "8s - loss: 1.2207 - acc: 0.4844 - val_loss: 1.4415 - val_acc: 0.3851\n",
      "Epoch 140/3000\n",
      "8s - loss: 1.2271 - acc: 0.4818 - val_loss: 1.4367 - val_acc: 0.3828\n",
      "Epoch 141/3000\n",
      "8s - loss: 1.2175 - acc: 0.4905 - val_loss: 1.4365 - val_acc: 0.3842\n",
      "Epoch 142/3000\n",
      "8s - loss: 1.2035 - acc: 0.5007 - val_loss: 1.4340 - val_acc: 0.3851\n",
      "Epoch 143/3000\n",
      "8s - loss: 1.2180 - acc: 0.4840 - val_loss: 1.4402 - val_acc: 0.3787\n",
      "Epoch 144/3000\n",
      "8s - loss: 1.2132 - acc: 0.4884 - val_loss: 1.4450 - val_acc: 0.3805\n",
      "Epoch 145/3000\n",
      "8s - loss: 1.2283 - acc: 0.4864 - val_loss: 1.4365 - val_acc: 0.3860\n",
      "Epoch 146/3000\n",
      "8s - loss: 1.2063 - acc: 0.4961 - val_loss: 1.4346 - val_acc: 0.3765\n",
      "Epoch 147/3000\n",
      "8s - loss: 1.2186 - acc: 0.4880 - val_loss: 1.4392 - val_acc: 0.3765\n",
      "Epoch 148/3000\n",
      "8s - loss: 1.2185 - acc: 0.4850 - val_loss: 1.4378 - val_acc: 0.3760\n",
      "Epoch 149/3000\n",
      "8s - loss: 1.2166 - acc: 0.4890 - val_loss: 1.4322 - val_acc: 0.3851\n",
      "Epoch 150/3000\n",
      "8s - loss: 1.2270 - acc: 0.4856 - val_loss: 1.4333 - val_acc: 0.3851\n",
      "Epoch 151/3000\n",
      "8s - loss: 1.2021 - acc: 0.4988 - val_loss: 1.4390 - val_acc: 0.3747\n",
      "Epoch 152/3000\n",
      "8s - loss: 1.2104 - acc: 0.4967 - val_loss: 1.4414 - val_acc: 0.3860\n",
      "Epoch 153/3000\n",
      "8s - loss: 1.2059 - acc: 0.4955 - val_loss: 1.4402 - val_acc: 0.3869\n",
      "Epoch 154/3000\n",
      "8s - loss: 1.2094 - acc: 0.4896 - val_loss: 1.4332 - val_acc: 0.3824\n",
      "Epoch 155/3000\n",
      "8s - loss: 1.2073 - acc: 0.4940 - val_loss: 1.4342 - val_acc: 0.3846\n",
      "Epoch 156/3000\n",
      "8s - loss: 1.2006 - acc: 0.4925 - val_loss: 1.4378 - val_acc: 0.3824\n",
      "Epoch 157/3000\n",
      "8s - loss: 1.2014 - acc: 0.4978 - val_loss: 1.4343 - val_acc: 0.3814\n",
      "Epoch 158/3000\n",
      "8s - loss: 1.2048 - acc: 0.4908 - val_loss: 1.4387 - val_acc: 0.3733\n",
      "Epoch 159/3000\n",
      "8s - loss: 1.2019 - acc: 0.4985 - val_loss: 1.4337 - val_acc: 0.3828\n",
      "Epoch 160/3000\n",
      "8s - loss: 1.2045 - acc: 0.4963 - val_loss: 1.4358 - val_acc: 0.3842\n",
      "Epoch 161/3000\n",
      "8s - loss: 1.2011 - acc: 0.4975 - val_loss: 1.4408 - val_acc: 0.3792\n",
      "Epoch 162/3000\n",
      "8s - loss: 1.2000 - acc: 0.5002 - val_loss: 1.4438 - val_acc: 0.3765\n",
      "Epoch 163/3000\n",
      "8s - loss: 1.2007 - acc: 0.4931 - val_loss: 1.4333 - val_acc: 0.3756\n",
      "Epoch 164/3000\n",
      "8s - loss: 1.1989 - acc: 0.4990 - val_loss: 1.4388 - val_acc: 0.3729\n",
      "Epoch 165/3000\n",
      "8s - loss: 1.2042 - acc: 0.4979 - val_loss: 1.4366 - val_acc: 0.3805\n",
      "Epoch 166/3000\n",
      "8s - loss: 1.1951 - acc: 0.5072 - val_loss: 1.4437 - val_acc: 0.3738\n",
      "Epoch 167/3000\n",
      "8s - loss: 1.1919 - acc: 0.5006 - val_loss: 1.4363 - val_acc: 0.3814\n",
      "Epoch 168/3000\n",
      "8s - loss: 1.1902 - acc: 0.5038 - val_loss: 1.4339 - val_acc: 0.3778\n",
      "Epoch 169/3000\n",
      "8s - loss: 1.2014 - acc: 0.5006 - val_loss: 1.4336 - val_acc: 0.3860\n",
      "Epoch 170/3000\n",
      "8s - loss: 1.1877 - acc: 0.5059 - val_loss: 1.4339 - val_acc: 0.3882\n",
      "Epoch 171/3000\n",
      "8s - loss: 1.1909 - acc: 0.5014 - val_loss: 1.4372 - val_acc: 0.3869\n",
      "Epoch 172/3000\n",
      "8s - loss: 1.1869 - acc: 0.5101 - val_loss: 1.4359 - val_acc: 0.3765\n",
      "Epoch 173/3000\n",
      "8s - loss: 1.1817 - acc: 0.5122 - val_loss: 1.4382 - val_acc: 0.3796\n",
      "Epoch 174/3000\n",
      "8s - loss: 1.1855 - acc: 0.5041 - val_loss: 1.4411 - val_acc: 0.3774\n",
      "Epoch 175/3000\n",
      "8s - loss: 1.1733 - acc: 0.5076 - val_loss: 1.4382 - val_acc: 0.3783\n",
      "Epoch 176/3000\n",
      "8s - loss: 1.1952 - acc: 0.5038 - val_loss: 1.4375 - val_acc: 0.3778\n",
      "Epoch 177/3000\n",
      "8s - loss: 1.1829 - acc: 0.5049 - val_loss: 1.4368 - val_acc: 0.3706\n",
      "Epoch 178/3000\n",
      "8s - loss: 1.1833 - acc: 0.5080 - val_loss: 1.4399 - val_acc: 0.3796\n",
      "Epoch 179/3000\n",
      "8s - loss: 1.1962 - acc: 0.5032 - val_loss: 1.4391 - val_acc: 0.3738\n",
      "Epoch 180/3000\n",
      "8s - loss: 1.1888 - acc: 0.5035 - val_loss: 1.4407 - val_acc: 0.3796\n",
      "Epoch 181/3000\n",
      "8s - loss: 1.1866 - acc: 0.5077 - val_loss: 1.4359 - val_acc: 0.3787\n",
      "Epoch 182/3000\n",
      "8s - loss: 1.1912 - acc: 0.5082 - val_loss: 1.4349 - val_acc: 0.3738\n",
      "Epoch 183/3000\n",
      "8s - loss: 1.1858 - acc: 0.5068 - val_loss: 1.4387 - val_acc: 0.3747\n",
      "Epoch 184/3000\n",
      "8s - loss: 1.1786 - acc: 0.5081 - val_loss: 1.4317 - val_acc: 0.3756\n",
      "Epoch 185/3000\n",
      "8s - loss: 1.1706 - acc: 0.5129 - val_loss: 1.4372 - val_acc: 0.3769\n",
      "Epoch 186/3000\n",
      "8s - loss: 1.1835 - acc: 0.5034 - val_loss: 1.4362 - val_acc: 0.3751\n",
      "Epoch 187/3000\n",
      "8s - loss: 1.1567 - acc: 0.5165 - val_loss: 1.4426 - val_acc: 0.3724\n",
      "Epoch 188/3000\n",
      "8s - loss: 1.1751 - acc: 0.5142 - val_loss: 1.4321 - val_acc: 0.3814\n",
      "Epoch 189/3000\n",
      "8s - loss: 1.1763 - acc: 0.5098 - val_loss: 1.4331 - val_acc: 0.3805\n",
      "Epoch 190/3000\n",
      "8s - loss: 1.1812 - acc: 0.5082 - val_loss: 1.4375 - val_acc: 0.3814\n",
      "Epoch 191/3000\n",
      "8s - loss: 1.1712 - acc: 0.5084 - val_loss: 1.4367 - val_acc: 0.3810\n",
      "Epoch 192/3000\n",
      "8s - loss: 1.1810 - acc: 0.5112 - val_loss: 1.4331 - val_acc: 0.3810\n",
      "Epoch 193/3000\n",
      "8s - loss: 1.1783 - acc: 0.5098 - val_loss: 1.4363 - val_acc: 0.3810\n",
      "Epoch 194/3000\n",
      "8s - loss: 1.1654 - acc: 0.5183 - val_loss: 1.4380 - val_acc: 0.3869\n",
      "Epoch 195/3000\n",
      "8s - loss: 1.1665 - acc: 0.5217 - val_loss: 1.4339 - val_acc: 0.3837\n",
      "Epoch 196/3000\n",
      "8s - loss: 1.1704 - acc: 0.5117 - val_loss: 1.4366 - val_acc: 0.3769\n",
      "Epoch 197/3000\n",
      "8s - loss: 1.1731 - acc: 0.5107 - val_loss: 1.4330 - val_acc: 0.3860\n",
      "Epoch 198/3000\n",
      "8s - loss: 1.1752 - acc: 0.5192 - val_loss: 1.4367 - val_acc: 0.3882\n",
      "Epoch 199/3000\n",
      "8s - loss: 1.1675 - acc: 0.5178 - val_loss: 1.4389 - val_acc: 0.3864\n",
      "Epoch 200/3000\n",
      "8s - loss: 1.1610 - acc: 0.5161 - val_loss: 1.4320 - val_acc: 0.3869\n",
      "Epoch 201/3000\n",
      "8s - loss: 1.1578 - acc: 0.5194 - val_loss: 1.4390 - val_acc: 0.3846\n",
      "Epoch 202/3000\n",
      "8s - loss: 1.1693 - acc: 0.5179 - val_loss: 1.4351 - val_acc: 0.3950\n",
      "Epoch 203/3000\n",
      "8s - loss: 1.1538 - acc: 0.5187 - val_loss: 1.4361 - val_acc: 0.3842\n",
      "Epoch 204/3000\n",
      "8s - loss: 1.1564 - acc: 0.5208 - val_loss: 1.4377 - val_acc: 0.3778\n",
      "Epoch 205/3000\n",
      "8s - loss: 1.1668 - acc: 0.5200 - val_loss: 1.4321 - val_acc: 0.3814\n",
      "Epoch 206/3000\n",
      "8s - loss: 1.1649 - acc: 0.5265 - val_loss: 1.4311 - val_acc: 0.3796\n",
      "Epoch 207/3000\n",
      "8s - loss: 1.1664 - acc: 0.5179 - val_loss: 1.4290 - val_acc: 0.3914\n",
      "Epoch 208/3000\n",
      "8s - loss: 1.1687 - acc: 0.5154 - val_loss: 1.4362 - val_acc: 0.3792\n",
      "Epoch 209/3000\n",
      "8s - loss: 1.1593 - acc: 0.5206 - val_loss: 1.4312 - val_acc: 0.3851\n",
      "Epoch 210/3000\n",
      "8s - loss: 1.1585 - acc: 0.5231 - val_loss: 1.4406 - val_acc: 0.3729\n",
      "Epoch 211/3000\n",
      "8s - loss: 1.1424 - acc: 0.5258 - val_loss: 1.4341 - val_acc: 0.3824\n",
      "Epoch 212/3000\n",
      "8s - loss: 1.1617 - acc: 0.5144 - val_loss: 1.4327 - val_acc: 0.3851\n",
      "Epoch 213/3000\n",
      "8s - loss: 1.1564 - acc: 0.5193 - val_loss: 1.4367 - val_acc: 0.3747\n",
      "Epoch 214/3000\n",
      "8s - loss: 1.1425 - acc: 0.5277 - val_loss: 1.4335 - val_acc: 0.3837\n",
      "Epoch 215/3000\n",
      "8s - loss: 1.1402 - acc: 0.5269 - val_loss: 1.4365 - val_acc: 0.3814\n",
      "Epoch 216/3000\n",
      "8s - loss: 1.1462 - acc: 0.5245 - val_loss: 1.4357 - val_acc: 0.3792\n",
      "Epoch 217/3000\n",
      "8s - loss: 1.1486 - acc: 0.5230 - val_loss: 1.4337 - val_acc: 0.3842\n",
      "Epoch 218/3000\n",
      "8s - loss: 1.1438 - acc: 0.5265 - val_loss: 1.4314 - val_acc: 0.3819\n",
      "Epoch 219/3000\n",
      "8s - loss: 1.1638 - acc: 0.5198 - val_loss: 1.4339 - val_acc: 0.3864\n",
      "Epoch 220/3000\n",
      "8s - loss: 1.1369 - acc: 0.5332 - val_loss: 1.4388 - val_acc: 0.3828\n",
      "Epoch 221/3000\n",
      "8s - loss: 1.1503 - acc: 0.5214 - val_loss: 1.4485 - val_acc: 0.3769\n",
      "Epoch 222/3000\n",
      "8s - loss: 1.1588 - acc: 0.5157 - val_loss: 1.4352 - val_acc: 0.3747\n",
      "Epoch 223/3000\n",
      "8s - loss: 1.1507 - acc: 0.5289 - val_loss: 1.4395 - val_acc: 0.3819\n",
      "Epoch 224/3000\n",
      "8s - loss: 1.1413 - acc: 0.5317 - val_loss: 1.4315 - val_acc: 0.3819\n",
      "Epoch 225/3000\n",
      "8s - loss: 1.1554 - acc: 0.5229 - val_loss: 1.4364 - val_acc: 0.3837\n",
      "Epoch 226/3000\n",
      "8s - loss: 1.1465 - acc: 0.5287 - val_loss: 1.4408 - val_acc: 0.3774\n",
      "Epoch 227/3000\n",
      "8s - loss: 1.1456 - acc: 0.5280 - val_loss: 1.4340 - val_acc: 0.3828\n",
      "Epoch 228/3000\n",
      "8s - loss: 1.1296 - acc: 0.5321 - val_loss: 1.4349 - val_acc: 0.3796\n",
      "Epoch 229/3000\n",
      "8s - loss: 1.1494 - acc: 0.5242 - val_loss: 1.4319 - val_acc: 0.3796\n",
      "Epoch 230/3000\n",
      "8s - loss: 1.1546 - acc: 0.5235 - val_loss: 1.4327 - val_acc: 0.3774\n",
      "Epoch 231/3000\n",
      "8s - loss: 1.1510 - acc: 0.5343 - val_loss: 1.4376 - val_acc: 0.3801\n",
      "Epoch 232/3000\n",
      "8s - loss: 1.1389 - acc: 0.5309 - val_loss: 1.4390 - val_acc: 0.3774\n",
      "Epoch 233/3000\n",
      "8s - loss: 1.1526 - acc: 0.5291 - val_loss: 1.4401 - val_acc: 0.3751\n",
      "Epoch 234/3000\n",
      "8s - loss: 1.1371 - acc: 0.5322 - val_loss: 1.4352 - val_acc: 0.3787\n",
      "Epoch 235/3000\n",
      "8s - loss: 1.1366 - acc: 0.5290 - val_loss: 1.4462 - val_acc: 0.3769\n",
      "Epoch 236/3000\n",
      "8s - loss: 1.1393 - acc: 0.5278 - val_loss: 1.4371 - val_acc: 0.3742\n",
      "Epoch 237/3000\n",
      "8s - loss: 1.1441 - acc: 0.5325 - val_loss: 1.4404 - val_acc: 0.3810\n",
      "Epoch 238/3000\n",
      "8s - loss: 1.1407 - acc: 0.5293 - val_loss: 1.4432 - val_acc: 0.3774\n",
      "Epoch 239/3000\n",
      "8s - loss: 1.1417 - acc: 0.5235 - val_loss: 1.4476 - val_acc: 0.3710\n",
      "Epoch 240/3000\n",
      "8s - loss: 1.1397 - acc: 0.5381 - val_loss: 1.4366 - val_acc: 0.3842\n",
      "Epoch 241/3000\n",
      "8s - loss: 1.1260 - acc: 0.5392 - val_loss: 1.4456 - val_acc: 0.3688\n",
      "Epoch 242/3000\n",
      "8s - loss: 1.1531 - acc: 0.5257 - val_loss: 1.4460 - val_acc: 0.3828\n",
      "Epoch 243/3000\n",
      "8s - loss: 1.1346 - acc: 0.5333 - val_loss: 1.4349 - val_acc: 0.3774\n",
      "Epoch 244/3000\n",
      "8s - loss: 1.1495 - acc: 0.5261 - val_loss: 1.4446 - val_acc: 0.3738\n",
      "Epoch 245/3000\n",
      "8s - loss: 1.1316 - acc: 0.5319 - val_loss: 1.4402 - val_acc: 0.3765\n",
      "Epoch 246/3000\n",
      "8s - loss: 1.1300 - acc: 0.5322 - val_loss: 1.4408 - val_acc: 0.3896\n",
      "Epoch 247/3000\n",
      "8s - loss: 1.1494 - acc: 0.5302 - val_loss: 1.4380 - val_acc: 0.3796\n",
      "Epoch 248/3000\n",
      "8s - loss: 1.1285 - acc: 0.5379 - val_loss: 1.4493 - val_acc: 0.3810\n",
      "Epoch 249/3000\n",
      "8s - loss: 1.1351 - acc: 0.5307 - val_loss: 1.4398 - val_acc: 0.3833\n",
      "Epoch 250/3000\n",
      "8s - loss: 1.1283 - acc: 0.5350 - val_loss: 1.4433 - val_acc: 0.3801\n",
      "Epoch 251/3000\n",
      "8s - loss: 1.1359 - acc: 0.5339 - val_loss: 1.4426 - val_acc: 0.3783\n",
      "Epoch 252/3000\n",
      "8s - loss: 1.1290 - acc: 0.5367 - val_loss: 1.4412 - val_acc: 0.3697\n",
      "Epoch 253/3000\n",
      "8s - loss: 1.1196 - acc: 0.5409 - val_loss: 1.4426 - val_acc: 0.3724\n",
      "Epoch 254/3000\n",
      "8s - loss: 1.1292 - acc: 0.5337 - val_loss: 1.4541 - val_acc: 0.3710\n",
      "Epoch 255/3000\n",
      "8s - loss: 1.1298 - acc: 0.5348 - val_loss: 1.4448 - val_acc: 0.3706\n",
      "Epoch 256/3000\n",
      "8s - loss: 1.1188 - acc: 0.5363 - val_loss: 1.4512 - val_acc: 0.3724\n",
      "Epoch 257/3000\n",
      "8s - loss: 1.1424 - acc: 0.5297 - val_loss: 1.4444 - val_acc: 0.3710\n",
      "Epoch 258/3000\n",
      "8s - loss: 1.1129 - acc: 0.5438 - val_loss: 1.4437 - val_acc: 0.3670\n",
      "Epoch 259/3000\n",
      "8s - loss: 1.1268 - acc: 0.5359 - val_loss: 1.4344 - val_acc: 0.3792\n",
      "Epoch 260/3000\n",
      "8s - loss: 1.1284 - acc: 0.5412 - val_loss: 1.4371 - val_acc: 0.3787\n",
      "Epoch 261/3000\n",
      "8s - loss: 1.1382 - acc: 0.5302 - val_loss: 1.4392 - val_acc: 0.3769\n",
      "Epoch 262/3000\n",
      "8s - loss: 1.1335 - acc: 0.5301 - val_loss: 1.4346 - val_acc: 0.3774\n",
      "Epoch 263/3000\n",
      "8s - loss: 1.1245 - acc: 0.5376 - val_loss: 1.4408 - val_acc: 0.3724\n",
      "Epoch 264/3000\n",
      "8s - loss: 1.1208 - acc: 0.5408 - val_loss: 1.4359 - val_acc: 0.3774\n",
      "Epoch 265/3000\n",
      "8s - loss: 1.1299 - acc: 0.5438 - val_loss: 1.4447 - val_acc: 0.3719\n",
      "Epoch 266/3000\n",
      "8s - loss: 1.1067 - acc: 0.5404 - val_loss: 1.4406 - val_acc: 0.3656\n",
      "Epoch 267/3000\n",
      "8s - loss: 1.1150 - acc: 0.5414 - val_loss: 1.4456 - val_acc: 0.3652\n",
      "Epoch 268/3000\n",
      "8s - loss: 1.1427 - acc: 0.5316 - val_loss: 1.4399 - val_acc: 0.3697\n",
      "Epoch 269/3000\n",
      "8s - loss: 1.1149 - acc: 0.5437 - val_loss: 1.4380 - val_acc: 0.3738\n",
      "Epoch 270/3000\n",
      "8s - loss: 1.1104 - acc: 0.5389 - val_loss: 1.4409 - val_acc: 0.3747\n",
      "Epoch 271/3000\n",
      "8s - loss: 1.1101 - acc: 0.5427 - val_loss: 1.4442 - val_acc: 0.3701\n",
      "Epoch 272/3000\n",
      "8s - loss: 1.1132 - acc: 0.5504 - val_loss: 1.4409 - val_acc: 0.3670\n",
      "Epoch 273/3000\n",
      "8s - loss: 1.1116 - acc: 0.5444 - val_loss: 1.4433 - val_acc: 0.3724\n",
      "Epoch 274/3000\n",
      "8s - loss: 1.1202 - acc: 0.5384 - val_loss: 1.4422 - val_acc: 0.3828\n",
      "Epoch 275/3000\n",
      "8s - loss: 1.1258 - acc: 0.5365 - val_loss: 1.4380 - val_acc: 0.3828\n",
      "Epoch 276/3000\n",
      "8s - loss: 1.1309 - acc: 0.5388 - val_loss: 1.4444 - val_acc: 0.3729\n",
      "Epoch 277/3000\n",
      "8s - loss: 1.1119 - acc: 0.5485 - val_loss: 1.4422 - val_acc: 0.3805\n",
      "Epoch 278/3000\n",
      "8s - loss: 1.1190 - acc: 0.5408 - val_loss: 1.4384 - val_acc: 0.3751\n",
      "Epoch 279/3000\n",
      "8s - loss: 1.1179 - acc: 0.5374 - val_loss: 1.4424 - val_acc: 0.3706\n",
      "Epoch 280/3000\n",
      "8s - loss: 1.1274 - acc: 0.5365 - val_loss: 1.4445 - val_acc: 0.3769\n",
      "Epoch 281/3000\n",
      "8s - loss: 1.1198 - acc: 0.5427 - val_loss: 1.4416 - val_acc: 0.3719\n",
      "Epoch 282/3000\n",
      "8s - loss: 1.1125 - acc: 0.5442 - val_loss: 1.4425 - val_acc: 0.3710\n",
      "Epoch 283/3000\n",
      "8s - loss: 1.1175 - acc: 0.5445 - val_loss: 1.4566 - val_acc: 0.3747\n",
      "Epoch 284/3000\n",
      "8s - loss: 1.1117 - acc: 0.5477 - val_loss: 1.4451 - val_acc: 0.3805\n",
      "Epoch 285/3000\n",
      "8s - loss: 1.1223 - acc: 0.5435 - val_loss: 1.4524 - val_acc: 0.3706\n",
      "Epoch 286/3000\n",
      "8s - loss: 1.1170 - acc: 0.5382 - val_loss: 1.4450 - val_acc: 0.3751\n",
      "Epoch 287/3000\n",
      "8s - loss: 1.1054 - acc: 0.5457 - val_loss: 1.4380 - val_acc: 0.3733\n",
      "Epoch 288/3000\n",
      "8s - loss: 1.1049 - acc: 0.5478 - val_loss: 1.4460 - val_acc: 0.3751\n",
      "Epoch 289/3000\n",
      "8s - loss: 1.1129 - acc: 0.5434 - val_loss: 1.4433 - val_acc: 0.3729\n",
      "Epoch 290/3000\n",
      "8s - loss: 1.1097 - acc: 0.5483 - val_loss: 1.4432 - val_acc: 0.3674\n",
      "Epoch 291/3000\n",
      "8s - loss: 1.1132 - acc: 0.5500 - val_loss: 1.4467 - val_acc: 0.3738\n",
      "Epoch 292/3000\n",
      "8s - loss: 1.1034 - acc: 0.5551 - val_loss: 1.4393 - val_acc: 0.3738\n",
      "Epoch 293/3000\n",
      "8s - loss: 1.1045 - acc: 0.5557 - val_loss: 1.4451 - val_acc: 0.3747\n",
      "Epoch 294/3000\n",
      "8s - loss: 1.1000 - acc: 0.5505 - val_loss: 1.4429 - val_acc: 0.3774\n",
      "Epoch 295/3000\n",
      "8s - loss: 1.0970 - acc: 0.5532 - val_loss: 1.4363 - val_acc: 0.3751\n",
      "Epoch 296/3000\n",
      "8s - loss: 1.1090 - acc: 0.5419 - val_loss: 1.4384 - val_acc: 0.3774\n",
      "Epoch 297/3000\n",
      "8s - loss: 1.1215 - acc: 0.5378 - val_loss: 1.4441 - val_acc: 0.3778\n",
      "Epoch 298/3000\n",
      "8s - loss: 1.1105 - acc: 0.5443 - val_loss: 1.4418 - val_acc: 0.3783\n",
      "Epoch 299/3000\n",
      "8s - loss: 1.0961 - acc: 0.5501 - val_loss: 1.4490 - val_acc: 0.3747\n",
      "Epoch 300/3000\n",
      "8s - loss: 1.1039 - acc: 0.5487 - val_loss: 1.4461 - val_acc: 0.3760\n",
      "Epoch 301/3000\n",
      "8s - loss: 1.1039 - acc: 0.5449 - val_loss: 1.4458 - val_acc: 0.3756\n",
      "Epoch 302/3000\n",
      "8s - loss: 1.1101 - acc: 0.5480 - val_loss: 1.4497 - val_acc: 0.3765\n",
      "Epoch 303/3000\n",
      "8s - loss: 1.0919 - acc: 0.5528 - val_loss: 1.4458 - val_acc: 0.3638\n",
      "Epoch 304/3000\n",
      "8s - loss: 1.1042 - acc: 0.5497 - val_loss: 1.4420 - val_acc: 0.3778\n",
      "Epoch 305/3000\n",
      "8s - loss: 1.1142 - acc: 0.5498 - val_loss: 1.4420 - val_acc: 0.3742\n",
      "Epoch 306/3000\n",
      "8s - loss: 1.1060 - acc: 0.5536 - val_loss: 1.4421 - val_acc: 0.3747\n",
      "Epoch 307/3000\n",
      "8s - loss: 1.1067 - acc: 0.5473 - val_loss: 1.4379 - val_acc: 0.3729\n",
      "Epoch 308/3000\n",
      "8s - loss: 1.1079 - acc: 0.5473 - val_loss: 1.4369 - val_acc: 0.3819\n",
      "Epoch 309/3000\n",
      "8s - loss: 1.1043 - acc: 0.5483 - val_loss: 1.4420 - val_acc: 0.3742\n",
      "Epoch 310/3000\n",
      "8s - loss: 1.0904 - acc: 0.5583 - val_loss: 1.4387 - val_acc: 0.3760\n",
      "Epoch 311/3000\n",
      "8s - loss: 1.1114 - acc: 0.5469 - val_loss: 1.4427 - val_acc: 0.3715\n",
      "Epoch 312/3000\n",
      "8s - loss: 1.1025 - acc: 0.5469 - val_loss: 1.4486 - val_acc: 0.3769\n",
      "Epoch 313/3000\n",
      "8s - loss: 1.1041 - acc: 0.5469 - val_loss: 1.4458 - val_acc: 0.3787\n",
      "Epoch 314/3000\n",
      "8s - loss: 1.1113 - acc: 0.5526 - val_loss: 1.4386 - val_acc: 0.3760\n",
      "Epoch 315/3000\n",
      "8s - loss: 1.1119 - acc: 0.5446 - val_loss: 1.4512 - val_acc: 0.3733\n",
      "Epoch 316/3000\n",
      "8s - loss: 1.1029 - acc: 0.5539 - val_loss: 1.4468 - val_acc: 0.3742\n",
      "Epoch 317/3000\n",
      "8s - loss: 1.0927 - acc: 0.5556 - val_loss: 1.4458 - val_acc: 0.3670\n",
      "Epoch 318/3000\n",
      "8s - loss: 1.0984 - acc: 0.5478 - val_loss: 1.4445 - val_acc: 0.3679\n",
      "Epoch 319/3000\n",
      "8s - loss: 1.0916 - acc: 0.5572 - val_loss: 1.4425 - val_acc: 0.3692\n",
      "Epoch 320/3000\n",
      "8s - loss: 1.0961 - acc: 0.5567 - val_loss: 1.4437 - val_acc: 0.3706\n",
      "Epoch 321/3000\n",
      "8s - loss: 1.1084 - acc: 0.5453 - val_loss: 1.4454 - val_acc: 0.3747\n",
      "Epoch 322/3000\n",
      "8s - loss: 1.0926 - acc: 0.5572 - val_loss: 1.4520 - val_acc: 0.3679\n",
      "Epoch 323/3000\n",
      "8s - loss: 1.1051 - acc: 0.5498 - val_loss: 1.4534 - val_acc: 0.3706\n",
      "Epoch 324/3000\n",
      "8s - loss: 1.0812 - acc: 0.5678 - val_loss: 1.4443 - val_acc: 0.3760\n",
      "Epoch 325/3000\n",
      "8s - loss: 1.0986 - acc: 0.5533 - val_loss: 1.4442 - val_acc: 0.3742\n",
      "Epoch 326/3000\n",
      "8s - loss: 1.0861 - acc: 0.5511 - val_loss: 1.4484 - val_acc: 0.3710\n",
      "Epoch 327/3000\n",
      "8s - loss: 1.0961 - acc: 0.5530 - val_loss: 1.4424 - val_acc: 0.3701\n",
      "Epoch 328/3000\n",
      "8s - loss: 1.0938 - acc: 0.5559 - val_loss: 1.4413 - val_acc: 0.3751\n",
      "Epoch 329/3000\n",
      "8s - loss: 1.0841 - acc: 0.5621 - val_loss: 1.4395 - val_acc: 0.3792\n",
      "Epoch 330/3000\n",
      "8s - loss: 1.0929 - acc: 0.5449 - val_loss: 1.4571 - val_acc: 0.3787\n",
      "Epoch 331/3000\n",
      "8s - loss: 1.0801 - acc: 0.5597 - val_loss: 1.4459 - val_acc: 0.3738\n",
      "Epoch 332/3000\n",
      "8s - loss: 1.0988 - acc: 0.5540 - val_loss: 1.4489 - val_acc: 0.3683\n",
      "Epoch 333/3000\n",
      "8s - loss: 1.0981 - acc: 0.5514 - val_loss: 1.4452 - val_acc: 0.3769\n",
      "Epoch 334/3000\n",
      "8s - loss: 1.0990 - acc: 0.5497 - val_loss: 1.4446 - val_acc: 0.3733\n",
      "Epoch 335/3000\n",
      "8s - loss: 1.0899 - acc: 0.5604 - val_loss: 1.4491 - val_acc: 0.3760\n",
      "Epoch 336/3000\n",
      "8s - loss: 1.0906 - acc: 0.5556 - val_loss: 1.4374 - val_acc: 0.3778\n",
      "Epoch 337/3000\n",
      "8s - loss: 1.0794 - acc: 0.5645 - val_loss: 1.4521 - val_acc: 0.3719\n",
      "Epoch 338/3000\n",
      "8s - loss: 1.0814 - acc: 0.5588 - val_loss: 1.4425 - val_acc: 0.3756\n",
      "Epoch 339/3000\n",
      "8s - loss: 1.0949 - acc: 0.5548 - val_loss: 1.4430 - val_acc: 0.3805\n",
      "Epoch 340/3000\n",
      "8s - loss: 1.0693 - acc: 0.5660 - val_loss: 1.4533 - val_acc: 0.3751\n",
      "Epoch 341/3000\n",
      "8s - loss: 1.0826 - acc: 0.5606 - val_loss: 1.4442 - val_acc: 0.3842\n",
      "Epoch 342/3000\n",
      "8s - loss: 1.0801 - acc: 0.5622 - val_loss: 1.4525 - val_acc: 0.3828\n",
      "Epoch 343/3000\n",
      "8s - loss: 1.0847 - acc: 0.5575 - val_loss: 1.4497 - val_acc: 0.3778\n",
      "Epoch 344/3000\n",
      "8s - loss: 1.0882 - acc: 0.5580 - val_loss: 1.4514 - val_acc: 0.3769\n",
      "Epoch 345/3000\n",
      "8s - loss: 1.0874 - acc: 0.5609 - val_loss: 1.4476 - val_acc: 0.3747\n",
      "Epoch 346/3000\n",
      "8s - loss: 1.0806 - acc: 0.5634 - val_loss: 1.4407 - val_acc: 0.3819\n",
      "Epoch 347/3000\n",
      "8s - loss: 1.0731 - acc: 0.5681 - val_loss: 1.4466 - val_acc: 0.3729\n",
      "Epoch 348/3000\n",
      "8s - loss: 1.0944 - acc: 0.5544 - val_loss: 1.4450 - val_acc: 0.3724\n",
      "Epoch 349/3000\n",
      "8s - loss: 1.1028 - acc: 0.5489 - val_loss: 1.4444 - val_acc: 0.3787\n",
      "Epoch 350/3000\n",
      "8s - loss: 1.0759 - acc: 0.5605 - val_loss: 1.4524 - val_acc: 0.3751\n",
      "Epoch 351/3000\n",
      "8s - loss: 1.1010 - acc: 0.5522 - val_loss: 1.4496 - val_acc: 0.3783\n",
      "Epoch 352/3000\n",
      "8s - loss: 1.0771 - acc: 0.5653 - val_loss: 1.4454 - val_acc: 0.3719\n",
      "Epoch 353/3000\n",
      "8s - loss: 1.0917 - acc: 0.5534 - val_loss: 1.4515 - val_acc: 0.3710\n",
      "Epoch 354/3000\n",
      "8s - loss: 1.0873 - acc: 0.5530 - val_loss: 1.4483 - val_acc: 0.3724\n",
      "Epoch 355/3000\n",
      "8s - loss: 1.0792 - acc: 0.5559 - val_loss: 1.4437 - val_acc: 0.3769\n",
      "Epoch 356/3000\n",
      "8s - loss: 1.0871 - acc: 0.5586 - val_loss: 1.4410 - val_acc: 0.3851\n",
      "Epoch 357/3000\n",
      "8s - loss: 1.0762 - acc: 0.5611 - val_loss: 1.4429 - val_acc: 0.3769\n",
      "Epoch 358/3000\n",
      "8s - loss: 1.0894 - acc: 0.5596 - val_loss: 1.4407 - val_acc: 0.3751\n",
      "Epoch 359/3000\n",
      "8s - loss: 1.0804 - acc: 0.5613 - val_loss: 1.4388 - val_acc: 0.3756\n",
      "Epoch 360/3000\n",
      "8s - loss: 1.0824 - acc: 0.5629 - val_loss: 1.4446 - val_acc: 0.3683\n",
      "Epoch 361/3000\n",
      "8s - loss: 1.0937 - acc: 0.5508 - val_loss: 1.4404 - val_acc: 0.3760\n",
      "Epoch 362/3000\n",
      "8s - loss: 1.0722 - acc: 0.5670 - val_loss: 1.4417 - val_acc: 0.3769\n",
      "Epoch 363/3000\n",
      "8s - loss: 1.0695 - acc: 0.5758 - val_loss: 1.4499 - val_acc: 0.3647\n",
      "Epoch 364/3000\n",
      "8s - loss: 1.0763 - acc: 0.5636 - val_loss: 1.4497 - val_acc: 0.3756\n",
      "Epoch 365/3000\n",
      "8s - loss: 1.0821 - acc: 0.5603 - val_loss: 1.4486 - val_acc: 0.3828\n",
      "Epoch 366/3000\n",
      "8s - loss: 1.0830 - acc: 0.5624 - val_loss: 1.4513 - val_acc: 0.3747\n",
      "Epoch 367/3000\n",
      "8s - loss: 1.0891 - acc: 0.5617 - val_loss: 1.4454 - val_acc: 0.3733\n",
      "Epoch 368/3000\n",
      "8s - loss: 1.0733 - acc: 0.5660 - val_loss: 1.4503 - val_acc: 0.3769\n",
      "Epoch 369/3000\n",
      "8s - loss: 1.0730 - acc: 0.5622 - val_loss: 1.4463 - val_acc: 0.3724\n",
      "Epoch 370/3000\n",
      "8s - loss: 1.0812 - acc: 0.5613 - val_loss: 1.4432 - val_acc: 0.3765\n",
      "Epoch 371/3000\n",
      "8s - loss: 1.0696 - acc: 0.5672 - val_loss: 1.4448 - val_acc: 0.3774\n",
      "Epoch 372/3000\n",
      "8s - loss: 1.0917 - acc: 0.5593 - val_loss: 1.4489 - val_acc: 0.3738\n",
      "Epoch 373/3000\n",
      "8s - loss: 1.0658 - acc: 0.5715 - val_loss: 1.4460 - val_acc: 0.3747\n",
      "Epoch 374/3000\n",
      "8s - loss: 1.0771 - acc: 0.5667 - val_loss: 1.4469 - val_acc: 0.3801\n",
      "Epoch 375/3000\n",
      "8s - loss: 1.0728 - acc: 0.5622 - val_loss: 1.4506 - val_acc: 0.3814\n",
      "Epoch 376/3000\n",
      "8s - loss: 1.0692 - acc: 0.5637 - val_loss: 1.4486 - val_acc: 0.3846\n",
      "Epoch 377/3000\n",
      "8s - loss: 1.0980 - acc: 0.5555 - val_loss: 1.4447 - val_acc: 0.3792\n",
      "Epoch 378/3000\n",
      "8s - loss: 1.0768 - acc: 0.5646 - val_loss: 1.4483 - val_acc: 0.3756\n",
      "Epoch 379/3000\n",
      "8s - loss: 1.0688 - acc: 0.5673 - val_loss: 1.4523 - val_acc: 0.3733\n",
      "Epoch 380/3000\n",
      "8s - loss: 1.0778 - acc: 0.5653 - val_loss: 1.4461 - val_acc: 0.3706\n",
      "Epoch 381/3000\n",
      "8s - loss: 1.0823 - acc: 0.5635 - val_loss: 1.4448 - val_acc: 0.3778\n",
      "Epoch 382/3000\n",
      "8s - loss: 1.0722 - acc: 0.5624 - val_loss: 1.4460 - val_acc: 0.3751\n",
      "Epoch 383/3000\n",
      "8s - loss: 1.0706 - acc: 0.5660 - val_loss: 1.4472 - val_acc: 0.3792\n",
      "Epoch 384/3000\n",
      "8s - loss: 1.0725 - acc: 0.5619 - val_loss: 1.4441 - val_acc: 0.3814\n",
      "Epoch 385/3000\n",
      "8s - loss: 1.0691 - acc: 0.5696 - val_loss: 1.4527 - val_acc: 0.3769\n",
      "Epoch 386/3000\n",
      "8s - loss: 1.0784 - acc: 0.5604 - val_loss: 1.4440 - val_acc: 0.3769\n",
      "Epoch 387/3000\n",
      "8s - loss: 1.0778 - acc: 0.5625 - val_loss: 1.4464 - val_acc: 0.3778\n",
      "Epoch 388/3000\n",
      "8s - loss: 1.0674 - acc: 0.5672 - val_loss: 1.4438 - val_acc: 0.3774\n",
      "Epoch 389/3000\n",
      "8s - loss: 1.0744 - acc: 0.5672 - val_loss: 1.4495 - val_acc: 0.3706\n",
      "Epoch 390/3000\n",
      "8s - loss: 1.0776 - acc: 0.5608 - val_loss: 1.4467 - val_acc: 0.3760\n",
      "Epoch 391/3000\n",
      "8s - loss: 1.0629 - acc: 0.5687 - val_loss: 1.4472 - val_acc: 0.3760\n",
      "Epoch 392/3000\n",
      "8s - loss: 1.0731 - acc: 0.5682 - val_loss: 1.4511 - val_acc: 0.3710\n",
      "Epoch 393/3000\n",
      "8s - loss: 1.0731 - acc: 0.5717 - val_loss: 1.4507 - val_acc: 0.3692\n",
      "Epoch 394/3000\n",
      "8s - loss: 1.0727 - acc: 0.5643 - val_loss: 1.4462 - val_acc: 0.3765\n",
      "Epoch 395/3000\n",
      "8s - loss: 1.0638 - acc: 0.5738 - val_loss: 1.4539 - val_acc: 0.3719\n",
      "Epoch 396/3000\n",
      "8s - loss: 1.0519 - acc: 0.5793 - val_loss: 1.4543 - val_acc: 0.3652\n",
      "Epoch 397/3000\n",
      "8s - loss: 1.0653 - acc: 0.5703 - val_loss: 1.4547 - val_acc: 0.3679\n",
      "Epoch 398/3000\n",
      "8s - loss: 1.0640 - acc: 0.5741 - val_loss: 1.4489 - val_acc: 0.3796\n",
      "Epoch 399/3000\n",
      "8s - loss: 1.0680 - acc: 0.5658 - val_loss: 1.4438 - val_acc: 0.3801\n",
      "Epoch 400/3000\n",
      "8s - loss: 1.0756 - acc: 0.5581 - val_loss: 1.4510 - val_acc: 0.3670\n",
      "Epoch 401/3000\n",
      "8s - loss: 1.0679 - acc: 0.5670 - val_loss: 1.4461 - val_acc: 0.3792\n",
      "Epoch 402/3000\n",
      "8s - loss: 1.0668 - acc: 0.5663 - val_loss: 1.4478 - val_acc: 0.3751\n",
      "Epoch 403/3000\n",
      "8s - loss: 1.0687 - acc: 0.5660 - val_loss: 1.4474 - val_acc: 0.3751\n",
      "Epoch 404/3000\n",
      "8s - loss: 1.0626 - acc: 0.5720 - val_loss: 1.4438 - val_acc: 0.3846\n",
      "Epoch 405/3000\n",
      "8s - loss: 1.0786 - acc: 0.5614 - val_loss: 1.4464 - val_acc: 0.3810\n",
      "Epoch 406/3000\n",
      "8s - loss: 1.0574 - acc: 0.5660 - val_loss: 1.4529 - val_acc: 0.3697\n",
      "Epoch 407/3000\n",
      "8s - loss: 1.0813 - acc: 0.5608 - val_loss: 1.4507 - val_acc: 0.3706\n",
      "Epoch 408/3000\n",
      "8s - loss: 1.0564 - acc: 0.5741 - val_loss: 1.4516 - val_acc: 0.3747\n",
      "Epoch 409/3000\n",
      "8s - loss: 1.0513 - acc: 0.5774 - val_loss: 1.4549 - val_acc: 0.3760\n",
      "Epoch 410/3000\n",
      "8s - loss: 1.0598 - acc: 0.5684 - val_loss: 1.4467 - val_acc: 0.3769\n",
      "Epoch 411/3000\n",
      "8s - loss: 1.0720 - acc: 0.5675 - val_loss: 1.4463 - val_acc: 0.3810\n",
      "Epoch 412/3000\n",
      "8s - loss: 1.0655 - acc: 0.5684 - val_loss: 1.4435 - val_acc: 0.3783\n",
      "Epoch 413/3000\n",
      "8s - loss: 1.0464 - acc: 0.5804 - val_loss: 1.4444 - val_acc: 0.3724\n",
      "Epoch 414/3000\n",
      "8s - loss: 1.0598 - acc: 0.5609 - val_loss: 1.4357 - val_acc: 0.3765\n",
      "Epoch 415/3000\n",
      "8s - loss: 1.0609 - acc: 0.5666 - val_loss: 1.4422 - val_acc: 0.3738\n",
      "Epoch 416/3000\n",
      "8s - loss: 1.0626 - acc: 0.5673 - val_loss: 1.4374 - val_acc: 0.3783\n",
      "Epoch 417/3000\n",
      "8s - loss: 1.0599 - acc: 0.5727 - val_loss: 1.4444 - val_acc: 0.3756\n",
      "Epoch 418/3000\n",
      "8s - loss: 1.0494 - acc: 0.5777 - val_loss: 1.4494 - val_acc: 0.3751\n",
      "Epoch 419/3000\n",
      "8s - loss: 1.0707 - acc: 0.5659 - val_loss: 1.4378 - val_acc: 0.3769\n",
      "Epoch 420/3000\n",
      "8s - loss: 1.0676 - acc: 0.5714 - val_loss: 1.4448 - val_acc: 0.3706\n",
      "Epoch 421/3000\n",
      "8s - loss: 1.0658 - acc: 0.5709 - val_loss: 1.4393 - val_acc: 0.3688\n",
      "Epoch 422/3000\n",
      "8s - loss: 1.0691 - acc: 0.5647 - val_loss: 1.4411 - val_acc: 0.3670\n",
      "Epoch 423/3000\n",
      "8s - loss: 1.0614 - acc: 0.5702 - val_loss: 1.4493 - val_acc: 0.3665\n",
      "Epoch 424/3000\n",
      "8s - loss: 1.0568 - acc: 0.5733 - val_loss: 1.4436 - val_acc: 0.3683\n",
      "Epoch 425/3000\n",
      "8s - loss: 1.0586 - acc: 0.5755 - val_loss: 1.4458 - val_acc: 0.3638\n",
      "Epoch 426/3000\n",
      "8s - loss: 1.0597 - acc: 0.5709 - val_loss: 1.4479 - val_acc: 0.3674\n",
      "Epoch 427/3000\n",
      "8s - loss: 1.0601 - acc: 0.5728 - val_loss: 1.4438 - val_acc: 0.3692\n",
      "Epoch 428/3000\n",
      "8s - loss: 1.0456 - acc: 0.5782 - val_loss: 1.4435 - val_acc: 0.3719\n",
      "Epoch 429/3000\n",
      "8s - loss: 1.0481 - acc: 0.5803 - val_loss: 1.4392 - val_acc: 0.3647\n",
      "Epoch 430/3000\n",
      "8s - loss: 1.0626 - acc: 0.5691 - val_loss: 1.4460 - val_acc: 0.3674\n",
      "Epoch 431/3000\n",
      "8s - loss: 1.0665 - acc: 0.5671 - val_loss: 1.4442 - val_acc: 0.3679\n",
      "Epoch 432/3000\n",
      "8s - loss: 1.0592 - acc: 0.5673 - val_loss: 1.4532 - val_acc: 0.3765\n",
      "Epoch 433/3000\n",
      "8s - loss: 1.0605 - acc: 0.5768 - val_loss: 1.4482 - val_acc: 0.3697\n",
      "Epoch 434/3000\n",
      "8s - loss: 1.0563 - acc: 0.5733 - val_loss: 1.4453 - val_acc: 0.3747\n",
      "Epoch 435/3000\n",
      "8s - loss: 1.0578 - acc: 0.5696 - val_loss: 1.4490 - val_acc: 0.3738\n",
      "Epoch 436/3000\n",
      "8s - loss: 1.0485 - acc: 0.5727 - val_loss: 1.4393 - val_acc: 0.3701\n",
      "Epoch 437/3000\n",
      "8s - loss: 1.0480 - acc: 0.5744 - val_loss: 1.4411 - val_acc: 0.3706\n",
      "Epoch 438/3000\n",
      "8s - loss: 1.0582 - acc: 0.5775 - val_loss: 1.4446 - val_acc: 0.3774\n",
      "Epoch 439/3000\n",
      "8s - loss: 1.0570 - acc: 0.5744 - val_loss: 1.4360 - val_acc: 0.3751\n",
      "Epoch 440/3000\n",
      "8s - loss: 1.0606 - acc: 0.5689 - val_loss: 1.4391 - val_acc: 0.3751\n",
      "Epoch 441/3000\n",
      "8s - loss: 1.0431 - acc: 0.5785 - val_loss: 1.4451 - val_acc: 0.3719\n",
      "Epoch 442/3000\n",
      "8s - loss: 1.0588 - acc: 0.5707 - val_loss: 1.4401 - val_acc: 0.3756\n",
      "Epoch 443/3000\n",
      "8s - loss: 1.0509 - acc: 0.5833 - val_loss: 1.4480 - val_acc: 0.3738\n",
      "Epoch 444/3000\n",
      "8s - loss: 1.0498 - acc: 0.5760 - val_loss: 1.4393 - val_acc: 0.3747\n",
      "Epoch 445/3000\n",
      "8s - loss: 1.0523 - acc: 0.5752 - val_loss: 1.4425 - val_acc: 0.3774\n",
      "Epoch 446/3000\n",
      "8s - loss: 1.0566 - acc: 0.5750 - val_loss: 1.4431 - val_acc: 0.3751\n",
      "Epoch 447/3000\n",
      "8s - loss: 1.0410 - acc: 0.5870 - val_loss: 1.4338 - val_acc: 0.3801\n",
      "Epoch 448/3000\n",
      "8s - loss: 1.0681 - acc: 0.5631 - val_loss: 1.4402 - val_acc: 0.3828\n",
      "Epoch 449/3000\n",
      "8s - loss: 1.0651 - acc: 0.5715 - val_loss: 1.4392 - val_acc: 0.3869\n",
      "Epoch 450/3000\n",
      "8s - loss: 1.0600 - acc: 0.5734 - val_loss: 1.4454 - val_acc: 0.3787\n",
      "Epoch 451/3000\n",
      "8s - loss: 1.0477 - acc: 0.5756 - val_loss: 1.4525 - val_acc: 0.3760\n",
      "Epoch 452/3000\n",
      "8s - loss: 1.0592 - acc: 0.5722 - val_loss: 1.4389 - val_acc: 0.3783\n",
      "Epoch 453/3000\n",
      "8s - loss: 1.0474 - acc: 0.5788 - val_loss: 1.4440 - val_acc: 0.3864\n",
      "Epoch 454/3000\n",
      "8s - loss: 1.0454 - acc: 0.5784 - val_loss: 1.4366 - val_acc: 0.3796\n",
      "Epoch 455/3000\n",
      "8s - loss: 1.0483 - acc: 0.5802 - val_loss: 1.4487 - val_acc: 0.3792\n",
      "Epoch 456/3000\n",
      "8s - loss: 1.0422 - acc: 0.5795 - val_loss: 1.4481 - val_acc: 0.3760\n",
      "Epoch 457/3000\n",
      "8s - loss: 1.0531 - acc: 0.5765 - val_loss: 1.4391 - val_acc: 0.3715\n",
      "Epoch 458/3000\n",
      "8s - loss: 1.0578 - acc: 0.5717 - val_loss: 1.4431 - val_acc: 0.3710\n",
      "Epoch 459/3000\n",
      "8s - loss: 1.0452 - acc: 0.5783 - val_loss: 1.4413 - val_acc: 0.3738\n",
      "Epoch 460/3000\n",
      "8s - loss: 1.0592 - acc: 0.5759 - val_loss: 1.4416 - val_acc: 0.3670\n",
      "Epoch 461/3000\n",
      "8s - loss: 1.0601 - acc: 0.5712 - val_loss: 1.4327 - val_acc: 0.3756\n",
      "Epoch 462/3000\n",
      "8s - loss: 1.0476 - acc: 0.5778 - val_loss: 1.4386 - val_acc: 0.3738\n",
      "Epoch 463/3000\n",
      "8s - loss: 1.0264 - acc: 0.5844 - val_loss: 1.4481 - val_acc: 0.3724\n",
      "Epoch 464/3000\n",
      "8s - loss: 1.0454 - acc: 0.5807 - val_loss: 1.4450 - val_acc: 0.3710\n",
      "Epoch 465/3000\n",
      "8s - loss: 1.0425 - acc: 0.5781 - val_loss: 1.4387 - val_acc: 0.3819\n",
      "Epoch 466/3000\n",
      "8s - loss: 1.0500 - acc: 0.5834 - val_loss: 1.4430 - val_acc: 0.3733\n",
      "Epoch 467/3000\n",
      "8s - loss: 1.0514 - acc: 0.5757 - val_loss: 1.4441 - val_acc: 0.3710\n",
      "Epoch 468/3000\n",
      "8s - loss: 1.0544 - acc: 0.5760 - val_loss: 1.4437 - val_acc: 0.3661\n",
      "Epoch 469/3000\n",
      "8s - loss: 1.0306 - acc: 0.5847 - val_loss: 1.4463 - val_acc: 0.3715\n",
      "Epoch 470/3000\n",
      "8s - loss: 1.0484 - acc: 0.5793 - val_loss: 1.4391 - val_acc: 0.3692\n",
      "Epoch 471/3000\n",
      "8s - loss: 1.0492 - acc: 0.5794 - val_loss: 1.4524 - val_acc: 0.3738\n",
      "Epoch 472/3000\n",
      "8s - loss: 1.0412 - acc: 0.5850 - val_loss: 1.4377 - val_acc: 0.3760\n",
      "Epoch 473/3000\n",
      "8s - loss: 1.0471 - acc: 0.5795 - val_loss: 1.4436 - val_acc: 0.3747\n",
      "Epoch 474/3000\n",
      "8s - loss: 1.0414 - acc: 0.5822 - val_loss: 1.4443 - val_acc: 0.3683\n",
      "Epoch 475/3000\n",
      "8s - loss: 1.0388 - acc: 0.5853 - val_loss: 1.4372 - val_acc: 0.3683\n",
      "Epoch 476/3000\n",
      "8s - loss: 1.0467 - acc: 0.5818 - val_loss: 1.4360 - val_acc: 0.3774\n",
      "Epoch 477/3000\n",
      "8s - loss: 1.0607 - acc: 0.5781 - val_loss: 1.4370 - val_acc: 0.3792\n",
      "Epoch 478/3000\n",
      "8s - loss: 1.0590 - acc: 0.5745 - val_loss: 1.4467 - val_acc: 0.3765\n",
      "Epoch 479/3000\n",
      "8s - loss: 1.0465 - acc: 0.5771 - val_loss: 1.4465 - val_acc: 0.3719\n",
      "Epoch 480/3000\n",
      "8s - loss: 1.0596 - acc: 0.5695 - val_loss: 1.4386 - val_acc: 0.3778\n",
      "Epoch 481/3000\n",
      "8s - loss: 1.0379 - acc: 0.5813 - val_loss: 1.4457 - val_acc: 0.3760\n",
      "Epoch 482/3000\n",
      "8s - loss: 1.0326 - acc: 0.5899 - val_loss: 1.4441 - val_acc: 0.3769\n",
      "Epoch 483/3000\n",
      "8s - loss: 1.0250 - acc: 0.5878 - val_loss: 1.4416 - val_acc: 0.3801\n",
      "Epoch 484/3000\n",
      "8s - loss: 1.0415 - acc: 0.5839 - val_loss: 1.4383 - val_acc: 0.3778\n",
      "Epoch 485/3000\n",
      "8s - loss: 1.0310 - acc: 0.5911 - val_loss: 1.4373 - val_acc: 0.3738\n",
      "Epoch 486/3000\n",
      "8s - loss: 1.0493 - acc: 0.5754 - val_loss: 1.4400 - val_acc: 0.3733\n",
      "Epoch 487/3000\n",
      "8s - loss: 1.0465 - acc: 0.5772 - val_loss: 1.4433 - val_acc: 0.3692\n",
      "Epoch 488/3000\n",
      "8s - loss: 1.0293 - acc: 0.5895 - val_loss: 1.4366 - val_acc: 0.3692\n",
      "Epoch 489/3000\n",
      "8s - loss: 1.0334 - acc: 0.5837 - val_loss: 1.4438 - val_acc: 0.3710\n",
      "Epoch 490/3000\n",
      "8s - loss: 1.0490 - acc: 0.5792 - val_loss: 1.4461 - val_acc: 0.3742\n",
      "Epoch 491/3000\n",
      "8s - loss: 1.0498 - acc: 0.5768 - val_loss: 1.4357 - val_acc: 0.3706\n",
      "Epoch 492/3000\n",
      "8s - loss: 1.0277 - acc: 0.5897 - val_loss: 1.4539 - val_acc: 0.3647\n",
      "Epoch 493/3000\n",
      "8s - loss: 1.0291 - acc: 0.5914 - val_loss: 1.4478 - val_acc: 0.3670\n",
      "Epoch 494/3000\n",
      "8s - loss: 1.0306 - acc: 0.5898 - val_loss: 1.4475 - val_acc: 0.3647\n",
      "Epoch 495/3000\n",
      "8s - loss: 1.0307 - acc: 0.5840 - val_loss: 1.4472 - val_acc: 0.3661\n",
      "Epoch 496/3000\n",
      "8s - loss: 1.0504 - acc: 0.5748 - val_loss: 1.4463 - val_acc: 0.3701\n",
      "Epoch 497/3000\n",
      "8s - loss: 1.0462 - acc: 0.5822 - val_loss: 1.4433 - val_acc: 0.3652\n",
      "Epoch 498/3000\n",
      "8s - loss: 1.0501 - acc: 0.5768 - val_loss: 1.4458 - val_acc: 0.3692\n",
      "Epoch 499/3000\n",
      "8s - loss: 1.0519 - acc: 0.5750 - val_loss: 1.4421 - val_acc: 0.3688\n",
      "Epoch 500/3000\n",
      "8s - loss: 1.0450 - acc: 0.5882 - val_loss: 1.4440 - val_acc: 0.3665\n",
      "Epoch 501/3000\n",
      "8s - loss: 1.0448 - acc: 0.5806 - val_loss: 1.4506 - val_acc: 0.3656\n",
      "Epoch 502/3000\n",
      "8s - loss: 1.0308 - acc: 0.5846 - val_loss: 1.4525 - val_acc: 0.3701\n",
      "Epoch 503/3000\n",
      "8s - loss: 1.0463 - acc: 0.5785 - val_loss: 1.4454 - val_acc: 0.3719\n",
      "Epoch 504/3000\n",
      "8s - loss: 1.0391 - acc: 0.5821 - val_loss: 1.4484 - val_acc: 0.3778\n",
      "Epoch 505/3000\n",
      "8s - loss: 1.0541 - acc: 0.5777 - val_loss: 1.4389 - val_acc: 0.3729\n",
      "Epoch 506/3000\n",
      "8s - loss: 1.0475 - acc: 0.5779 - val_loss: 1.4497 - val_acc: 0.3624\n",
      "Epoch 507/3000\n",
      "8s - loss: 1.0256 - acc: 0.5898 - val_loss: 1.4429 - val_acc: 0.3760\n",
      "Epoch 508/3000\n",
      "8s - loss: 1.0340 - acc: 0.5844 - val_loss: 1.4473 - val_acc: 0.3647\n",
      "Epoch 509/3000\n",
      "8s - loss: 1.0312 - acc: 0.5850 - val_loss: 1.4512 - val_acc: 0.3661\n",
      "Epoch 510/3000\n",
      "8s - loss: 1.0251 - acc: 0.5885 - val_loss: 1.4452 - val_acc: 0.3692\n",
      "Epoch 511/3000\n",
      "8s - loss: 1.0345 - acc: 0.5788 - val_loss: 1.4475 - val_acc: 0.3692\n",
      "Epoch 512/3000\n",
      "8s - loss: 1.0431 - acc: 0.5829 - val_loss: 1.4501 - val_acc: 0.3701\n",
      "Epoch 513/3000\n",
      "8s - loss: 1.0374 - acc: 0.5892 - val_loss: 1.4427 - val_acc: 0.3683\n",
      "Epoch 514/3000\n",
      "8s - loss: 1.0439 - acc: 0.5794 - val_loss: 1.4376 - val_acc: 0.3724\n",
      "Epoch 515/3000\n",
      "8s - loss: 1.0402 - acc: 0.5819 - val_loss: 1.4515 - val_acc: 0.3647\n",
      "Epoch 516/3000\n",
      "8s - loss: 1.0374 - acc: 0.5880 - val_loss: 1.4404 - val_acc: 0.3715\n",
      "Epoch 517/3000\n",
      "8s - loss: 1.0193 - acc: 0.5908 - val_loss: 1.4509 - val_acc: 0.3647\n",
      "Epoch 518/3000\n",
      "8s - loss: 1.0302 - acc: 0.5863 - val_loss: 1.4436 - val_acc: 0.3742\n",
      "Epoch 519/3000\n",
      "8s - loss: 1.0372 - acc: 0.5830 - val_loss: 1.4413 - val_acc: 0.3747\n",
      "Epoch 520/3000\n",
      "8s - loss: 1.0261 - acc: 0.5855 - val_loss: 1.4485 - val_acc: 0.3602\n",
      "Epoch 521/3000\n",
      "8s - loss: 1.0270 - acc: 0.5880 - val_loss: 1.4554 - val_acc: 0.3656\n",
      "Epoch 522/3000\n",
      "8s - loss: 1.0301 - acc: 0.5938 - val_loss: 1.4526 - val_acc: 0.3629\n",
      "Epoch 523/3000\n",
      "8s - loss: 1.0352 - acc: 0.5875 - val_loss: 1.4414 - val_acc: 0.3697\n",
      "Epoch 524/3000\n",
      "8s - loss: 1.0548 - acc: 0.5743 - val_loss: 1.4537 - val_acc: 0.3656\n",
      "Epoch 525/3000\n",
      "8s - loss: 1.0321 - acc: 0.5832 - val_loss: 1.4502 - val_acc: 0.3633\n",
      "Epoch 526/3000\n",
      "8s - loss: 1.0335 - acc: 0.5824 - val_loss: 1.4371 - val_acc: 0.3719\n",
      "Epoch 527/3000\n",
      "8s - loss: 1.0292 - acc: 0.5847 - val_loss: 1.4513 - val_acc: 0.3647\n",
      "Epoch 528/3000\n",
      "8s - loss: 1.0376 - acc: 0.5849 - val_loss: 1.4351 - val_acc: 0.3701\n",
      "Epoch 529/3000\n",
      "8s - loss: 1.0503 - acc: 0.5851 - val_loss: 1.4418 - val_acc: 0.3710\n",
      "Epoch 530/3000\n",
      "8s - loss: 1.0363 - acc: 0.5790 - val_loss: 1.4433 - val_acc: 0.3665\n",
      "Epoch 531/3000\n",
      "8s - loss: 1.0320 - acc: 0.5790 - val_loss: 1.4493 - val_acc: 0.3643\n",
      "Epoch 532/3000\n",
      "8s - loss: 1.0332 - acc: 0.5855 - val_loss: 1.4482 - val_acc: 0.3679\n",
      "Epoch 533/3000\n",
      "8s - loss: 1.0473 - acc: 0.5785 - val_loss: 1.4407 - val_acc: 0.3760\n",
      "Epoch 534/3000\n",
      "8s - loss: 1.0225 - acc: 0.5918 - val_loss: 1.4389 - val_acc: 0.3697\n",
      "Epoch 535/3000\n",
      "8s - loss: 1.0354 - acc: 0.5827 - val_loss: 1.4515 - val_acc: 0.3719\n",
      "Epoch 536/3000\n",
      "8s - loss: 1.0339 - acc: 0.5840 - val_loss: 1.4445 - val_acc: 0.3756\n",
      "Epoch 537/3000\n",
      "8s - loss: 1.0264 - acc: 0.5905 - val_loss: 1.4430 - val_acc: 0.3783\n",
      "Epoch 538/3000\n",
      "8s - loss: 1.0192 - acc: 0.5944 - val_loss: 1.4332 - val_acc: 0.3760\n",
      "Epoch 539/3000\n",
      "8s - loss: 1.0273 - acc: 0.5912 - val_loss: 1.4420 - val_acc: 0.3697\n",
      "Epoch 540/3000\n",
      "8s - loss: 1.0140 - acc: 0.5935 - val_loss: 1.4416 - val_acc: 0.3738\n",
      "Epoch 541/3000\n",
      "8s - loss: 1.0295 - acc: 0.5862 - val_loss: 1.4503 - val_acc: 0.3661\n",
      "Epoch 542/3000\n",
      "8s - loss: 1.0396 - acc: 0.5836 - val_loss: 1.4374 - val_acc: 0.3756\n",
      "Epoch 543/3000\n",
      "8s - loss: 1.0322 - acc: 0.5840 - val_loss: 1.4430 - val_acc: 0.3715\n",
      "Epoch 544/3000\n",
      "8s - loss: 1.0358 - acc: 0.5806 - val_loss: 1.4493 - val_acc: 0.3706\n",
      "Epoch 545/3000\n",
      "8s - loss: 1.0191 - acc: 0.5904 - val_loss: 1.4412 - val_acc: 0.3706\n",
      "Epoch 546/3000\n",
      "8s - loss: 1.0284 - acc: 0.5908 - val_loss: 1.4366 - val_acc: 0.3733\n",
      "Epoch 547/3000\n",
      "8s - loss: 1.0231 - acc: 0.5934 - val_loss: 1.4421 - val_acc: 0.3688\n",
      "Epoch 548/3000\n",
      "8s - loss: 1.0280 - acc: 0.5834 - val_loss: 1.4502 - val_acc: 0.3710\n",
      "Epoch 549/3000\n",
      "8s - loss: 1.0306 - acc: 0.5923 - val_loss: 1.4467 - val_acc: 0.3674\n",
      "Epoch 550/3000\n",
      "8s - loss: 1.0318 - acc: 0.5915 - val_loss: 1.4430 - val_acc: 0.3697\n",
      "Epoch 551/3000\n",
      "8s - loss: 1.0253 - acc: 0.5928 - val_loss: 1.4395 - val_acc: 0.3778\n",
      "Epoch 552/3000\n",
      "8s - loss: 1.0221 - acc: 0.5883 - val_loss: 1.4346 - val_acc: 0.3742\n",
      "Epoch 553/3000\n",
      "8s - loss: 1.0254 - acc: 0.5881 - val_loss: 1.4455 - val_acc: 0.3697\n",
      "Epoch 554/3000\n",
      "8s - loss: 1.0322 - acc: 0.5897 - val_loss: 1.4446 - val_acc: 0.3801\n",
      "Epoch 555/3000\n",
      "8s - loss: 1.0215 - acc: 0.5954 - val_loss: 1.4462 - val_acc: 0.3701\n",
      "Epoch 556/3000\n",
      "8s - loss: 1.0294 - acc: 0.5964 - val_loss: 1.4334 - val_acc: 0.3756\n",
      "Epoch 557/3000\n",
      "8s - loss: 1.0167 - acc: 0.5900 - val_loss: 1.4398 - val_acc: 0.3724\n",
      "Epoch 558/3000\n",
      "8s - loss: 1.0322 - acc: 0.5856 - val_loss: 1.4421 - val_acc: 0.3742\n",
      "Epoch 559/3000\n",
      "8s - loss: 1.0139 - acc: 0.5982 - val_loss: 1.4429 - val_acc: 0.3697\n",
      "Epoch 560/3000\n",
      "8s - loss: 1.0289 - acc: 0.5853 - val_loss: 1.4464 - val_acc: 0.3701\n",
      "Epoch 561/3000\n",
      "8s - loss: 1.0240 - acc: 0.5861 - val_loss: 1.4447 - val_acc: 0.3688\n",
      "Epoch 562/3000\n",
      "8s - loss: 1.0201 - acc: 0.5857 - val_loss: 1.4427 - val_acc: 0.3747\n",
      "Epoch 563/3000\n",
      "8s - loss: 1.0333 - acc: 0.5833 - val_loss: 1.4406 - val_acc: 0.3715\n",
      "Epoch 564/3000\n",
      "8s - loss: 1.0184 - acc: 0.5899 - val_loss: 1.4481 - val_acc: 0.3652\n",
      "Epoch 565/3000\n",
      "8s - loss: 1.0314 - acc: 0.5856 - val_loss: 1.4442 - val_acc: 0.3692\n",
      "Epoch 566/3000\n",
      "8s - loss: 1.0261 - acc: 0.5883 - val_loss: 1.4454 - val_acc: 0.3719\n",
      "Epoch 567/3000\n",
      "8s - loss: 1.0151 - acc: 0.5965 - val_loss: 1.4450 - val_acc: 0.3692\n",
      "Epoch 568/3000\n",
      "8s - loss: 1.0260 - acc: 0.5909 - val_loss: 1.4376 - val_acc: 0.3674\n",
      "Epoch 569/3000\n",
      "8s - loss: 1.0102 - acc: 0.5974 - val_loss: 1.4388 - val_acc: 0.3715\n",
      "Epoch 570/3000\n",
      "8s - loss: 1.0150 - acc: 0.5971 - val_loss: 1.4471 - val_acc: 0.3683\n",
      "Epoch 571/3000\n",
      "8s - loss: 1.0243 - acc: 0.5892 - val_loss: 1.4393 - val_acc: 0.3701\n",
      "Epoch 572/3000\n",
      "8s - loss: 1.0241 - acc: 0.5913 - val_loss: 1.4427 - val_acc: 0.3747\n",
      "Epoch 573/3000\n",
      "8s - loss: 1.0185 - acc: 0.5939 - val_loss: 1.4484 - val_acc: 0.3629\n",
      "Epoch 574/3000\n",
      "8s - loss: 1.0164 - acc: 0.5941 - val_loss: 1.4450 - val_acc: 0.3638\n",
      "Epoch 575/3000\n",
      "8s - loss: 1.0127 - acc: 0.5954 - val_loss: 1.4433 - val_acc: 0.3706\n",
      "Epoch 576/3000\n",
      "8s - loss: 1.0208 - acc: 0.5904 - val_loss: 1.4389 - val_acc: 0.3724\n",
      "Epoch 577/3000\n",
      "8s - loss: 1.0110 - acc: 0.6016 - val_loss: 1.4520 - val_acc: 0.3692\n",
      "Epoch 578/3000\n",
      "8s - loss: 1.0246 - acc: 0.5891 - val_loss: 1.4471 - val_acc: 0.3683\n",
      "Epoch 579/3000\n",
      "8s - loss: 1.0157 - acc: 0.5954 - val_loss: 1.4497 - val_acc: 0.3683\n",
      "Epoch 580/3000\n",
      "8s - loss: 1.0258 - acc: 0.5973 - val_loss: 1.4486 - val_acc: 0.3724\n",
      "Epoch 581/3000\n",
      "8s - loss: 1.0292 - acc: 0.5904 - val_loss: 1.4383 - val_acc: 0.3801\n",
      "Epoch 582/3000\n",
      "8s - loss: 1.0100 - acc: 0.5983 - val_loss: 1.4499 - val_acc: 0.3769\n",
      "Epoch 583/3000\n",
      "8s - loss: 1.0145 - acc: 0.5925 - val_loss: 1.4454 - val_acc: 0.3760\n",
      "Epoch 584/3000\n",
      "8s - loss: 1.0240 - acc: 0.5874 - val_loss: 1.4413 - val_acc: 0.3760\n",
      "Epoch 585/3000\n",
      "8s - loss: 1.0155 - acc: 0.5927 - val_loss: 1.4422 - val_acc: 0.3828\n",
      "Epoch 586/3000\n",
      "8s - loss: 1.0143 - acc: 0.5941 - val_loss: 1.4443 - val_acc: 0.3738\n",
      "Epoch 587/3000\n",
      "8s - loss: 1.0220 - acc: 0.5943 - val_loss: 1.4483 - val_acc: 0.3787\n",
      "Epoch 588/3000\n",
      "8s - loss: 1.0227 - acc: 0.5949 - val_loss: 1.4407 - val_acc: 0.3733\n",
      "Epoch 589/3000\n",
      "8s - loss: 1.0272 - acc: 0.5908 - val_loss: 1.4482 - val_acc: 0.3796\n",
      "Epoch 590/3000\n",
      "8s - loss: 1.0206 - acc: 0.5952 - val_loss: 1.4471 - val_acc: 0.3729\n",
      "Epoch 591/3000\n",
      "8s - loss: 1.0282 - acc: 0.5863 - val_loss: 1.4419 - val_acc: 0.3724\n",
      "Epoch 592/3000\n",
      "8s - loss: 1.0104 - acc: 0.5925 - val_loss: 1.4527 - val_acc: 0.3724\n",
      "Epoch 593/3000\n",
      "8s - loss: 1.0188 - acc: 0.5948 - val_loss: 1.4520 - val_acc: 0.3706\n",
      "Epoch 594/3000\n",
      "8s - loss: 1.0210 - acc: 0.5951 - val_loss: 1.4443 - val_acc: 0.3719\n",
      "Epoch 595/3000\n",
      "8s - loss: 1.0271 - acc: 0.5922 - val_loss: 1.4365 - val_acc: 0.3783\n",
      "Epoch 596/3000\n",
      "8s - loss: 1.0178 - acc: 0.5969 - val_loss: 1.4423 - val_acc: 0.3751\n",
      "Epoch 597/3000\n",
      "8s - loss: 1.0240 - acc: 0.5896 - val_loss: 1.4532 - val_acc: 0.3683\n",
      "Epoch 598/3000\n",
      "8s - loss: 1.0218 - acc: 0.5886 - val_loss: 1.4459 - val_acc: 0.3688\n",
      "Epoch 599/3000\n",
      "8s - loss: 1.0173 - acc: 0.5937 - val_loss: 1.4519 - val_acc: 0.3697\n",
      "Epoch 600/3000\n",
      "8s - loss: 1.0196 - acc: 0.5879 - val_loss: 1.4472 - val_acc: 0.3715\n",
      "Epoch 601/3000\n",
      "8s - loss: 1.0167 - acc: 0.5952 - val_loss: 1.4452 - val_acc: 0.3742\n",
      "Epoch 602/3000\n",
      "8s - loss: 1.0124 - acc: 0.5921 - val_loss: 1.4568 - val_acc: 0.3679\n",
      "Epoch 603/3000\n",
      "8s - loss: 1.0172 - acc: 0.5968 - val_loss: 1.4545 - val_acc: 0.3674\n",
      "Epoch 604/3000\n",
      "8s - loss: 1.0226 - acc: 0.5944 - val_loss: 1.4528 - val_acc: 0.3683\n",
      "Epoch 605/3000\n",
      "8s - loss: 1.0176 - acc: 0.5961 - val_loss: 1.4483 - val_acc: 0.3692\n",
      "Epoch 606/3000\n",
      "8s - loss: 1.0103 - acc: 0.5987 - val_loss: 1.4516 - val_acc: 0.3697\n",
      "Epoch 607/3000\n",
      "8s - loss: 1.0156 - acc: 0.5924 - val_loss: 1.4658 - val_acc: 0.3697\n",
      "Epoch 608/3000\n",
      "8s - loss: 1.0235 - acc: 0.5943 - val_loss: 1.4460 - val_acc: 0.3706\n",
      "Epoch 609/3000\n",
      "8s - loss: 1.0186 - acc: 0.5905 - val_loss: 1.4570 - val_acc: 0.3688\n",
      "Epoch 610/3000\n",
      "8s - loss: 1.0125 - acc: 0.5929 - val_loss: 1.4472 - val_acc: 0.3633\n",
      "Epoch 611/3000\n",
      "8s - loss: 1.0331 - acc: 0.5888 - val_loss: 1.4408 - val_acc: 0.3756\n",
      "Epoch 612/3000\n",
      "8s - loss: 1.0210 - acc: 0.5924 - val_loss: 1.4464 - val_acc: 0.3814\n",
      "Epoch 613/3000\n",
      "8s - loss: 1.0355 - acc: 0.5919 - val_loss: 1.4413 - val_acc: 0.3747\n",
      "Epoch 614/3000\n",
      "8s - loss: 1.0234 - acc: 0.5881 - val_loss: 1.4400 - val_acc: 0.3742\n",
      "Epoch 615/3000\n",
      "8s - loss: 1.0189 - acc: 0.5935 - val_loss: 1.4468 - val_acc: 0.3710\n",
      "Epoch 616/3000\n",
      "8s - loss: 1.0137 - acc: 0.5925 - val_loss: 1.4381 - val_acc: 0.3724\n",
      "Epoch 617/3000\n",
      "8s - loss: 1.0255 - acc: 0.5870 - val_loss: 1.4421 - val_acc: 0.3647\n",
      "Epoch 618/3000\n",
      "8s - loss: 1.0203 - acc: 0.5909 - val_loss: 1.4449 - val_acc: 0.3719\n",
      "Epoch 619/3000\n",
      "8s - loss: 1.0103 - acc: 0.6003 - val_loss: 1.4417 - val_acc: 0.3710\n",
      "Epoch 620/3000\n",
      "8s - loss: 0.9986 - acc: 0.6032 - val_loss: 1.4536 - val_acc: 0.3697\n",
      "Epoch 621/3000\n",
      "8s - loss: 1.0090 - acc: 0.6028 - val_loss: 1.4466 - val_acc: 0.3710\n",
      "Epoch 622/3000\n",
      "8s - loss: 1.0044 - acc: 0.6017 - val_loss: 1.4526 - val_acc: 0.3656\n",
      "Epoch 623/3000\n",
      "8s - loss: 1.0293 - acc: 0.5898 - val_loss: 1.4445 - val_acc: 0.3688\n",
      "Epoch 624/3000\n",
      "8s - loss: 1.0142 - acc: 0.5976 - val_loss: 1.4468 - val_acc: 0.3688\n",
      "Epoch 625/3000\n",
      "8s - loss: 1.0124 - acc: 0.5938 - val_loss: 1.4505 - val_acc: 0.3724\n",
      "Epoch 626/3000\n",
      "8s - loss: 1.0213 - acc: 0.5949 - val_loss: 1.4471 - val_acc: 0.3674\n",
      "Epoch 627/3000\n",
      "8s - loss: 1.0024 - acc: 0.6033 - val_loss: 1.4433 - val_acc: 0.3656\n",
      "Epoch 628/3000\n",
      "8s - loss: 1.0141 - acc: 0.5988 - val_loss: 1.4465 - val_acc: 0.3692\n",
      "Epoch 629/3000\n",
      "8s - loss: 1.0166 - acc: 0.6004 - val_loss: 1.4409 - val_acc: 0.3633\n",
      "Epoch 630/3000\n",
      "8s - loss: 1.0136 - acc: 0.5949 - val_loss: 1.4502 - val_acc: 0.3670\n",
      "Epoch 631/3000\n",
      "8s - loss: 1.0155 - acc: 0.5968 - val_loss: 1.4450 - val_acc: 0.3715\n",
      "Epoch 632/3000\n",
      "8s - loss: 1.0278 - acc: 0.5899 - val_loss: 1.4420 - val_acc: 0.3670\n",
      "Epoch 633/3000\n",
      "8s - loss: 1.0036 - acc: 0.6034 - val_loss: 1.4467 - val_acc: 0.3679\n",
      "Epoch 634/3000\n",
      "8s - loss: 1.0065 - acc: 0.5976 - val_loss: 1.4424 - val_acc: 0.3724\n",
      "Epoch 635/3000\n",
      "8s - loss: 1.0089 - acc: 0.5976 - val_loss: 1.4403 - val_acc: 0.3783\n",
      "Epoch 636/3000\n",
      "8s - loss: 1.0054 - acc: 0.5976 - val_loss: 1.4466 - val_acc: 0.3729\n",
      "Epoch 637/3000\n",
      "8s - loss: 1.0108 - acc: 0.5977 - val_loss: 1.4414 - val_acc: 0.3729\n",
      "Epoch 638/3000\n",
      "8s - loss: 1.0150 - acc: 0.5946 - val_loss: 1.4468 - val_acc: 0.3683\n",
      "Epoch 639/3000\n",
      "8s - loss: 1.0093 - acc: 0.5948 - val_loss: 1.4427 - val_acc: 0.3715\n",
      "Epoch 640/3000\n",
      "8s - loss: 1.0144 - acc: 0.5952 - val_loss: 1.4455 - val_acc: 0.3719\n",
      "Epoch 641/3000\n",
      "8s - loss: 1.0106 - acc: 0.6020 - val_loss: 1.4360 - val_acc: 0.3774\n",
      "Epoch 642/3000\n",
      "8s - loss: 1.0118 - acc: 0.5926 - val_loss: 1.4455 - val_acc: 0.3729\n",
      "Epoch 643/3000\n",
      "8s - loss: 1.0059 - acc: 0.5991 - val_loss: 1.4414 - val_acc: 0.3760\n",
      "Epoch 644/3000\n",
      "8s - loss: 1.0147 - acc: 0.5961 - val_loss: 1.4447 - val_acc: 0.3706\n",
      "Epoch 645/3000\n",
      "8s - loss: 1.0005 - acc: 0.6019 - val_loss: 1.4425 - val_acc: 0.3715\n",
      "Epoch 646/3000\n",
      "8s - loss: 1.0165 - acc: 0.5899 - val_loss: 1.4529 - val_acc: 0.3751\n",
      "Epoch 647/3000\n",
      "8s - loss: 1.0288 - acc: 0.5865 - val_loss: 1.4439 - val_acc: 0.3715\n",
      "Epoch 648/3000\n",
      "8s - loss: 1.0122 - acc: 0.5949 - val_loss: 1.4438 - val_acc: 0.3792\n",
      "Epoch 649/3000\n",
      "8s - loss: 1.0171 - acc: 0.5903 - val_loss: 1.4436 - val_acc: 0.3738\n",
      "Epoch 650/3000\n",
      "8s - loss: 1.0182 - acc: 0.5922 - val_loss: 1.4393 - val_acc: 0.3715\n",
      "Epoch 651/3000\n",
      "8s - loss: 0.9973 - acc: 0.6091 - val_loss: 1.4486 - val_acc: 0.3724\n",
      "Epoch 652/3000\n",
      "8s - loss: 1.0075 - acc: 0.5993 - val_loss: 1.4505 - val_acc: 0.3688\n",
      "Epoch 653/3000\n",
      "8s - loss: 1.0116 - acc: 0.6003 - val_loss: 1.4409 - val_acc: 0.3738\n",
      "Epoch 654/3000\n",
      "8s - loss: 1.0076 - acc: 0.6057 - val_loss: 1.4467 - val_acc: 0.3697\n",
      "Epoch 655/3000\n",
      "8s - loss: 0.9985 - acc: 0.6017 - val_loss: 1.4445 - val_acc: 0.3756\n",
      "Epoch 656/3000\n",
      "8s - loss: 1.0093 - acc: 0.5922 - val_loss: 1.4406 - val_acc: 0.3769\n",
      "Epoch 657/3000\n",
      "8s - loss: 1.0067 - acc: 0.5999 - val_loss: 1.4465 - val_acc: 0.3769\n",
      "Epoch 658/3000\n",
      "8s - loss: 1.0077 - acc: 0.5952 - val_loss: 1.4470 - val_acc: 0.3819\n",
      "Epoch 659/3000\n",
      "8s - loss: 1.0200 - acc: 0.5900 - val_loss: 1.4383 - val_acc: 0.3801\n",
      "Epoch 660/3000\n",
      "8s - loss: 1.0122 - acc: 0.5984 - val_loss: 1.4505 - val_acc: 0.3742\n",
      "Epoch 661/3000\n",
      "8s - loss: 1.0211 - acc: 0.5923 - val_loss: 1.4401 - val_acc: 0.3860\n",
      "Epoch 662/3000\n",
      "8s - loss: 1.0145 - acc: 0.5875 - val_loss: 1.4505 - val_acc: 0.3760\n",
      "Epoch 663/3000\n",
      "8s - loss: 1.0210 - acc: 0.5951 - val_loss: 1.4481 - val_acc: 0.3674\n",
      "Epoch 664/3000\n",
      "8s - loss: 1.0071 - acc: 0.6006 - val_loss: 1.4445 - val_acc: 0.3774\n",
      "Epoch 665/3000\n",
      "8s - loss: 1.0119 - acc: 0.5957 - val_loss: 1.4498 - val_acc: 0.3742\n",
      "Epoch 666/3000\n",
      "8s - loss: 1.0269 - acc: 0.5916 - val_loss: 1.4509 - val_acc: 0.3692\n",
      "Epoch 667/3000\n",
      "8s - loss: 1.0017 - acc: 0.6038 - val_loss: 1.4450 - val_acc: 0.3828\n",
      "Epoch 668/3000\n",
      "8s - loss: 0.9977 - acc: 0.6025 - val_loss: 1.4480 - val_acc: 0.3747\n",
      "Epoch 669/3000\n",
      "8s - loss: 1.0155 - acc: 0.5957 - val_loss: 1.4440 - val_acc: 0.3819\n",
      "Epoch 670/3000\n",
      "8s - loss: 1.0195 - acc: 0.5923 - val_loss: 1.4481 - val_acc: 0.3814\n",
      "Epoch 671/3000\n",
      "8s - loss: 0.9956 - acc: 0.6020 - val_loss: 1.4477 - val_acc: 0.3774\n",
      "Epoch 672/3000\n",
      "8s - loss: 0.9978 - acc: 0.5966 - val_loss: 1.4445 - val_acc: 0.3751\n",
      "Epoch 673/3000\n",
      "8s - loss: 1.0031 - acc: 0.6002 - val_loss: 1.4503 - val_acc: 0.3733\n",
      "Epoch 674/3000\n",
      "8s - loss: 1.0135 - acc: 0.5995 - val_loss: 1.4453 - val_acc: 0.3760\n",
      "Epoch 675/3000\n",
      "8s - loss: 1.0042 - acc: 0.6082 - val_loss: 1.4418 - val_acc: 0.3733\n",
      "Epoch 676/3000\n",
      "8s - loss: 1.0122 - acc: 0.5965 - val_loss: 1.4441 - val_acc: 0.3747\n",
      "Epoch 677/3000\n",
      "8s - loss: 1.0119 - acc: 0.5959 - val_loss: 1.4562 - val_acc: 0.3751\n",
      "Epoch 678/3000\n",
      "8s - loss: 1.0111 - acc: 0.5945 - val_loss: 1.4471 - val_acc: 0.3801\n",
      "Epoch 679/3000\n",
      "8s - loss: 1.0123 - acc: 0.5966 - val_loss: 1.4573 - val_acc: 0.3778\n",
      "Epoch 680/3000\n",
      "8s - loss: 1.0181 - acc: 0.5972 - val_loss: 1.4483 - val_acc: 0.3810\n",
      "Epoch 681/3000\n",
      "8s - loss: 1.0074 - acc: 0.5984 - val_loss: 1.4527 - val_acc: 0.3801\n",
      "Epoch 682/3000\n",
      "8s - loss: 1.0116 - acc: 0.5982 - val_loss: 1.4422 - val_acc: 0.3837\n",
      "Epoch 683/3000\n",
      "8s - loss: 0.9951 - acc: 0.6004 - val_loss: 1.4429 - val_acc: 0.3783\n",
      "Epoch 684/3000\n",
      "8s - loss: 1.0039 - acc: 0.5984 - val_loss: 1.4459 - val_acc: 0.3801\n",
      "Epoch 685/3000\n",
      "8s - loss: 1.0019 - acc: 0.6022 - val_loss: 1.4485 - val_acc: 0.3756\n",
      "Epoch 686/3000\n",
      "8s - loss: 1.0101 - acc: 0.6006 - val_loss: 1.4433 - val_acc: 0.3774\n",
      "Epoch 687/3000\n",
      "8s - loss: 1.0089 - acc: 0.5945 - val_loss: 1.4460 - val_acc: 0.3774\n",
      "Epoch 688/3000\n",
      "8s - loss: 1.0111 - acc: 0.5983 - val_loss: 1.4430 - val_acc: 0.3828\n",
      "Epoch 689/3000\n",
      "8s - loss: 0.9983 - acc: 0.5950 - val_loss: 1.4399 - val_acc: 0.3851\n",
      "Epoch 690/3000\n",
      "8s - loss: 0.9961 - acc: 0.6035 - val_loss: 1.4484 - val_acc: 0.3774\n",
      "Epoch 691/3000\n",
      "8s - loss: 0.9985 - acc: 0.6064 - val_loss: 1.4524 - val_acc: 0.3769\n",
      "Epoch 692/3000\n",
      "8s - loss: 0.9908 - acc: 0.6097 - val_loss: 1.4420 - val_acc: 0.3878\n",
      "Epoch 693/3000\n",
      "8s - loss: 1.0157 - acc: 0.5882 - val_loss: 1.4497 - val_acc: 0.3824\n",
      "Epoch 694/3000\n",
      "8s - loss: 0.9998 - acc: 0.6030 - val_loss: 1.4545 - val_acc: 0.3706\n",
      "Epoch 695/3000\n",
      "8s - loss: 1.0050 - acc: 0.5984 - val_loss: 1.4524 - val_acc: 0.3742\n",
      "Epoch 696/3000\n",
      "8s - loss: 0.9897 - acc: 0.6037 - val_loss: 1.4503 - val_acc: 0.3729\n",
      "Epoch 697/3000\n",
      "8s - loss: 0.9987 - acc: 0.6040 - val_loss: 1.4480 - val_acc: 0.3774\n",
      "Epoch 698/3000\n",
      "8s - loss: 1.0107 - acc: 0.5983 - val_loss: 1.4476 - val_acc: 0.3765\n",
      "Epoch 699/3000\n",
      "8s - loss: 0.9972 - acc: 0.6056 - val_loss: 1.4454 - val_acc: 0.3783\n",
      "Epoch 700/3000\n",
      "8s - loss: 1.0003 - acc: 0.6024 - val_loss: 1.4512 - val_acc: 0.3729\n",
      "Epoch 701/3000\n",
      "8s - loss: 1.0015 - acc: 0.6006 - val_loss: 1.4411 - val_acc: 0.3756\n",
      "Epoch 702/3000\n",
      "8s - loss: 1.0100 - acc: 0.6032 - val_loss: 1.4430 - val_acc: 0.3765\n",
      "Epoch 703/3000\n",
      "8s - loss: 1.0051 - acc: 0.6016 - val_loss: 1.4486 - val_acc: 0.3760\n",
      "Epoch 704/3000\n",
      "8s - loss: 1.0010 - acc: 0.6067 - val_loss: 1.4535 - val_acc: 0.3774\n",
      "Epoch 705/3000\n",
      "8s - loss: 1.0040 - acc: 0.6009 - val_loss: 1.4405 - val_acc: 0.3824\n",
      "Epoch 706/3000\n",
      "8s - loss: 0.9982 - acc: 0.6038 - val_loss: 1.4485 - val_acc: 0.3842\n",
      "Epoch 707/3000\n",
      "8s - loss: 1.0030 - acc: 0.6020 - val_loss: 1.4585 - val_acc: 0.3769\n",
      "Epoch 708/3000\n",
      "8s - loss: 0.9977 - acc: 0.6025 - val_loss: 1.4611 - val_acc: 0.3769\n",
      "Epoch 709/3000\n",
      "8s - loss: 1.0031 - acc: 0.6017 - val_loss: 1.4607 - val_acc: 0.3778\n",
      "Epoch 710/3000\n",
      "8s - loss: 0.9894 - acc: 0.6098 - val_loss: 1.4442 - val_acc: 0.3751\n",
      "Epoch 711/3000\n",
      "8s - loss: 1.0107 - acc: 0.5992 - val_loss: 1.4505 - val_acc: 0.3765\n",
      "Epoch 712/3000\n",
      "8s - loss: 1.0101 - acc: 0.6025 - val_loss: 1.4498 - val_acc: 0.3751\n",
      "Epoch 713/3000\n",
      "8s - loss: 0.9948 - acc: 0.6075 - val_loss: 1.4482 - val_acc: 0.3878\n",
      "Epoch 714/3000\n",
      "8s - loss: 0.9964 - acc: 0.6022 - val_loss: 1.4587 - val_acc: 0.3760\n",
      "Epoch 715/3000\n",
      "8s - loss: 1.0140 - acc: 0.5956 - val_loss: 1.4469 - val_acc: 0.3869\n",
      "Epoch 716/3000\n",
      "8s - loss: 1.0073 - acc: 0.6051 - val_loss: 1.4497 - val_acc: 0.3819\n",
      "Epoch 717/3000\n",
      "8s - loss: 0.9931 - acc: 0.6054 - val_loss: 1.4476 - val_acc: 0.3805\n",
      "Epoch 718/3000\n",
      "8s - loss: 0.9961 - acc: 0.6032 - val_loss: 1.4391 - val_acc: 0.3887\n",
      "Epoch 719/3000\n",
      "8s - loss: 0.9941 - acc: 0.6075 - val_loss: 1.4469 - val_acc: 0.3787\n",
      "Epoch 720/3000\n",
      "8s - loss: 0.9918 - acc: 0.6107 - val_loss: 1.4429 - val_acc: 0.3833\n",
      "Epoch 721/3000\n",
      "8s - loss: 0.9946 - acc: 0.5989 - val_loss: 1.4531 - val_acc: 0.3783\n",
      "Epoch 722/3000\n",
      "8s - loss: 0.9945 - acc: 0.6023 - val_loss: 1.4485 - val_acc: 0.3819\n",
      "Epoch 723/3000\n",
      "8s - loss: 0.9992 - acc: 0.6015 - val_loss: 1.4436 - val_acc: 0.3846\n",
      "Epoch 724/3000\n",
      "8s - loss: 0.9955 - acc: 0.6011 - val_loss: 1.4492 - val_acc: 0.3769\n",
      "Epoch 725/3000\n",
      "8s - loss: 0.9961 - acc: 0.6096 - val_loss: 1.4511 - val_acc: 0.3778\n",
      "Epoch 726/3000\n",
      "8s - loss: 0.9986 - acc: 0.6046 - val_loss: 1.4509 - val_acc: 0.3792\n",
      "Epoch 727/3000\n",
      "8s - loss: 0.9922 - acc: 0.6038 - val_loss: 1.4444 - val_acc: 0.3814\n",
      "Epoch 728/3000\n",
      "8s - loss: 0.9722 - acc: 0.6154 - val_loss: 1.4471 - val_acc: 0.3860\n",
      "Epoch 729/3000\n",
      "8s - loss: 1.0003 - acc: 0.6024 - val_loss: 1.4447 - val_acc: 0.3765\n",
      "Epoch 730/3000\n",
      "8s - loss: 1.0058 - acc: 0.5995 - val_loss: 1.4469 - val_acc: 0.3733\n",
      "Epoch 731/3000\n",
      "8s - loss: 0.9980 - acc: 0.6045 - val_loss: 1.4479 - val_acc: 0.3760\n",
      "Epoch 732/3000\n",
      "8s - loss: 0.9918 - acc: 0.6064 - val_loss: 1.4477 - val_acc: 0.3810\n",
      "Epoch 733/3000\n",
      "8s - loss: 1.0042 - acc: 0.5989 - val_loss: 1.4483 - val_acc: 0.3760\n",
      "Epoch 734/3000\n",
      "8s - loss: 1.0028 - acc: 0.6060 - val_loss: 1.4479 - val_acc: 0.3792\n",
      "Epoch 735/3000\n",
      "8s - loss: 1.0149 - acc: 0.5935 - val_loss: 1.4488 - val_acc: 0.3774\n",
      "Epoch 736/3000\n",
      "8s - loss: 0.9850 - acc: 0.6105 - val_loss: 1.4491 - val_acc: 0.3805\n",
      "Epoch 737/3000\n",
      "8s - loss: 1.0005 - acc: 0.6019 - val_loss: 1.4434 - val_acc: 0.3792\n",
      "Epoch 738/3000\n",
      "8s - loss: 0.9977 - acc: 0.6039 - val_loss: 1.4473 - val_acc: 0.3796\n",
      "Epoch 739/3000\n",
      "8s - loss: 0.9993 - acc: 0.6037 - val_loss: 1.4517 - val_acc: 0.3692\n",
      "Epoch 740/3000\n",
      "8s - loss: 1.0091 - acc: 0.5919 - val_loss: 1.4491 - val_acc: 0.3778\n",
      "Epoch 741/3000\n",
      "8s - loss: 0.9900 - acc: 0.6068 - val_loss: 1.4552 - val_acc: 0.3710\n",
      "Epoch 742/3000\n",
      "8s - loss: 0.9994 - acc: 0.5993 - val_loss: 1.4474 - val_acc: 0.3747\n",
      "Epoch 743/3000\n",
      "8s - loss: 0.9917 - acc: 0.6073 - val_loss: 1.4579 - val_acc: 0.3697\n",
      "Epoch 744/3000\n",
      "8s - loss: 0.9924 - acc: 0.5994 - val_loss: 1.4504 - val_acc: 0.3769\n",
      "Epoch 745/3000\n",
      "8s - loss: 0.9992 - acc: 0.6039 - val_loss: 1.4504 - val_acc: 0.3801\n",
      "Epoch 746/3000\n",
      "8s - loss: 0.9993 - acc: 0.6005 - val_loss: 1.4500 - val_acc: 0.3738\n",
      "Epoch 747/3000\n",
      "8s - loss: 0.9954 - acc: 0.6009 - val_loss: 1.4428 - val_acc: 0.3828\n",
      "Epoch 748/3000\n",
      "8s - loss: 0.9989 - acc: 0.6084 - val_loss: 1.4441 - val_acc: 0.3792\n",
      "Epoch 749/3000\n",
      "8s - loss: 0.9866 - acc: 0.6117 - val_loss: 1.4531 - val_acc: 0.3706\n",
      "Epoch 750/3000\n",
      "8s - loss: 1.0048 - acc: 0.5971 - val_loss: 1.4500 - val_acc: 0.3688\n",
      "Epoch 751/3000\n",
      "8s - loss: 0.9870 - acc: 0.6041 - val_loss: 1.4427 - val_acc: 0.3692\n",
      "Epoch 752/3000\n",
      "8s - loss: 1.0104 - acc: 0.6007 - val_loss: 1.4510 - val_acc: 0.3710\n",
      "Epoch 753/3000\n",
      "8s - loss: 0.9801 - acc: 0.6133 - val_loss: 1.4438 - val_acc: 0.3760\n",
      "Epoch 754/3000\n",
      "8s - loss: 1.0097 - acc: 0.6020 - val_loss: 1.4450 - val_acc: 0.3738\n",
      "Epoch 755/3000\n",
      "8s - loss: 0.9942 - acc: 0.6079 - val_loss: 1.4437 - val_acc: 0.3738\n",
      "Epoch 756/3000\n",
      "8s - loss: 0.9878 - acc: 0.6073 - val_loss: 1.4402 - val_acc: 0.3747\n",
      "Epoch 757/3000\n",
      "8s - loss: 0.9908 - acc: 0.6039 - val_loss: 1.4458 - val_acc: 0.3729\n",
      "Epoch 758/3000\n",
      "8s - loss: 0.9929 - acc: 0.6051 - val_loss: 1.4479 - val_acc: 0.3683\n",
      "Epoch 759/3000\n",
      "8s - loss: 0.9848 - acc: 0.6144 - val_loss: 1.4447 - val_acc: 0.3738\n",
      "Epoch 760/3000\n",
      "8s - loss: 0.9833 - acc: 0.6086 - val_loss: 1.4525 - val_acc: 0.3724\n",
      "Epoch 761/3000\n",
      "8s - loss: 0.9889 - acc: 0.6103 - val_loss: 1.4493 - val_acc: 0.3701\n",
      "Epoch 762/3000\n",
      "8s - loss: 1.0045 - acc: 0.5953 - val_loss: 1.4444 - val_acc: 0.3719\n",
      "Epoch 763/3000\n",
      "8s - loss: 0.9903 - acc: 0.6119 - val_loss: 1.4456 - val_acc: 0.3765\n",
      "Epoch 764/3000\n",
      "8s - loss: 0.9956 - acc: 0.5968 - val_loss: 1.4469 - val_acc: 0.3729\n",
      "Epoch 765/3000\n",
      "8s - loss: 0.9916 - acc: 0.6032 - val_loss: 1.4443 - val_acc: 0.3792\n",
      "Epoch 766/3000\n",
      "8s - loss: 0.9930 - acc: 0.6091 - val_loss: 1.4491 - val_acc: 0.3742\n",
      "Epoch 767/3000\n",
      "8s - loss: 0.9993 - acc: 0.5988 - val_loss: 1.4466 - val_acc: 0.3656\n",
      "Epoch 768/3000\n",
      "8s - loss: 0.9843 - acc: 0.6142 - val_loss: 1.4510 - val_acc: 0.3710\n",
      "Epoch 769/3000\n",
      "8s - loss: 0.9957 - acc: 0.6005 - val_loss: 1.4541 - val_acc: 0.3733\n",
      "Epoch 770/3000\n",
      "8s - loss: 0.9916 - acc: 0.6064 - val_loss: 1.4401 - val_acc: 0.3787\n",
      "Epoch 771/3000\n",
      "8s - loss: 1.0060 - acc: 0.6053 - val_loss: 1.4447 - val_acc: 0.3719\n",
      "Epoch 772/3000\n",
      "8s - loss: 0.9885 - acc: 0.6054 - val_loss: 1.4411 - val_acc: 0.3769\n",
      "Epoch 773/3000\n",
      "8s - loss: 0.9956 - acc: 0.6074 - val_loss: 1.4469 - val_acc: 0.3765\n",
      "Epoch 774/3000\n",
      "8s - loss: 0.9983 - acc: 0.6023 - val_loss: 1.4449 - val_acc: 0.3769\n",
      "Epoch 775/3000\n",
      "8s - loss: 0.9761 - acc: 0.6105 - val_loss: 1.4441 - val_acc: 0.3774\n",
      "Epoch 776/3000\n",
      "8s - loss: 0.9924 - acc: 0.6068 - val_loss: 1.4494 - val_acc: 0.3697\n",
      "Epoch 777/3000\n",
      "8s - loss: 0.9838 - acc: 0.6072 - val_loss: 1.4442 - val_acc: 0.3738\n",
      "Epoch 778/3000\n",
      "8s - loss: 0.9880 - acc: 0.6085 - val_loss: 1.4506 - val_acc: 0.3719\n",
      "Epoch 779/3000\n",
      "8s - loss: 0.9678 - acc: 0.6149 - val_loss: 1.4511 - val_acc: 0.3787\n",
      "Epoch 780/3000\n",
      "8s - loss: 0.9917 - acc: 0.6048 - val_loss: 1.4419 - val_acc: 0.3833\n",
      "Epoch 781/3000\n",
      "8s - loss: 0.9993 - acc: 0.6054 - val_loss: 1.4552 - val_acc: 0.3774\n",
      "Epoch 782/3000\n",
      "8s - loss: 1.0041 - acc: 0.5975 - val_loss: 1.4450 - val_acc: 0.3747\n",
      "Epoch 783/3000\n",
      "8s - loss: 0.9930 - acc: 0.6090 - val_loss: 1.4611 - val_acc: 0.3710\n",
      "Epoch 784/3000\n",
      "8s - loss: 0.9786 - acc: 0.6116 - val_loss: 1.4587 - val_acc: 0.3792\n",
      "Epoch 785/3000\n",
      "8s - loss: 0.9848 - acc: 0.6073 - val_loss: 1.4506 - val_acc: 0.3715\n",
      "Epoch 786/3000\n",
      "8s - loss: 0.9936 - acc: 0.6081 - val_loss: 1.4531 - val_acc: 0.3751\n",
      "Epoch 787/3000\n",
      "8s - loss: 0.9849 - acc: 0.6074 - val_loss: 1.4526 - val_acc: 0.3756\n",
      "Epoch 788/3000\n",
      "8s - loss: 1.0126 - acc: 0.6048 - val_loss: 1.4465 - val_acc: 0.3851\n",
      "Epoch 789/3000\n",
      "8s - loss: 0.9816 - acc: 0.6095 - val_loss: 1.4488 - val_acc: 0.3751\n",
      "Epoch 790/3000\n",
      "8s - loss: 1.0052 - acc: 0.6022 - val_loss: 1.4521 - val_acc: 0.3792\n",
      "Epoch 791/3000\n",
      "8s - loss: 0.9901 - acc: 0.6128 - val_loss: 1.4457 - val_acc: 0.3810\n",
      "Epoch 792/3000\n",
      "8s - loss: 1.0048 - acc: 0.6003 - val_loss: 1.4425 - val_acc: 0.3751\n",
      "Epoch 793/3000\n",
      "8s - loss: 0.9857 - acc: 0.6148 - val_loss: 1.4486 - val_acc: 0.3760\n",
      "Epoch 794/3000\n",
      "8s - loss: 0.9916 - acc: 0.6050 - val_loss: 1.4501 - val_acc: 0.3842\n",
      "Epoch 795/3000\n",
      "8s - loss: 0.9845 - acc: 0.6111 - val_loss: 1.4461 - val_acc: 0.3824\n",
      "Epoch 796/3000\n",
      "8s - loss: 0.9794 - acc: 0.6068 - val_loss: 1.4494 - val_acc: 0.3760\n",
      "Epoch 797/3000\n",
      "8s - loss: 0.9808 - acc: 0.6074 - val_loss: 1.4529 - val_acc: 0.3774\n",
      "Epoch 798/3000\n",
      "8s - loss: 1.0034 - acc: 0.5984 - val_loss: 1.4632 - val_acc: 0.3715\n",
      "Epoch 799/3000\n",
      "8s - loss: 0.9915 - acc: 0.6063 - val_loss: 1.4388 - val_acc: 0.3810\n",
      "Epoch 800/3000\n",
      "8s - loss: 0.9896 - acc: 0.6036 - val_loss: 1.4566 - val_acc: 0.3729\n",
      "Epoch 801/3000\n",
      "8s - loss: 0.9949 - acc: 0.6049 - val_loss: 1.4557 - val_acc: 0.3706\n",
      "Epoch 802/3000\n",
      "8s - loss: 1.0025 - acc: 0.6031 - val_loss: 1.4547 - val_acc: 0.3738\n",
      "Epoch 803/3000\n",
      "8s - loss: 0.9910 - acc: 0.6104 - val_loss: 1.4587 - val_acc: 0.3665\n",
      "Epoch 804/3000\n",
      "8s - loss: 0.9684 - acc: 0.6169 - val_loss: 1.4547 - val_acc: 0.3670\n",
      "Epoch 805/3000\n",
      "8s - loss: 0.9931 - acc: 0.6053 - val_loss: 1.4492 - val_acc: 0.3629\n",
      "Epoch 806/3000\n",
      "8s - loss: 0.9836 - acc: 0.6101 - val_loss: 1.4558 - val_acc: 0.3638\n",
      "Epoch 807/3000\n",
      "8s - loss: 0.9838 - acc: 0.6130 - val_loss: 1.4539 - val_acc: 0.3661\n",
      "Epoch 808/3000\n",
      "8s - loss: 0.9790 - acc: 0.6149 - val_loss: 1.4513 - val_acc: 0.3719\n",
      "Epoch 809/3000\n",
      "8s - loss: 0.9855 - acc: 0.6119 - val_loss: 1.4534 - val_acc: 0.3665\n",
      "Epoch 810/3000\n",
      "8s - loss: 1.0030 - acc: 0.5983 - val_loss: 1.4568 - val_acc: 0.3692\n",
      "Epoch 811/3000\n",
      "8s - loss: 0.9743 - acc: 0.6197 - val_loss: 1.4531 - val_acc: 0.3710\n",
      "Epoch 812/3000\n",
      "8s - loss: 0.9859 - acc: 0.6101 - val_loss: 1.4546 - val_acc: 0.3733\n",
      "Epoch 813/3000\n",
      "8s - loss: 0.9834 - acc: 0.6152 - val_loss: 1.4517 - val_acc: 0.3706\n",
      "Epoch 814/3000\n",
      "8s - loss: 0.9890 - acc: 0.6049 - val_loss: 1.4514 - val_acc: 0.3792\n",
      "Epoch 815/3000\n",
      "8s - loss: 0.9848 - acc: 0.6092 - val_loss: 1.4519 - val_acc: 0.3710\n",
      "Epoch 816/3000\n",
      "8s - loss: 0.9853 - acc: 0.6134 - val_loss: 1.4514 - val_acc: 0.3697\n",
      "Epoch 817/3000\n",
      "8s - loss: 0.9872 - acc: 0.6074 - val_loss: 1.4550 - val_acc: 0.3683\n",
      "Epoch 818/3000\n",
      "8s - loss: 0.9761 - acc: 0.6175 - val_loss: 1.4551 - val_acc: 0.3683\n",
      "Epoch 819/3000\n",
      "8s - loss: 0.9798 - acc: 0.6068 - val_loss: 1.4385 - val_acc: 0.3719\n",
      "Epoch 820/3000\n",
      "8s - loss: 0.9952 - acc: 0.6008 - val_loss: 1.4471 - val_acc: 0.3701\n",
      "Epoch 821/3000\n",
      "8s - loss: 0.9827 - acc: 0.6080 - val_loss: 1.4395 - val_acc: 0.3778\n",
      "Epoch 822/3000\n",
      "8s - loss: 0.9764 - acc: 0.6116 - val_loss: 1.4456 - val_acc: 0.3778\n",
      "Epoch 823/3000\n",
      "8s - loss: 0.9605 - acc: 0.6249 - val_loss: 1.4492 - val_acc: 0.3733\n",
      "Epoch 824/3000\n",
      "8s - loss: 0.9956 - acc: 0.6007 - val_loss: 1.4454 - val_acc: 0.3733\n",
      "Epoch 825/3000\n",
      "8s - loss: 0.9740 - acc: 0.6151 - val_loss: 1.4522 - val_acc: 0.3796\n",
      "Epoch 826/3000\n",
      "8s - loss: 0.9779 - acc: 0.6136 - val_loss: 1.4488 - val_acc: 0.3665\n",
      "Epoch 827/3000\n",
      "8s - loss: 0.9762 - acc: 0.6123 - val_loss: 1.4491 - val_acc: 0.3710\n",
      "Epoch 828/3000\n",
      "8s - loss: 0.9664 - acc: 0.6186 - val_loss: 1.4495 - val_acc: 0.3814\n",
      "Epoch 829/3000\n",
      "8s - loss: 0.9919 - acc: 0.6055 - val_loss: 1.4424 - val_acc: 0.3774\n",
      "Epoch 830/3000\n",
      "8s - loss: 0.9787 - acc: 0.6123 - val_loss: 1.4537 - val_acc: 0.3783\n",
      "Epoch 831/3000\n",
      "8s - loss: 0.9812 - acc: 0.6097 - val_loss: 1.4540 - val_acc: 0.3738\n",
      "Epoch 832/3000\n",
      "8s - loss: 0.9888 - acc: 0.6057 - val_loss: 1.4489 - val_acc: 0.3778\n",
      "Epoch 833/3000\n",
      "8s - loss: 0.9998 - acc: 0.6048 - val_loss: 1.4472 - val_acc: 0.3783\n",
      "Epoch 834/3000\n",
      "8s - loss: 0.9917 - acc: 0.6044 - val_loss: 1.4501 - val_acc: 0.3769\n",
      "Epoch 835/3000\n",
      "8s - loss: 0.9864 - acc: 0.6103 - val_loss: 1.4490 - val_acc: 0.3842\n",
      "Epoch 836/3000\n",
      "8s - loss: 0.9928 - acc: 0.6075 - val_loss: 1.4415 - val_acc: 0.3774\n",
      "Epoch 837/3000\n",
      "8s - loss: 0.9841 - acc: 0.6094 - val_loss: 1.4443 - val_acc: 0.3778\n",
      "Epoch 838/3000\n",
      "8s - loss: 0.9890 - acc: 0.6062 - val_loss: 1.4472 - val_acc: 0.3751\n",
      "Epoch 839/3000\n",
      "8s - loss: 0.9699 - acc: 0.6157 - val_loss: 1.4463 - val_acc: 0.3774\n",
      "Epoch 840/3000\n",
      "8s - loss: 0.9747 - acc: 0.6113 - val_loss: 1.4484 - val_acc: 0.3715\n",
      "Epoch 841/3000\n",
      "8s - loss: 0.9907 - acc: 0.6061 - val_loss: 1.4478 - val_acc: 0.3824\n",
      "Epoch 842/3000\n",
      "8s - loss: 0.9798 - acc: 0.6188 - val_loss: 1.4528 - val_acc: 0.3715\n",
      "Epoch 843/3000\n",
      "8s - loss: 0.9866 - acc: 0.6086 - val_loss: 1.4463 - val_acc: 0.3778\n",
      "Epoch 844/3000\n",
      "8s - loss: 0.9765 - acc: 0.6105 - val_loss: 1.4465 - val_acc: 0.3796\n",
      "Epoch 845/3000\n",
      "8s - loss: 0.9808 - acc: 0.6139 - val_loss: 1.4520 - val_acc: 0.3679\n",
      "Epoch 846/3000\n",
      "8s - loss: 0.9872 - acc: 0.6104 - val_loss: 1.4447 - val_acc: 0.3792\n",
      "Epoch 847/3000\n",
      "8s - loss: 0.9810 - acc: 0.6113 - val_loss: 1.4510 - val_acc: 0.3760\n",
      "Epoch 848/3000\n",
      "8s - loss: 0.9807 - acc: 0.6123 - val_loss: 1.4447 - val_acc: 0.3828\n",
      "Epoch 849/3000\n",
      "8s - loss: 0.9633 - acc: 0.6166 - val_loss: 1.4441 - val_acc: 0.3733\n",
      "Epoch 850/3000\n",
      "8s - loss: 0.9824 - acc: 0.6087 - val_loss: 1.4466 - val_acc: 0.3760\n",
      "Epoch 851/3000\n",
      "8s - loss: 0.9634 - acc: 0.6194 - val_loss: 1.4366 - val_acc: 0.3814\n",
      "Epoch 852/3000\n",
      "8s - loss: 0.9921 - acc: 0.6054 - val_loss: 1.4455 - val_acc: 0.3833\n",
      "Epoch 853/3000\n",
      "8s - loss: 0.9925 - acc: 0.6084 - val_loss: 1.4432 - val_acc: 0.3738\n",
      "Epoch 854/3000\n",
      "8s - loss: 0.9762 - acc: 0.6115 - val_loss: 1.4478 - val_acc: 0.3783\n",
      "Epoch 855/3000\n",
      "8s - loss: 0.9836 - acc: 0.6089 - val_loss: 1.4429 - val_acc: 0.3873\n",
      "Epoch 856/3000\n",
      "8s - loss: 0.9974 - acc: 0.6044 - val_loss: 1.4411 - val_acc: 0.3801\n",
      "Epoch 857/3000\n",
      "8s - loss: 0.9718 - acc: 0.6182 - val_loss: 1.4439 - val_acc: 0.3819\n",
      "Epoch 858/3000\n",
      "8s - loss: 0.9704 - acc: 0.6160 - val_loss: 1.4469 - val_acc: 0.3792\n",
      "Epoch 859/3000\n",
      "8s - loss: 0.9919 - acc: 0.6118 - val_loss: 1.4478 - val_acc: 0.3787\n",
      "Epoch 860/3000\n",
      "8s - loss: 0.9895 - acc: 0.6152 - val_loss: 1.4457 - val_acc: 0.3792\n",
      "Epoch 861/3000\n",
      "8s - loss: 0.9660 - acc: 0.6194 - val_loss: 1.4489 - val_acc: 0.3796\n",
      "Epoch 862/3000\n",
      "8s - loss: 0.9818 - acc: 0.6117 - val_loss: 1.4519 - val_acc: 0.3738\n",
      "Epoch 863/3000\n",
      "8s - loss: 0.9873 - acc: 0.6103 - val_loss: 1.4487 - val_acc: 0.3769\n",
      "Epoch 864/3000\n",
      "8s - loss: 0.9766 - acc: 0.6154 - val_loss: 1.4545 - val_acc: 0.3729\n",
      "Epoch 865/3000\n",
      "8s - loss: 0.9866 - acc: 0.6088 - val_loss: 1.4488 - val_acc: 0.3778\n",
      "Epoch 866/3000\n",
      "8s - loss: 0.9862 - acc: 0.6043 - val_loss: 1.4499 - val_acc: 0.3760\n",
      "Epoch 867/3000\n",
      "8s - loss: 0.9696 - acc: 0.6176 - val_loss: 1.4524 - val_acc: 0.3801\n",
      "Epoch 868/3000\n",
      "8s - loss: 0.9779 - acc: 0.6169 - val_loss: 1.4468 - val_acc: 0.3747\n",
      "Epoch 869/3000\n",
      "8s - loss: 0.9739 - acc: 0.6092 - val_loss: 1.4547 - val_acc: 0.3683\n",
      "Epoch 870/3000\n",
      "8s - loss: 0.9621 - acc: 0.6166 - val_loss: 1.4525 - val_acc: 0.3724\n",
      "Epoch 871/3000\n",
      "8s - loss: 0.9840 - acc: 0.6051 - val_loss: 1.4538 - val_acc: 0.3729\n",
      "Epoch 872/3000\n",
      "8s - loss: 0.9799 - acc: 0.6156 - val_loss: 1.4510 - val_acc: 0.3760\n",
      "Epoch 873/3000\n",
      "8s - loss: 0.9787 - acc: 0.6124 - val_loss: 1.4634 - val_acc: 0.3624\n",
      "Epoch 874/3000\n",
      "8s - loss: 0.9754 - acc: 0.6086 - val_loss: 1.4530 - val_acc: 0.3692\n",
      "Epoch 875/3000\n",
      "8s - loss: 0.9625 - acc: 0.6189 - val_loss: 1.4559 - val_acc: 0.3606\n",
      "Epoch 876/3000\n",
      "8s - loss: 0.9740 - acc: 0.6178 - val_loss: 1.4398 - val_acc: 0.3706\n",
      "Epoch 877/3000\n",
      "8s - loss: 0.9705 - acc: 0.6154 - val_loss: 1.4520 - val_acc: 0.3697\n",
      "Epoch 878/3000\n",
      "8s - loss: 0.9790 - acc: 0.6170 - val_loss: 1.4532 - val_acc: 0.3688\n",
      "Epoch 879/3000\n",
      "8s - loss: 0.9871 - acc: 0.6130 - val_loss: 1.4427 - val_acc: 0.3710\n",
      "Epoch 880/3000\n",
      "8s - loss: 0.9830 - acc: 0.6089 - val_loss: 1.4522 - val_acc: 0.3679\n",
      "Epoch 881/3000\n",
      "8s - loss: 0.9755 - acc: 0.6138 - val_loss: 1.4486 - val_acc: 0.3697\n",
      "Epoch 882/3000\n",
      "8s - loss: 0.9764 - acc: 0.6096 - val_loss: 1.4485 - val_acc: 0.3656\n",
      "Epoch 883/3000\n",
      "8s - loss: 0.9683 - acc: 0.6174 - val_loss: 1.4516 - val_acc: 0.3661\n",
      "Epoch 884/3000\n",
      "8s - loss: 0.9809 - acc: 0.6068 - val_loss: 1.4496 - val_acc: 0.3674\n",
      "Epoch 885/3000\n",
      "8s - loss: 0.9870 - acc: 0.6054 - val_loss: 1.4529 - val_acc: 0.3629\n",
      "Epoch 886/3000\n",
      "8s - loss: 0.9872 - acc: 0.6081 - val_loss: 1.4446 - val_acc: 0.3647\n",
      "Epoch 887/3000\n",
      "8s - loss: 0.9838 - acc: 0.6120 - val_loss: 1.4503 - val_acc: 0.3661\n",
      "Epoch 888/3000\n",
      "8s - loss: 0.9648 - acc: 0.6177 - val_loss: 1.4497 - val_acc: 0.3715\n",
      "Epoch 889/3000\n",
      "8s - loss: 0.9732 - acc: 0.6177 - val_loss: 1.4518 - val_acc: 0.3679\n",
      "Epoch 890/3000\n",
      "8s - loss: 0.9657 - acc: 0.6191 - val_loss: 1.4491 - val_acc: 0.3656\n",
      "Epoch 891/3000\n",
      "8s - loss: 0.9893 - acc: 0.6113 - val_loss: 1.4512 - val_acc: 0.3692\n",
      "Epoch 892/3000\n",
      "8s - loss: 0.9649 - acc: 0.6227 - val_loss: 1.4420 - val_acc: 0.3724\n",
      "Epoch 893/3000\n",
      "8s - loss: 0.9630 - acc: 0.6184 - val_loss: 1.4460 - val_acc: 0.3724\n",
      "Epoch 894/3000\n",
      "8s - loss: 0.9779 - acc: 0.6148 - val_loss: 1.4527 - val_acc: 0.3697\n",
      "Epoch 895/3000\n",
      "8s - loss: 0.9817 - acc: 0.6142 - val_loss: 1.4465 - val_acc: 0.3701\n",
      "Epoch 896/3000\n",
      "8s - loss: 0.9883 - acc: 0.6077 - val_loss: 1.4532 - val_acc: 0.3692\n",
      "Epoch 897/3000\n",
      "8s - loss: 0.9861 - acc: 0.6100 - val_loss: 1.4480 - val_acc: 0.3747\n",
      "Epoch 898/3000\n",
      "8s - loss: 0.9876 - acc: 0.6064 - val_loss: 1.4481 - val_acc: 0.3670\n",
      "Epoch 899/3000\n",
      "8s - loss: 0.9767 - acc: 0.6095 - val_loss: 1.4393 - val_acc: 0.3733\n",
      "Epoch 900/3000\n",
      "8s - loss: 0.9892 - acc: 0.6118 - val_loss: 1.4452 - val_acc: 0.3751\n",
      "Epoch 901/3000\n",
      "8s - loss: 0.9756 - acc: 0.6134 - val_loss: 1.4408 - val_acc: 0.3719\n",
      "Epoch 902/3000\n",
      "8s - loss: 0.9696 - acc: 0.6187 - val_loss: 1.4405 - val_acc: 0.3719\n",
      "Epoch 903/3000\n",
      "8s - loss: 0.9902 - acc: 0.6061 - val_loss: 1.4504 - val_acc: 0.3688\n",
      "Epoch 904/3000\n",
      "8s - loss: 0.9739 - acc: 0.6126 - val_loss: 1.4525 - val_acc: 0.3665\n",
      "Epoch 905/3000\n",
      "8s - loss: 0.9801 - acc: 0.6185 - val_loss: 1.4558 - val_acc: 0.3615\n",
      "Epoch 906/3000\n",
      "8s - loss: 0.9947 - acc: 0.6066 - val_loss: 1.4449 - val_acc: 0.3706\n",
      "Epoch 907/3000\n",
      "8s - loss: 0.9701 - acc: 0.6178 - val_loss: 1.4435 - val_acc: 0.3742\n",
      "Epoch 908/3000\n",
      "8s - loss: 0.9916 - acc: 0.6061 - val_loss: 1.4411 - val_acc: 0.3810\n",
      "Epoch 909/3000\n",
      "8s - loss: 0.9669 - acc: 0.6160 - val_loss: 1.4502 - val_acc: 0.3774\n",
      "Epoch 910/3000\n",
      "8s - loss: 0.9660 - acc: 0.6232 - val_loss: 1.4524 - val_acc: 0.3706\n",
      "Epoch 911/3000\n",
      "8s - loss: 0.9787 - acc: 0.6126 - val_loss: 1.4468 - val_acc: 0.3692\n",
      "Epoch 912/3000\n",
      "8s - loss: 0.9731 - acc: 0.6171 - val_loss: 1.4430 - val_acc: 0.3756\n",
      "Epoch 913/3000\n",
      "8s - loss: 0.9837 - acc: 0.6095 - val_loss: 1.4512 - val_acc: 0.3719\n",
      "Epoch 914/3000\n",
      "8s - loss: 0.9792 - acc: 0.6149 - val_loss: 1.4455 - val_acc: 0.3692\n",
      "Epoch 915/3000\n",
      "8s - loss: 0.9855 - acc: 0.6100 - val_loss: 1.4429 - val_acc: 0.3729\n",
      "Epoch 916/3000\n",
      "8s - loss: 0.9640 - acc: 0.6189 - val_loss: 1.4463 - val_acc: 0.3778\n",
      "Epoch 917/3000\n",
      "8s - loss: 0.9669 - acc: 0.6206 - val_loss: 1.4454 - val_acc: 0.3760\n",
      "Epoch 918/3000\n",
      "8s - loss: 0.9666 - acc: 0.6150 - val_loss: 1.4458 - val_acc: 0.3710\n",
      "Epoch 919/3000\n",
      "8s - loss: 0.9813 - acc: 0.6097 - val_loss: 1.4460 - val_acc: 0.3701\n",
      "Epoch 920/3000\n",
      "8s - loss: 0.9881 - acc: 0.6118 - val_loss: 1.4411 - val_acc: 0.3701\n",
      "Epoch 921/3000\n",
      "8s - loss: 0.9779 - acc: 0.6121 - val_loss: 1.4465 - val_acc: 0.3706\n",
      "Epoch 922/3000\n",
      "8s - loss: 0.9745 - acc: 0.6144 - val_loss: 1.4476 - val_acc: 0.3738\n",
      "Epoch 923/3000\n",
      "8s - loss: 0.9738 - acc: 0.6145 - val_loss: 1.4503 - val_acc: 0.3701\n",
      "Epoch 924/3000\n",
      "8s - loss: 0.9826 - acc: 0.6105 - val_loss: 1.4451 - val_acc: 0.3692\n",
      "Epoch 925/3000\n",
      "8s - loss: 0.9847 - acc: 0.6104 - val_loss: 1.4452 - val_acc: 0.3643\n",
      "Epoch 926/3000\n",
      "8s - loss: 0.9687 - acc: 0.6161 - val_loss: 1.4504 - val_acc: 0.3738\n",
      "Epoch 927/3000\n",
      "8s - loss: 0.9738 - acc: 0.6182 - val_loss: 1.4415 - val_acc: 0.3697\n",
      "Epoch 928/3000\n",
      "8s - loss: 0.9774 - acc: 0.6090 - val_loss: 1.4444 - val_acc: 0.3697\n",
      "Epoch 929/3000\n",
      "8s - loss: 0.9719 - acc: 0.6159 - val_loss: 1.4490 - val_acc: 0.3597\n",
      "Epoch 930/3000\n",
      "8s - loss: 0.9713 - acc: 0.6180 - val_loss: 1.4457 - val_acc: 0.3652\n",
      "Epoch 931/3000\n",
      "8s - loss: 0.9875 - acc: 0.6098 - val_loss: 1.4445 - val_acc: 0.3624\n",
      "Epoch 932/3000\n",
      "8s - loss: 0.9776 - acc: 0.6172 - val_loss: 1.4433 - val_acc: 0.3710\n",
      "Epoch 933/3000\n",
      "8s - loss: 0.9754 - acc: 0.6178 - val_loss: 1.4542 - val_acc: 0.3656\n",
      "Epoch 934/3000\n",
      "8s - loss: 0.9739 - acc: 0.6141 - val_loss: 1.4485 - val_acc: 0.3724\n",
      "Epoch 935/3000\n",
      "8s - loss: 0.9740 - acc: 0.6203 - val_loss: 1.4518 - val_acc: 0.3679\n",
      "Epoch 936/3000\n",
      "8s - loss: 0.9723 - acc: 0.6154 - val_loss: 1.4510 - val_acc: 0.3760\n",
      "Epoch 937/3000\n",
      "8s - loss: 0.9899 - acc: 0.6082 - val_loss: 1.4360 - val_acc: 0.3805\n",
      "Epoch 938/3000\n",
      "8s - loss: 0.9751 - acc: 0.6142 - val_loss: 1.4473 - val_acc: 0.3724\n",
      "Epoch 939/3000\n",
      "8s - loss: 0.9775 - acc: 0.6149 - val_loss: 1.4520 - val_acc: 0.3602\n",
      "Epoch 940/3000\n",
      "8s - loss: 0.9865 - acc: 0.6090 - val_loss: 1.4470 - val_acc: 0.3729\n",
      "Epoch 941/3000\n",
      "8s - loss: 0.9624 - acc: 0.6260 - val_loss: 1.4451 - val_acc: 0.3665\n",
      "Epoch 942/3000\n",
      "8s - loss: 0.9643 - acc: 0.6197 - val_loss: 1.4492 - val_acc: 0.3706\n",
      "Epoch 943/3000\n",
      "8s - loss: 0.9857 - acc: 0.6105 - val_loss: 1.4583 - val_acc: 0.3647\n",
      "Epoch 944/3000\n",
      "8s - loss: 0.9667 - acc: 0.6259 - val_loss: 1.4534 - val_acc: 0.3724\n",
      "Epoch 945/3000\n",
      "8s - loss: 0.9800 - acc: 0.6139 - val_loss: 1.4463 - val_acc: 0.3747\n",
      "Epoch 946/3000\n",
      "8s - loss: 0.9790 - acc: 0.6141 - val_loss: 1.4487 - val_acc: 0.3729\n",
      "Epoch 947/3000\n",
      "8s - loss: 0.9768 - acc: 0.6130 - val_loss: 1.4479 - val_acc: 0.3620\n",
      "Epoch 948/3000\n",
      "8s - loss: 0.9868 - acc: 0.6107 - val_loss: 1.4464 - val_acc: 0.3674\n",
      "Epoch 949/3000\n",
      "8s - loss: 0.9551 - acc: 0.6235 - val_loss: 1.4504 - val_acc: 0.3760\n",
      "Epoch 950/3000\n",
      "8s - loss: 0.9636 - acc: 0.6233 - val_loss: 1.4439 - val_acc: 0.3765\n",
      "Epoch 951/3000\n",
      "8s - loss: 0.9745 - acc: 0.6116 - val_loss: 1.4463 - val_acc: 0.3738\n",
      "Epoch 952/3000\n",
      "8s - loss: 0.9565 - acc: 0.6224 - val_loss: 1.4458 - val_acc: 0.3719\n",
      "Epoch 953/3000\n",
      "8s - loss: 0.9740 - acc: 0.6173 - val_loss: 1.4524 - val_acc: 0.3620\n",
      "Epoch 954/3000\n",
      "8s - loss: 0.9668 - acc: 0.6165 - val_loss: 1.4469 - val_acc: 0.3683\n",
      "Epoch 955/3000\n",
      "8s - loss: 0.9734 - acc: 0.6166 - val_loss: 1.4479 - val_acc: 0.3706\n",
      "Epoch 956/3000\n",
      "8s - loss: 0.9675 - acc: 0.6161 - val_loss: 1.4471 - val_acc: 0.3715\n",
      "Epoch 957/3000\n",
      "8s - loss: 0.9729 - acc: 0.6143 - val_loss: 1.4465 - val_acc: 0.3697\n",
      "Epoch 958/3000\n",
      "8s - loss: 0.9591 - acc: 0.6128 - val_loss: 1.4521 - val_acc: 0.3611\n",
      "Epoch 959/3000\n",
      "8s - loss: 0.9927 - acc: 0.6092 - val_loss: 1.4533 - val_acc: 0.3624\n",
      "Epoch 960/3000\n",
      "8s - loss: 0.9623 - acc: 0.6195 - val_loss: 1.4479 - val_acc: 0.3674\n",
      "Epoch 961/3000\n",
      "8s - loss: 0.9697 - acc: 0.6184 - val_loss: 1.4495 - val_acc: 0.3674\n",
      "Epoch 962/3000\n",
      "8s - loss: 0.9727 - acc: 0.6189 - val_loss: 1.4424 - val_acc: 0.3787\n",
      "Epoch 963/3000\n",
      "8s - loss: 0.9790 - acc: 0.6140 - val_loss: 1.4390 - val_acc: 0.3719\n",
      "Epoch 964/3000\n",
      "8s - loss: 0.9696 - acc: 0.6192 - val_loss: 1.4473 - val_acc: 0.3729\n",
      "Epoch 965/3000\n",
      "8s - loss: 0.9702 - acc: 0.6251 - val_loss: 1.4419 - val_acc: 0.3729\n",
      "Epoch 966/3000\n",
      "8s - loss: 0.9766 - acc: 0.6108 - val_loss: 1.4481 - val_acc: 0.3715\n",
      "Epoch 967/3000\n",
      "8s - loss: 0.9745 - acc: 0.6140 - val_loss: 1.4468 - val_acc: 0.3787\n",
      "Epoch 968/3000\n",
      "8s - loss: 0.9598 - acc: 0.6213 - val_loss: 1.4434 - val_acc: 0.3656\n",
      "Epoch 969/3000\n",
      "8s - loss: 0.9718 - acc: 0.6172 - val_loss: 1.4470 - val_acc: 0.3742\n",
      "Epoch 970/3000\n",
      "8s - loss: 0.9695 - acc: 0.6130 - val_loss: 1.4401 - val_acc: 0.3792\n",
      "Epoch 971/3000\n",
      "8s - loss: 0.9725 - acc: 0.6164 - val_loss: 1.4456 - val_acc: 0.3683\n",
      "Epoch 972/3000\n",
      "8s - loss: 0.9848 - acc: 0.6131 - val_loss: 1.4510 - val_acc: 0.3647\n",
      "Epoch 973/3000\n",
      "8s - loss: 0.9734 - acc: 0.6171 - val_loss: 1.4423 - val_acc: 0.3683\n",
      "Epoch 974/3000\n",
      "8s - loss: 0.9780 - acc: 0.6120 - val_loss: 1.4514 - val_acc: 0.3747\n",
      "Epoch 975/3000\n",
      "8s - loss: 0.9712 - acc: 0.6148 - val_loss: 1.4467 - val_acc: 0.3774\n",
      "Epoch 976/3000\n",
      "8s - loss: 0.9790 - acc: 0.6122 - val_loss: 1.4425 - val_acc: 0.3729\n",
      "Epoch 977/3000\n",
      "8s - loss: 0.9629 - acc: 0.6197 - val_loss: 1.4495 - val_acc: 0.3679\n",
      "Epoch 978/3000\n",
      "8s - loss: 0.9694 - acc: 0.6200 - val_loss: 1.4460 - val_acc: 0.3706\n",
      "Epoch 979/3000\n",
      "8s - loss: 0.9728 - acc: 0.6152 - val_loss: 1.4491 - val_acc: 0.3706\n",
      "Epoch 980/3000\n",
      "8s - loss: 0.9692 - acc: 0.6210 - val_loss: 1.4506 - val_acc: 0.3656\n",
      "Epoch 981/3000\n",
      "8s - loss: 0.9699 - acc: 0.6258 - val_loss: 1.4481 - val_acc: 0.3760\n",
      "Epoch 982/3000\n",
      "8s - loss: 0.9715 - acc: 0.6149 - val_loss: 1.4424 - val_acc: 0.3765\n",
      "Epoch 983/3000\n",
      "8s - loss: 0.9695 - acc: 0.6207 - val_loss: 1.4444 - val_acc: 0.3778\n",
      "Epoch 984/3000\n",
      "8s - loss: 0.9787 - acc: 0.6126 - val_loss: 1.4568 - val_acc: 0.3729\n",
      "Epoch 985/3000\n",
      "8s - loss: 0.9879 - acc: 0.6116 - val_loss: 1.4427 - val_acc: 0.3719\n",
      "Epoch 986/3000\n",
      "8s - loss: 0.9752 - acc: 0.6121 - val_loss: 1.4470 - val_acc: 0.3733\n",
      "Epoch 987/3000\n",
      "8s - loss: 0.9528 - acc: 0.6210 - val_loss: 1.4504 - val_acc: 0.3670\n",
      "Epoch 988/3000\n",
      "8s - loss: 0.9558 - acc: 0.6231 - val_loss: 1.4468 - val_acc: 0.3701\n",
      "Epoch 989/3000\n",
      "8s - loss: 0.9655 - acc: 0.6209 - val_loss: 1.4470 - val_acc: 0.3683\n",
      "Epoch 990/3000\n",
      "8s - loss: 0.9665 - acc: 0.6164 - val_loss: 1.4474 - val_acc: 0.3670\n",
      "Epoch 991/3000\n",
      "8s - loss: 0.9624 - acc: 0.6249 - val_loss: 1.4486 - val_acc: 0.3710\n",
      "Epoch 992/3000\n",
      "8s - loss: 0.9461 - acc: 0.6323 - val_loss: 1.4486 - val_acc: 0.3769\n",
      "Epoch 993/3000\n",
      "8s - loss: 0.9685 - acc: 0.6126 - val_loss: 1.4557 - val_acc: 0.3760\n",
      "Epoch 994/3000\n",
      "8s - loss: 0.9865 - acc: 0.6140 - val_loss: 1.4494 - val_acc: 0.3701\n",
      "Epoch 995/3000\n",
      "8s - loss: 0.9648 - acc: 0.6222 - val_loss: 1.4506 - val_acc: 0.3715\n",
      "Epoch 996/3000\n",
      "8s - loss: 0.9747 - acc: 0.6152 - val_loss: 1.4576 - val_acc: 0.3670\n",
      "Epoch 997/3000\n",
      "8s - loss: 0.9688 - acc: 0.6188 - val_loss: 1.4506 - val_acc: 0.3724\n",
      "Epoch 998/3000\n",
      "8s - loss: 0.9809 - acc: 0.6140 - val_loss: 1.4465 - val_acc: 0.3724\n",
      "Epoch 999/3000\n",
      "8s - loss: 0.9889 - acc: 0.6074 - val_loss: 1.4493 - val_acc: 0.3751\n",
      "Epoch 1000/3000\n",
      "8s - loss: 0.9649 - acc: 0.6246 - val_loss: 1.4435 - val_acc: 0.3688\n",
      "Epoch 1001/3000\n",
      "8s - loss: 0.9613 - acc: 0.6171 - val_loss: 1.4405 - val_acc: 0.3756\n",
      "Epoch 1002/3000\n",
      "8s - loss: 0.9741 - acc: 0.6188 - val_loss: 1.4435 - val_acc: 0.3692\n",
      "Epoch 1003/3000\n",
      "8s - loss: 0.9666 - acc: 0.6231 - val_loss: 1.4449 - val_acc: 0.3661\n",
      "Epoch 1004/3000\n",
      "8s - loss: 0.9757 - acc: 0.6142 - val_loss: 1.4487 - val_acc: 0.3733\n",
      "Epoch 1005/3000\n",
      "8s - loss: 0.9698 - acc: 0.6124 - val_loss: 1.4457 - val_acc: 0.3701\n",
      "Epoch 1006/3000\n",
      "8s - loss: 0.9689 - acc: 0.6174 - val_loss: 1.4463 - val_acc: 0.3729\n",
      "Epoch 1007/3000\n",
      "8s - loss: 0.9594 - acc: 0.6217 - val_loss: 1.4450 - val_acc: 0.3706\n",
      "Epoch 1008/3000\n",
      "8s - loss: 0.9709 - acc: 0.6191 - val_loss: 1.4451 - val_acc: 0.3738\n",
      "Epoch 1009/3000\n",
      "8s - loss: 0.9756 - acc: 0.6142 - val_loss: 1.4507 - val_acc: 0.3697\n",
      "Epoch 1010/3000\n",
      "8s - loss: 0.9676 - acc: 0.6215 - val_loss: 1.4510 - val_acc: 0.3719\n",
      "Epoch 1011/3000\n",
      "8s - loss: 0.9618 - acc: 0.6238 - val_loss: 1.4491 - val_acc: 0.3724\n",
      "Epoch 1012/3000\n",
      "8s - loss: 0.9695 - acc: 0.6193 - val_loss: 1.4386 - val_acc: 0.3814\n",
      "Epoch 1013/3000\n",
      "8s - loss: 0.9755 - acc: 0.6164 - val_loss: 1.4467 - val_acc: 0.3751\n",
      "Epoch 1014/3000\n",
      "8s - loss: 0.9663 - acc: 0.6161 - val_loss: 1.4522 - val_acc: 0.3742\n",
      "Epoch 1015/3000\n",
      "8s - loss: 0.9650 - acc: 0.6243 - val_loss: 1.4422 - val_acc: 0.3774\n",
      "Epoch 1016/3000\n",
      "8s - loss: 0.9789 - acc: 0.6126 - val_loss: 1.4521 - val_acc: 0.3756\n",
      "Epoch 1017/3000\n",
      "8s - loss: 0.9608 - acc: 0.6230 - val_loss: 1.4492 - val_acc: 0.3742\n",
      "Epoch 1018/3000\n",
      "8s - loss: 0.9511 - acc: 0.6271 - val_loss: 1.4486 - val_acc: 0.3652\n",
      "Epoch 1019/3000\n",
      "8s - loss: 0.9659 - acc: 0.6174 - val_loss: 1.4421 - val_acc: 0.3783\n",
      "Epoch 1020/3000\n",
      "8s - loss: 0.9664 - acc: 0.6223 - val_loss: 1.4416 - val_acc: 0.3765\n",
      "Epoch 1021/3000\n",
      "8s - loss: 0.9703 - acc: 0.6162 - val_loss: 1.4470 - val_acc: 0.3747\n",
      "Epoch 1022/3000\n",
      "8s - loss: 0.9705 - acc: 0.6168 - val_loss: 1.4496 - val_acc: 0.3688\n",
      "Epoch 1023/3000\n",
      "8s - loss: 0.9567 - acc: 0.6293 - val_loss: 1.4435 - val_acc: 0.3778\n",
      "Epoch 1024/3000\n",
      "8s - loss: 0.9606 - acc: 0.6220 - val_loss: 1.4412 - val_acc: 0.3715\n",
      "Epoch 1025/3000\n",
      "8s - loss: 0.9529 - acc: 0.6262 - val_loss: 1.4573 - val_acc: 0.3683\n",
      "Epoch 1026/3000\n",
      "8s - loss: 0.9524 - acc: 0.6292 - val_loss: 1.4465 - val_acc: 0.3733\n",
      "Epoch 1027/3000\n",
      "8s - loss: 0.9616 - acc: 0.6225 - val_loss: 1.4521 - val_acc: 0.3697\n",
      "Epoch 1028/3000\n",
      "8s - loss: 0.9727 - acc: 0.6138 - val_loss: 1.4509 - val_acc: 0.3724\n",
      "Epoch 1029/3000\n",
      "8s - loss: 0.9636 - acc: 0.6209 - val_loss: 1.4478 - val_acc: 0.3670\n",
      "Epoch 1030/3000\n",
      "8s - loss: 0.9548 - acc: 0.6200 - val_loss: 1.4528 - val_acc: 0.3647\n",
      "Epoch 1031/3000\n",
      "8s - loss: 0.9688 - acc: 0.6261 - val_loss: 1.4575 - val_acc: 0.3652\n",
      "Epoch 1032/3000\n",
      "8s - loss: 0.9739 - acc: 0.6130 - val_loss: 1.4487 - val_acc: 0.3674\n",
      "Epoch 1033/3000\n",
      "8s - loss: 0.9691 - acc: 0.6135 - val_loss: 1.4511 - val_acc: 0.3692\n",
      "Epoch 1034/3000\n",
      "8s - loss: 0.9696 - acc: 0.6196 - val_loss: 1.4539 - val_acc: 0.3638\n",
      "Epoch 1035/3000\n",
      "8s - loss: 0.9594 - acc: 0.6201 - val_loss: 1.4536 - val_acc: 0.3701\n",
      "Epoch 1036/3000\n",
      "8s - loss: 0.9553 - acc: 0.6260 - val_loss: 1.4547 - val_acc: 0.3706\n",
      "Epoch 1037/3000\n",
      "8s - loss: 0.9527 - acc: 0.6225 - val_loss: 1.4487 - val_acc: 0.3633\n",
      "Epoch 1038/3000\n",
      "8s - loss: 0.9709 - acc: 0.6130 - val_loss: 1.4430 - val_acc: 0.3724\n",
      "Epoch 1039/3000\n",
      "8s - loss: 0.9715 - acc: 0.6220 - val_loss: 1.4527 - val_acc: 0.3570\n",
      "Epoch 1040/3000\n",
      "8s - loss: 0.9624 - acc: 0.6167 - val_loss: 1.4493 - val_acc: 0.3647\n",
      "Epoch 1041/3000\n",
      "8s - loss: 0.9678 - acc: 0.6167 - val_loss: 1.4611 - val_acc: 0.3688\n",
      "Epoch 1042/3000\n",
      "8s - loss: 0.9564 - acc: 0.6253 - val_loss: 1.4513 - val_acc: 0.3674\n",
      "Epoch 1043/3000\n",
      "8s - loss: 0.9515 - acc: 0.6261 - val_loss: 1.4489 - val_acc: 0.3597\n",
      "Epoch 1044/3000\n",
      "8s - loss: 0.9752 - acc: 0.6170 - val_loss: 1.4515 - val_acc: 0.3629\n",
      "Epoch 1045/3000\n",
      "8s - loss: 0.9654 - acc: 0.6129 - val_loss: 1.4551 - val_acc: 0.3629\n",
      "Epoch 1046/3000\n",
      "8s - loss: 0.9832 - acc: 0.6119 - val_loss: 1.4531 - val_acc: 0.3643\n",
      "Epoch 1047/3000\n",
      "8s - loss: 0.9767 - acc: 0.6188 - val_loss: 1.4570 - val_acc: 0.3629\n",
      "Epoch 1048/3000\n",
      "8s - loss: 0.9615 - acc: 0.6156 - val_loss: 1.4471 - val_acc: 0.3652\n",
      "Epoch 1049/3000\n",
      "8s - loss: 0.9614 - acc: 0.6241 - val_loss: 1.4505 - val_acc: 0.3652\n",
      "Epoch 1050/3000\n",
      "8s - loss: 0.9660 - acc: 0.6178 - val_loss: 1.4529 - val_acc: 0.3620\n",
      "Epoch 1051/3000\n",
      "8s - loss: 0.9595 - acc: 0.6203 - val_loss: 1.4462 - val_acc: 0.3706\n",
      "Epoch 1052/3000\n",
      "8s - loss: 0.9636 - acc: 0.6226 - val_loss: 1.4492 - val_acc: 0.3688\n",
      "Epoch 1053/3000\n",
      "8s - loss: 0.9692 - acc: 0.6184 - val_loss: 1.4546 - val_acc: 0.3733\n",
      "Epoch 1054/3000\n",
      "8s - loss: 0.9645 - acc: 0.6214 - val_loss: 1.4448 - val_acc: 0.3778\n",
      "Epoch 1055/3000\n",
      "8s - loss: 0.9589 - acc: 0.6237 - val_loss: 1.4513 - val_acc: 0.3724\n",
      "Epoch 1056/3000\n",
      "8s - loss: 0.9575 - acc: 0.6205 - val_loss: 1.4492 - val_acc: 0.3719\n",
      "Epoch 1057/3000\n",
      "8s - loss: 0.9557 - acc: 0.6196 - val_loss: 1.4479 - val_acc: 0.3715\n",
      "Epoch 1058/3000\n",
      "8s - loss: 0.9649 - acc: 0.6179 - val_loss: 1.4562 - val_acc: 0.3760\n",
      "Epoch 1059/3000\n",
      "8s - loss: 0.9706 - acc: 0.6267 - val_loss: 1.4540 - val_acc: 0.3765\n",
      "Epoch 1060/3000\n",
      "8s - loss: 0.9549 - acc: 0.6177 - val_loss: 1.4494 - val_acc: 0.3756\n",
      "Epoch 1061/3000\n",
      "8s - loss: 0.9712 - acc: 0.6194 - val_loss: 1.4529 - val_acc: 0.3710\n",
      "Epoch 1062/3000\n",
      "8s - loss: 0.9787 - acc: 0.6146 - val_loss: 1.4485 - val_acc: 0.3643\n",
      "Epoch 1063/3000\n",
      "8s - loss: 0.9501 - acc: 0.6260 - val_loss: 1.4547 - val_acc: 0.3643\n",
      "Epoch 1064/3000\n",
      "8s - loss: 0.9728 - acc: 0.6189 - val_loss: 1.4528 - val_acc: 0.3633\n",
      "Epoch 1065/3000\n",
      "8s - loss: 0.9630 - acc: 0.6178 - val_loss: 1.4464 - val_acc: 0.3674\n",
      "Epoch 1066/3000\n",
      "8s - loss: 0.9677 - acc: 0.6178 - val_loss: 1.4501 - val_acc: 0.3670\n",
      "Epoch 1067/3000\n",
      "8s - loss: 0.9578 - acc: 0.6215 - val_loss: 1.4596 - val_acc: 0.3710\n",
      "Epoch 1068/3000\n",
      "8s - loss: 0.9654 - acc: 0.6226 - val_loss: 1.4558 - val_acc: 0.3688\n",
      "Epoch 1069/3000\n",
      "8s - loss: 0.9629 - acc: 0.6222 - val_loss: 1.4515 - val_acc: 0.3692\n",
      "Epoch 1070/3000\n",
      "8s - loss: 0.9797 - acc: 0.6078 - val_loss: 1.4521 - val_acc: 0.3674\n",
      "Epoch 1071/3000\n",
      "8s - loss: 0.9677 - acc: 0.6119 - val_loss: 1.4492 - val_acc: 0.3656\n",
      "Epoch 1072/3000\n",
      "8s - loss: 0.9578 - acc: 0.6234 - val_loss: 1.4624 - val_acc: 0.3629\n",
      "Epoch 1073/3000\n",
      "8s - loss: 0.9700 - acc: 0.6194 - val_loss: 1.4546 - val_acc: 0.3615\n",
      "Epoch 1074/3000\n",
      "8s - loss: 0.9635 - acc: 0.6156 - val_loss: 1.4489 - val_acc: 0.3674\n",
      "Epoch 1075/3000\n",
      "8s - loss: 0.9497 - acc: 0.6300 - val_loss: 1.4429 - val_acc: 0.3756\n",
      "Epoch 1076/3000\n",
      "8s - loss: 0.9618 - acc: 0.6222 - val_loss: 1.4419 - val_acc: 0.3656\n",
      "Epoch 1077/3000\n",
      "8s - loss: 0.9565 - acc: 0.6236 - val_loss: 1.4527 - val_acc: 0.3670\n",
      "Epoch 1078/3000\n",
      "8s - loss: 0.9724 - acc: 0.6154 - val_loss: 1.4416 - val_acc: 0.3706\n",
      "Epoch 1079/3000\n",
      "8s - loss: 0.9673 - acc: 0.6191 - val_loss: 1.4426 - val_acc: 0.3643\n",
      "Epoch 1080/3000\n",
      "8s - loss: 0.9644 - acc: 0.6229 - val_loss: 1.4494 - val_acc: 0.3710\n",
      "Epoch 1081/3000\n",
      "8s - loss: 0.9579 - acc: 0.6264 - val_loss: 1.4542 - val_acc: 0.3697\n",
      "Epoch 1082/3000\n",
      "8s - loss: 0.9539 - acc: 0.6305 - val_loss: 1.4589 - val_acc: 0.3615\n",
      "Epoch 1083/3000\n",
      "8s - loss: 0.9664 - acc: 0.6214 - val_loss: 1.4466 - val_acc: 0.3683\n",
      "Epoch 1084/3000\n",
      "8s - loss: 0.9540 - acc: 0.6197 - val_loss: 1.4594 - val_acc: 0.3647\n",
      "Epoch 1085/3000\n",
      "8s - loss: 0.9645 - acc: 0.6199 - val_loss: 1.4405 - val_acc: 0.3674\n",
      "Epoch 1086/3000\n",
      "8s - loss: 0.9636 - acc: 0.6175 - val_loss: 1.4453 - val_acc: 0.3724\n",
      "Epoch 1087/3000\n",
      "8s - loss: 0.9637 - acc: 0.6237 - val_loss: 1.4499 - val_acc: 0.3701\n",
      "Epoch 1088/3000\n",
      "8s - loss: 0.9751 - acc: 0.6137 - val_loss: 1.4477 - val_acc: 0.3733\n",
      "Epoch 1089/3000\n",
      "8s - loss: 0.9607 - acc: 0.6215 - val_loss: 1.4513 - val_acc: 0.3697\n",
      "Epoch 1090/3000\n",
      "8s - loss: 0.9662 - acc: 0.6230 - val_loss: 1.4415 - val_acc: 0.3765\n",
      "Epoch 1091/3000\n",
      "8s - loss: 0.9625 - acc: 0.6180 - val_loss: 1.4552 - val_acc: 0.3665\n",
      "Epoch 1092/3000\n",
      "8s - loss: 0.9630 - acc: 0.6197 - val_loss: 1.4513 - val_acc: 0.3688\n",
      "Epoch 1093/3000\n",
      "8s - loss: 0.9628 - acc: 0.6204 - val_loss: 1.4529 - val_acc: 0.3633\n",
      "Epoch 1094/3000\n",
      "8s - loss: 0.9652 - acc: 0.6176 - val_loss: 1.4464 - val_acc: 0.3747\n",
      "Epoch 1095/3000\n",
      "8s - loss: 0.9513 - acc: 0.6254 - val_loss: 1.4558 - val_acc: 0.3706\n",
      "Epoch 1096/3000\n",
      "8s - loss: 0.9480 - acc: 0.6259 - val_loss: 1.4495 - val_acc: 0.3710\n",
      "Epoch 1097/3000\n",
      "8s - loss: 0.9615 - acc: 0.6214 - val_loss: 1.4509 - val_acc: 0.3778\n",
      "Epoch 1098/3000\n",
      "8s - loss: 0.9664 - acc: 0.6133 - val_loss: 1.4578 - val_acc: 0.3706\n",
      "Epoch 1099/3000\n",
      "8s - loss: 0.9603 - acc: 0.6185 - val_loss: 1.4539 - val_acc: 0.3733\n",
      "Epoch 1100/3000\n",
      "8s - loss: 0.9781 - acc: 0.6152 - val_loss: 1.4510 - val_acc: 0.3724\n",
      "Epoch 1101/3000\n",
      "8s - loss: 0.9524 - acc: 0.6262 - val_loss: 1.4518 - val_acc: 0.3665\n",
      "Epoch 1102/3000\n",
      "8s - loss: 0.9539 - acc: 0.6215 - val_loss: 1.4466 - val_acc: 0.3656\n",
      "Epoch 1103/3000\n",
      "8s - loss: 0.9476 - acc: 0.6272 - val_loss: 1.4519 - val_acc: 0.3710\n",
      "Epoch 1104/3000\n",
      "8s - loss: 0.9567 - acc: 0.6271 - val_loss: 1.4478 - val_acc: 0.3670\n",
      "Epoch 1105/3000\n",
      "8s - loss: 0.9548 - acc: 0.6174 - val_loss: 1.4501 - val_acc: 0.3688\n",
      "Epoch 1106/3000\n",
      "8s - loss: 0.9523 - acc: 0.6328 - val_loss: 1.4475 - val_acc: 0.3729\n",
      "Epoch 1107/3000\n",
      "8s - loss: 0.9620 - acc: 0.6236 - val_loss: 1.4599 - val_acc: 0.3697\n",
      "Epoch 1108/3000\n",
      "8s - loss: 0.9575 - acc: 0.6237 - val_loss: 1.4498 - val_acc: 0.3679\n",
      "Epoch 1109/3000\n",
      "8s - loss: 0.9537 - acc: 0.6277 - val_loss: 1.4482 - val_acc: 0.3724\n",
      "Epoch 1110/3000\n",
      "8s - loss: 0.9624 - acc: 0.6206 - val_loss: 1.4456 - val_acc: 0.3701\n",
      "Epoch 1111/3000\n",
      "8s - loss: 0.9597 - acc: 0.6212 - val_loss: 1.4477 - val_acc: 0.3715\n",
      "Epoch 1112/3000\n",
      "8s - loss: 0.9486 - acc: 0.6238 - val_loss: 1.4438 - val_acc: 0.3738\n",
      "Epoch 1113/3000\n",
      "8s - loss: 0.9467 - acc: 0.6270 - val_loss: 1.4472 - val_acc: 0.3719\n",
      "Epoch 1114/3000\n",
      "8s - loss: 0.9533 - acc: 0.6247 - val_loss: 1.4426 - val_acc: 0.3787\n",
      "Epoch 1115/3000\n",
      "8s - loss: 0.9635 - acc: 0.6206 - val_loss: 1.4463 - val_acc: 0.3765\n",
      "Epoch 1116/3000\n",
      "8s - loss: 0.9700 - acc: 0.6188 - val_loss: 1.4397 - val_acc: 0.3729\n",
      "Epoch 1117/3000\n",
      "8s - loss: 0.9532 - acc: 0.6281 - val_loss: 1.4394 - val_acc: 0.3697\n",
      "Epoch 1118/3000\n",
      "8s - loss: 0.9538 - acc: 0.6218 - val_loss: 1.4463 - val_acc: 0.3747\n",
      "Epoch 1119/3000\n",
      "8s - loss: 0.9633 - acc: 0.6226 - val_loss: 1.4573 - val_acc: 0.3652\n",
      "Epoch 1120/3000\n",
      "8s - loss: 0.9526 - acc: 0.6258 - val_loss: 1.4512 - val_acc: 0.3624\n",
      "Epoch 1121/3000\n",
      "8s - loss: 0.9695 - acc: 0.6162 - val_loss: 1.4600 - val_acc: 0.3679\n",
      "Epoch 1122/3000\n",
      "8s - loss: 0.9782 - acc: 0.6165 - val_loss: 1.4501 - val_acc: 0.3670\n",
      "Epoch 1123/3000\n",
      "8s - loss: 0.9653 - acc: 0.6139 - val_loss: 1.4414 - val_acc: 0.3756\n",
      "Epoch 1124/3000\n",
      "8s - loss: 0.9715 - acc: 0.6123 - val_loss: 1.4500 - val_acc: 0.3611\n",
      "Epoch 1125/3000\n",
      "8s - loss: 0.9580 - acc: 0.6205 - val_loss: 1.4505 - val_acc: 0.3697\n",
      "Epoch 1126/3000\n",
      "8s - loss: 0.9612 - acc: 0.6194 - val_loss: 1.4450 - val_acc: 0.3697\n",
      "Epoch 1127/3000\n",
      "8s - loss: 0.9518 - acc: 0.6194 - val_loss: 1.4483 - val_acc: 0.3638\n",
      "Epoch 1128/3000\n",
      "8s - loss: 0.9508 - acc: 0.6289 - val_loss: 1.4497 - val_acc: 0.3715\n",
      "Epoch 1129/3000\n",
      "8s - loss: 0.9586 - acc: 0.6233 - val_loss: 1.4401 - val_acc: 0.3729\n",
      "Epoch 1130/3000\n",
      "8s - loss: 0.9614 - acc: 0.6190 - val_loss: 1.4472 - val_acc: 0.3656\n",
      "Epoch 1131/3000\n",
      "8s - loss: 0.9476 - acc: 0.6278 - val_loss: 1.4525 - val_acc: 0.3701\n",
      "Epoch 1132/3000\n",
      "8s - loss: 0.9435 - acc: 0.6311 - val_loss: 1.4467 - val_acc: 0.3783\n",
      "Epoch 1133/3000\n",
      "8s - loss: 0.9616 - acc: 0.6180 - val_loss: 1.4531 - val_acc: 0.3724\n",
      "Epoch 1134/3000\n",
      "8s - loss: 0.9586 - acc: 0.6223 - val_loss: 1.4462 - val_acc: 0.3724\n",
      "Epoch 1135/3000\n",
      "8s - loss: 0.9610 - acc: 0.6224 - val_loss: 1.4431 - val_acc: 0.3701\n",
      "Epoch 1136/3000\n",
      "8s - loss: 0.9605 - acc: 0.6175 - val_loss: 1.4534 - val_acc: 0.3760\n",
      "Epoch 1137/3000\n",
      "8s - loss: 0.9448 - acc: 0.6276 - val_loss: 1.4441 - val_acc: 0.3760\n",
      "Epoch 1138/3000\n",
      "8s - loss: 0.9759 - acc: 0.6136 - val_loss: 1.4483 - val_acc: 0.3710\n",
      "Epoch 1139/3000\n",
      "8s - loss: 0.9517 - acc: 0.6256 - val_loss: 1.4366 - val_acc: 0.3729\n",
      "Epoch 1140/3000\n",
      "8s - loss: 0.9435 - acc: 0.6243 - val_loss: 1.4442 - val_acc: 0.3751\n",
      "Epoch 1141/3000\n",
      "8s - loss: 0.9520 - acc: 0.6224 - val_loss: 1.4463 - val_acc: 0.3729\n",
      "Epoch 1142/3000\n",
      "8s - loss: 0.9594 - acc: 0.6229 - val_loss: 1.4430 - val_acc: 0.3778\n",
      "Epoch 1143/3000\n",
      "8s - loss: 0.9678 - acc: 0.6180 - val_loss: 1.4483 - val_acc: 0.3620\n",
      "Epoch 1144/3000\n",
      "8s - loss: 0.9698 - acc: 0.6202 - val_loss: 1.4524 - val_acc: 0.3701\n",
      "Epoch 1145/3000\n",
      "8s - loss: 0.9629 - acc: 0.6220 - val_loss: 1.4459 - val_acc: 0.3683\n",
      "Epoch 1146/3000\n",
      "8s - loss: 0.9656 - acc: 0.6251 - val_loss: 1.4442 - val_acc: 0.3638\n",
      "Epoch 1147/3000\n",
      "8s - loss: 0.9458 - acc: 0.6299 - val_loss: 1.4442 - val_acc: 0.3692\n",
      "Epoch 1148/3000\n",
      "8s - loss: 0.9472 - acc: 0.6262 - val_loss: 1.4446 - val_acc: 0.3706\n",
      "Epoch 1149/3000\n",
      "8s - loss: 0.9298 - acc: 0.6362 - val_loss: 1.4463 - val_acc: 0.3602\n",
      "Epoch 1150/3000\n",
      "8s - loss: 0.9529 - acc: 0.6216 - val_loss: 1.4412 - val_acc: 0.3701\n",
      "Epoch 1151/3000\n",
      "8s - loss: 0.9374 - acc: 0.6344 - val_loss: 1.4451 - val_acc: 0.3656\n",
      "Epoch 1152/3000\n",
      "8s - loss: 0.9556 - acc: 0.6231 - val_loss: 1.4470 - val_acc: 0.3719\n",
      "Epoch 1153/3000\n",
      "8s - loss: 0.9594 - acc: 0.6184 - val_loss: 1.4485 - val_acc: 0.3683\n",
      "Epoch 1154/3000\n",
      "8s - loss: 0.9410 - acc: 0.6290 - val_loss: 1.4484 - val_acc: 0.3733\n",
      "Epoch 1155/3000\n",
      "8s - loss: 0.9588 - acc: 0.6187 - val_loss: 1.4442 - val_acc: 0.3715\n",
      "Epoch 1156/3000\n",
      "8s - loss: 0.9588 - acc: 0.6151 - val_loss: 1.4421 - val_acc: 0.3715\n",
      "Epoch 1157/3000\n",
      "8s - loss: 0.9637 - acc: 0.6196 - val_loss: 1.4448 - val_acc: 0.3729\n",
      "Epoch 1158/3000\n",
      "8s - loss: 0.9629 - acc: 0.6185 - val_loss: 1.4468 - val_acc: 0.3697\n",
      "Epoch 1159/3000\n",
      "8s - loss: 0.9539 - acc: 0.6224 - val_loss: 1.4486 - val_acc: 0.3647\n",
      "Epoch 1160/3000\n",
      "8s - loss: 0.9540 - acc: 0.6257 - val_loss: 1.4472 - val_acc: 0.3701\n",
      "Epoch 1161/3000\n",
      "8s - loss: 0.9507 - acc: 0.6245 - val_loss: 1.4440 - val_acc: 0.3733\n",
      "Epoch 1162/3000\n",
      "8s - loss: 0.9488 - acc: 0.6340 - val_loss: 1.4460 - val_acc: 0.3674\n",
      "Epoch 1163/3000\n",
      "8s - loss: 0.9635 - acc: 0.6231 - val_loss: 1.4409 - val_acc: 0.3769\n",
      "Epoch 1164/3000\n",
      "8s - loss: 0.9585 - acc: 0.6269 - val_loss: 1.4432 - val_acc: 0.3715\n",
      "Epoch 1165/3000\n",
      "8s - loss: 0.9525 - acc: 0.6225 - val_loss: 1.4447 - val_acc: 0.3765\n",
      "Epoch 1166/3000\n",
      "8s - loss: 0.9431 - acc: 0.6280 - val_loss: 1.4397 - val_acc: 0.3751\n",
      "Epoch 1167/3000\n",
      "8s - loss: 0.9570 - acc: 0.6223 - val_loss: 1.4402 - val_acc: 0.3792\n",
      "Epoch 1168/3000\n",
      "8s - loss: 0.9637 - acc: 0.6224 - val_loss: 1.4471 - val_acc: 0.3665\n",
      "Epoch 1169/3000\n",
      "8s - loss: 0.9384 - acc: 0.6274 - val_loss: 1.4440 - val_acc: 0.3679\n",
      "Epoch 1170/3000\n",
      "8s - loss: 0.9277 - acc: 0.6278 - val_loss: 1.4459 - val_acc: 0.3738\n",
      "Epoch 1171/3000\n",
      "8s - loss: 0.9371 - acc: 0.6277 - val_loss: 1.4439 - val_acc: 0.3742\n",
      "Epoch 1172/3000\n",
      "8s - loss: 0.9448 - acc: 0.6244 - val_loss: 1.4528 - val_acc: 0.3688\n",
      "Epoch 1173/3000\n",
      "8s - loss: 0.9607 - acc: 0.6229 - val_loss: 1.4421 - val_acc: 0.3719\n",
      "Epoch 1174/3000\n",
      "8s - loss: 0.9455 - acc: 0.6312 - val_loss: 1.4499 - val_acc: 0.3670\n",
      "Epoch 1175/3000\n",
      "8s - loss: 0.9622 - acc: 0.6241 - val_loss: 1.4431 - val_acc: 0.3756\n",
      "Epoch 1176/3000\n",
      "8s - loss: 0.9506 - acc: 0.6316 - val_loss: 1.4445 - val_acc: 0.3701\n",
      "Epoch 1177/3000\n",
      "8s - loss: 0.9591 - acc: 0.6215 - val_loss: 1.4445 - val_acc: 0.3738\n",
      "Epoch 1178/3000\n",
      "8s - loss: 0.9413 - acc: 0.6329 - val_loss: 1.4532 - val_acc: 0.3706\n",
      "Epoch 1179/3000\n",
      "8s - loss: 0.9581 - acc: 0.6165 - val_loss: 1.4408 - val_acc: 0.3747\n",
      "Epoch 1180/3000\n",
      "8s - loss: 0.9575 - acc: 0.6228 - val_loss: 1.4480 - val_acc: 0.3774\n",
      "Epoch 1181/3000\n",
      "8s - loss: 0.9593 - acc: 0.6218 - val_loss: 1.4443 - val_acc: 0.3846\n",
      "Epoch 1182/3000\n",
      "8s - loss: 0.9675 - acc: 0.6208 - val_loss: 1.4408 - val_acc: 0.3774\n",
      "Epoch 1183/3000\n",
      "8s - loss: 0.9512 - acc: 0.6250 - val_loss: 1.4514 - val_acc: 0.3814\n",
      "Epoch 1184/3000\n",
      "8s - loss: 0.9409 - acc: 0.6309 - val_loss: 1.4464 - val_acc: 0.3692\n",
      "Epoch 1185/3000\n",
      "8s - loss: 0.9506 - acc: 0.6314 - val_loss: 1.4411 - val_acc: 0.3792\n",
      "Epoch 1186/3000\n",
      "8s - loss: 0.9548 - acc: 0.6236 - val_loss: 1.4483 - val_acc: 0.3665\n",
      "Epoch 1187/3000\n",
      "8s - loss: 0.9514 - acc: 0.6223 - val_loss: 1.4473 - val_acc: 0.3792\n",
      "Epoch 1188/3000\n",
      "8s - loss: 0.9628 - acc: 0.6238 - val_loss: 1.4406 - val_acc: 0.3792\n",
      "Epoch 1189/3000\n",
      "8s - loss: 0.9465 - acc: 0.6231 - val_loss: 1.4542 - val_acc: 0.3783\n",
      "Epoch 1190/3000\n",
      "8s - loss: 0.9408 - acc: 0.6292 - val_loss: 1.4479 - val_acc: 0.3738\n",
      "Epoch 1191/3000\n",
      "8s - loss: 0.9347 - acc: 0.6312 - val_loss: 1.4449 - val_acc: 0.3756\n",
      "Epoch 1192/3000\n",
      "8s - loss: 0.9496 - acc: 0.6274 - val_loss: 1.4449 - val_acc: 0.3774\n",
      "Epoch 1193/3000\n",
      "8s - loss: 0.9471 - acc: 0.6251 - val_loss: 1.4378 - val_acc: 0.3742\n",
      "Epoch 1194/3000\n",
      "8s - loss: 0.9515 - acc: 0.6244 - val_loss: 1.4443 - val_acc: 0.3692\n",
      "Epoch 1195/3000\n",
      "8s - loss: 0.9571 - acc: 0.6244 - val_loss: 1.4518 - val_acc: 0.3683\n",
      "Epoch 1196/3000\n",
      "8s - loss: 0.9581 - acc: 0.6260 - val_loss: 1.4445 - val_acc: 0.3683\n",
      "Epoch 1197/3000\n",
      "8s - loss: 0.9480 - acc: 0.6242 - val_loss: 1.4472 - val_acc: 0.3670\n",
      "Epoch 1198/3000\n",
      "8s - loss: 0.9460 - acc: 0.6259 - val_loss: 1.4542 - val_acc: 0.3692\n",
      "Epoch 1199/3000\n",
      "8s - loss: 0.9480 - acc: 0.6251 - val_loss: 1.4430 - val_acc: 0.3729\n",
      "Epoch 1200/3000\n",
      "8s - loss: 0.9485 - acc: 0.6250 - val_loss: 1.4360 - val_acc: 0.3769\n",
      "Epoch 1201/3000\n",
      "8s - loss: 0.9601 - acc: 0.6232 - val_loss: 1.4444 - val_acc: 0.3733\n",
      "Epoch 1202/3000\n",
      "8s - loss: 0.9446 - acc: 0.6330 - val_loss: 1.4416 - val_acc: 0.3747\n",
      "Epoch 1203/3000\n",
      "8s - loss: 0.9391 - acc: 0.6272 - val_loss: 1.4448 - val_acc: 0.3760\n",
      "Epoch 1204/3000\n",
      "8s - loss: 0.9504 - acc: 0.6251 - val_loss: 1.4373 - val_acc: 0.3701\n",
      "Epoch 1205/3000\n",
      "8s - loss: 0.9517 - acc: 0.6256 - val_loss: 1.4475 - val_acc: 0.3670\n",
      "Epoch 1206/3000\n",
      "8s - loss: 0.9575 - acc: 0.6191 - val_loss: 1.4392 - val_acc: 0.3724\n",
      "Epoch 1207/3000\n",
      "8s - loss: 0.9653 - acc: 0.6178 - val_loss: 1.4372 - val_acc: 0.3765\n",
      "Epoch 1208/3000\n",
      "8s - loss: 0.9615 - acc: 0.6193 - val_loss: 1.4401 - val_acc: 0.3751\n",
      "Epoch 1209/3000\n",
      "8s - loss: 0.9427 - acc: 0.6283 - val_loss: 1.4476 - val_acc: 0.3674\n",
      "Epoch 1210/3000\n",
      "8s - loss: 0.9589 - acc: 0.6194 - val_loss: 1.4423 - val_acc: 0.3747\n",
      "Epoch 1211/3000\n",
      "8s - loss: 0.9836 - acc: 0.6104 - val_loss: 1.4458 - val_acc: 0.3738\n",
      "Epoch 1212/3000\n",
      "8s - loss: 0.9395 - acc: 0.6320 - val_loss: 1.4436 - val_acc: 0.3715\n",
      "Epoch 1213/3000\n",
      "8s - loss: 0.9595 - acc: 0.6248 - val_loss: 1.4456 - val_acc: 0.3701\n",
      "Epoch 1214/3000\n",
      "8s - loss: 0.9559 - acc: 0.6195 - val_loss: 1.4498 - val_acc: 0.3670\n",
      "Epoch 1215/3000\n",
      "8s - loss: 0.9575 - acc: 0.6274 - val_loss: 1.4479 - val_acc: 0.3670\n",
      "Epoch 1216/3000\n",
      "8s - loss: 0.9617 - acc: 0.6182 - val_loss: 1.4457 - val_acc: 0.3760\n",
      "Epoch 1217/3000\n",
      "8s - loss: 0.9613 - acc: 0.6217 - val_loss: 1.4468 - val_acc: 0.3688\n",
      "Epoch 1218/3000\n",
      "8s - loss: 0.9434 - acc: 0.6325 - val_loss: 1.4450 - val_acc: 0.3692\n",
      "Epoch 1219/3000\n",
      "8s - loss: 0.9604 - acc: 0.6206 - val_loss: 1.4565 - val_acc: 0.3683\n",
      "Epoch 1220/3000\n",
      "8s - loss: 0.9476 - acc: 0.6240 - val_loss: 1.4485 - val_acc: 0.3710\n",
      "Epoch 1221/3000\n",
      "8s - loss: 0.9449 - acc: 0.6316 - val_loss: 1.4412 - val_acc: 0.3701\n",
      "Epoch 1222/3000\n",
      "8s - loss: 0.9441 - acc: 0.6305 - val_loss: 1.4500 - val_acc: 0.3620\n",
      "Epoch 1223/3000\n",
      "8s - loss: 0.9573 - acc: 0.6233 - val_loss: 1.4431 - val_acc: 0.3679\n",
      "Epoch 1224/3000\n",
      "8s - loss: 0.9558 - acc: 0.6295 - val_loss: 1.4565 - val_acc: 0.3620\n",
      "Epoch 1225/3000\n",
      "8s - loss: 0.9544 - acc: 0.6261 - val_loss: 1.4460 - val_acc: 0.3692\n",
      "Epoch 1226/3000\n",
      "8s - loss: 0.9360 - acc: 0.6322 - val_loss: 1.4453 - val_acc: 0.3733\n",
      "Epoch 1227/3000\n",
      "8s - loss: 0.9600 - acc: 0.6250 - val_loss: 1.4449 - val_acc: 0.3706\n",
      "Epoch 1228/3000\n",
      "8s - loss: 0.9588 - acc: 0.6224 - val_loss: 1.4523 - val_acc: 0.3674\n",
      "Epoch 1229/3000\n",
      "8s - loss: 0.9543 - acc: 0.6291 - val_loss: 1.4409 - val_acc: 0.3765\n",
      "Epoch 1230/3000\n",
      "8s - loss: 0.9653 - acc: 0.6217 - val_loss: 1.4480 - val_acc: 0.3710\n",
      "Epoch 1231/3000\n",
      "8s - loss: 0.9539 - acc: 0.6272 - val_loss: 1.4356 - val_acc: 0.3796\n",
      "Epoch 1232/3000\n",
      "8s - loss: 0.9615 - acc: 0.6200 - val_loss: 1.4367 - val_acc: 0.3751\n",
      "Epoch 1233/3000\n",
      "8s - loss: 0.9281 - acc: 0.6375 - val_loss: 1.4520 - val_acc: 0.3738\n",
      "Epoch 1234/3000\n",
      "8s - loss: 0.9541 - acc: 0.6251 - val_loss: 1.4500 - val_acc: 0.3715\n",
      "Epoch 1235/3000\n",
      "8s - loss: 0.9395 - acc: 0.6341 - val_loss: 1.4503 - val_acc: 0.3733\n",
      "Epoch 1236/3000\n",
      "8s - loss: 0.9581 - acc: 0.6237 - val_loss: 1.4411 - val_acc: 0.3769\n",
      "Epoch 1237/3000\n",
      "8s - loss: 0.9508 - acc: 0.6248 - val_loss: 1.4496 - val_acc: 0.3747\n",
      "Epoch 1238/3000\n",
      "8s - loss: 0.9470 - acc: 0.6257 - val_loss: 1.4426 - val_acc: 0.3805\n",
      "Epoch 1239/3000\n",
      "8s - loss: 0.9490 - acc: 0.6276 - val_loss: 1.4487 - val_acc: 0.3805\n",
      "Epoch 1240/3000\n",
      "8s - loss: 0.9460 - acc: 0.6327 - val_loss: 1.4528 - val_acc: 0.3769\n",
      "Epoch 1241/3000\n",
      "8s - loss: 0.9475 - acc: 0.6363 - val_loss: 1.4446 - val_acc: 0.3796\n",
      "Epoch 1242/3000\n",
      "8s - loss: 0.9473 - acc: 0.6290 - val_loss: 1.4431 - val_acc: 0.3715\n",
      "Epoch 1243/3000\n",
      "8s - loss: 0.9513 - acc: 0.6269 - val_loss: 1.4500 - val_acc: 0.3724\n",
      "Epoch 1244/3000\n",
      "8s - loss: 0.9473 - acc: 0.6267 - val_loss: 1.4468 - val_acc: 0.3747\n",
      "Epoch 1245/3000\n",
      "8s - loss: 0.9549 - acc: 0.6228 - val_loss: 1.4491 - val_acc: 0.3729\n",
      "Epoch 1246/3000\n",
      "8s - loss: 0.9418 - acc: 0.6253 - val_loss: 1.4463 - val_acc: 0.3729\n",
      "Epoch 1247/3000\n",
      "9s - loss: 0.9603 - acc: 0.6251 - val_loss: 1.4459 - val_acc: 0.3778\n",
      "Epoch 1248/3000\n",
      "9s - loss: 0.9522 - acc: 0.6270 - val_loss: 1.4482 - val_acc: 0.3765\n",
      "Epoch 1249/3000\n",
      "8s - loss: 0.9516 - acc: 0.6295 - val_loss: 1.4415 - val_acc: 0.3742\n",
      "Epoch 1250/3000\n",
      "8s - loss: 0.9522 - acc: 0.6295 - val_loss: 1.4426 - val_acc: 0.3765\n",
      "Epoch 1251/3000\n",
      "8s - loss: 0.9385 - acc: 0.6337 - val_loss: 1.4458 - val_acc: 0.3729\n",
      "Epoch 1252/3000\n",
      "8s - loss: 0.9595 - acc: 0.6237 - val_loss: 1.4410 - val_acc: 0.3738\n",
      "Epoch 1253/3000\n",
      "8s - loss: 0.9556 - acc: 0.6247 - val_loss: 1.4407 - val_acc: 0.3733\n",
      "Epoch 1254/3000\n",
      "8s - loss: 0.9571 - acc: 0.6302 - val_loss: 1.4424 - val_acc: 0.3760\n",
      "Epoch 1255/3000\n",
      "8s - loss: 0.9608 - acc: 0.6246 - val_loss: 1.4484 - val_acc: 0.3729\n",
      "Epoch 1256/3000\n",
      "8s - loss: 0.9478 - acc: 0.6278 - val_loss: 1.4443 - val_acc: 0.3747\n",
      "Epoch 1257/3000\n",
      "8s - loss: 0.9355 - acc: 0.6305 - val_loss: 1.4411 - val_acc: 0.3810\n",
      "Epoch 1258/3000\n",
      "8s - loss: 0.9386 - acc: 0.6331 - val_loss: 1.4484 - val_acc: 0.3719\n",
      "Epoch 1259/3000\n",
      "8s - loss: 0.9643 - acc: 0.6202 - val_loss: 1.4407 - val_acc: 0.3778\n",
      "Epoch 1260/3000\n",
      "8s - loss: 0.9473 - acc: 0.6333 - val_loss: 1.4435 - val_acc: 0.3769\n",
      "Epoch 1261/3000\n",
      "9s - loss: 0.9436 - acc: 0.6295 - val_loss: 1.4463 - val_acc: 0.3792\n",
      "Epoch 1262/3000\n",
      "9s - loss: 0.9456 - acc: 0.6307 - val_loss: 1.4517 - val_acc: 0.3769\n",
      "Epoch 1263/3000\n",
      "9s - loss: 0.9548 - acc: 0.6196 - val_loss: 1.4339 - val_acc: 0.3842\n",
      "Epoch 1264/3000\n",
      "9s - loss: 0.9561 - acc: 0.6251 - val_loss: 1.4435 - val_acc: 0.3760\n",
      "Epoch 1265/3000\n",
      "8s - loss: 0.9587 - acc: 0.6244 - val_loss: 1.4410 - val_acc: 0.3701\n",
      "Epoch 1266/3000\n",
      "8s - loss: 0.9358 - acc: 0.6326 - val_loss: 1.4500 - val_acc: 0.3774\n",
      "Epoch 1267/3000\n",
      "8s - loss: 0.9472 - acc: 0.6278 - val_loss: 1.4450 - val_acc: 0.3805\n",
      "Epoch 1268/3000\n",
      "8s - loss: 0.9546 - acc: 0.6293 - val_loss: 1.4396 - val_acc: 0.3765\n",
      "Epoch 1269/3000\n",
      "8s - loss: 0.9555 - acc: 0.6252 - val_loss: 1.4453 - val_acc: 0.3760\n",
      "Epoch 1270/3000\n",
      "8s - loss: 0.9466 - acc: 0.6344 - val_loss: 1.4431 - val_acc: 0.3842\n",
      "Epoch 1271/3000\n",
      "8s - loss: 0.9693 - acc: 0.6222 - val_loss: 1.4462 - val_acc: 0.3796\n",
      "Epoch 1272/3000\n",
      "8s - loss: 0.9433 - acc: 0.6251 - val_loss: 1.4490 - val_acc: 0.3751\n",
      "Epoch 1273/3000\n",
      "8s - loss: 0.9549 - acc: 0.6249 - val_loss: 1.4457 - val_acc: 0.3774\n",
      "Epoch 1274/3000\n",
      "8s - loss: 0.9660 - acc: 0.6191 - val_loss: 1.4506 - val_acc: 0.3751\n",
      "Epoch 1275/3000\n",
      "8s - loss: 0.9589 - acc: 0.6241 - val_loss: 1.4511 - val_acc: 0.3724\n",
      "Epoch 1276/3000\n",
      "8s - loss: 0.9443 - acc: 0.6260 - val_loss: 1.4461 - val_acc: 0.3774\n",
      "Epoch 1277/3000\n",
      "8s - loss: 0.9609 - acc: 0.6261 - val_loss: 1.4551 - val_acc: 0.3692\n",
      "Epoch 1278/3000\n",
      "8s - loss: 0.9546 - acc: 0.6253 - val_loss: 1.4472 - val_acc: 0.3710\n",
      "Epoch 1279/3000\n",
      "8s - loss: 0.9610 - acc: 0.6234 - val_loss: 1.4447 - val_acc: 0.3801\n",
      "Epoch 1280/3000\n",
      "8s - loss: 0.9456 - acc: 0.6276 - val_loss: 1.4453 - val_acc: 0.3774\n",
      "Epoch 1281/3000\n",
      "8s - loss: 0.9514 - acc: 0.6221 - val_loss: 1.4487 - val_acc: 0.3747\n",
      "Epoch 1282/3000\n",
      "8s - loss: 0.9449 - acc: 0.6267 - val_loss: 1.4424 - val_acc: 0.3792\n",
      "Epoch 1283/3000\n",
      "8s - loss: 0.9368 - acc: 0.6355 - val_loss: 1.4478 - val_acc: 0.3729\n",
      "Epoch 1284/3000\n",
      "8s - loss: 0.9388 - acc: 0.6317 - val_loss: 1.4516 - val_acc: 0.3715\n",
      "Epoch 1285/3000\n",
      "8s - loss: 0.9497 - acc: 0.6303 - val_loss: 1.4471 - val_acc: 0.3751\n",
      "Epoch 1286/3000\n",
      "8s - loss: 0.9463 - acc: 0.6335 - val_loss: 1.4365 - val_acc: 0.3783\n",
      "Epoch 1287/3000\n",
      "8s - loss: 0.9420 - acc: 0.6330 - val_loss: 1.4414 - val_acc: 0.3851\n",
      "Epoch 1288/3000\n",
      "8s - loss: 0.9339 - acc: 0.6341 - val_loss: 1.4415 - val_acc: 0.3742\n",
      "Epoch 1289/3000\n",
      "8s - loss: 0.9450 - acc: 0.6272 - val_loss: 1.4483 - val_acc: 0.3719\n",
      "Epoch 1290/3000\n",
      "8s - loss: 0.9406 - acc: 0.6293 - val_loss: 1.4445 - val_acc: 0.3787\n",
      "Epoch 1291/3000\n",
      "8s - loss: 0.9510 - acc: 0.6215 - val_loss: 1.4466 - val_acc: 0.3719\n",
      "Epoch 1292/3000\n",
      "8s - loss: 0.9508 - acc: 0.6261 - val_loss: 1.4389 - val_acc: 0.3747\n",
      "Epoch 1293/3000\n",
      "8s - loss: 0.9304 - acc: 0.6378 - val_loss: 1.4391 - val_acc: 0.3760\n",
      "Epoch 1294/3000\n",
      "8s - loss: 0.9373 - acc: 0.6281 - val_loss: 1.4470 - val_acc: 0.3729\n",
      "Epoch 1295/3000\n",
      "8s - loss: 0.9577 - acc: 0.6226 - val_loss: 1.4481 - val_acc: 0.3697\n",
      "Epoch 1296/3000\n",
      "8s - loss: 0.9384 - acc: 0.6292 - val_loss: 1.4440 - val_acc: 0.3810\n",
      "Epoch 1297/3000\n",
      "8s - loss: 0.9677 - acc: 0.6234 - val_loss: 1.4490 - val_acc: 0.3692\n",
      "Epoch 1298/3000\n",
      "8s - loss: 0.9622 - acc: 0.6197 - val_loss: 1.4453 - val_acc: 0.3697\n",
      "Epoch 1299/3000\n",
      "8s - loss: 0.9442 - acc: 0.6309 - val_loss: 1.4530 - val_acc: 0.3710\n",
      "Epoch 1300/3000\n",
      "8s - loss: 0.9545 - acc: 0.6259 - val_loss: 1.4475 - val_acc: 0.3729\n",
      "Epoch 1301/3000\n",
      "8s - loss: 0.9397 - acc: 0.6336 - val_loss: 1.4560 - val_acc: 0.3679\n",
      "Epoch 1302/3000\n",
      "8s - loss: 0.9398 - acc: 0.6285 - val_loss: 1.4470 - val_acc: 0.3742\n",
      "Epoch 1303/3000\n",
      "8s - loss: 0.9389 - acc: 0.6255 - val_loss: 1.4612 - val_acc: 0.3733\n",
      "Epoch 1304/3000\n",
      "8s - loss: 0.9461 - acc: 0.6260 - val_loss: 1.4545 - val_acc: 0.3688\n",
      "Epoch 1305/3000\n",
      "8s - loss: 0.9468 - acc: 0.6264 - val_loss: 1.4440 - val_acc: 0.3738\n",
      "Epoch 1306/3000\n",
      "8s - loss: 0.9424 - acc: 0.6301 - val_loss: 1.4504 - val_acc: 0.3670\n",
      "Epoch 1307/3000\n",
      "8s - loss: 0.9385 - acc: 0.6305 - val_loss: 1.4560 - val_acc: 0.3719\n",
      "Epoch 1308/3000\n",
      "8s - loss: 0.9440 - acc: 0.6286 - val_loss: 1.4516 - val_acc: 0.3733\n",
      "Epoch 1309/3000\n",
      "8s - loss: 0.9493 - acc: 0.6293 - val_loss: 1.4495 - val_acc: 0.3679\n",
      "Epoch 1310/3000\n",
      "8s - loss: 0.9556 - acc: 0.6250 - val_loss: 1.4433 - val_acc: 0.3778\n",
      "Epoch 1311/3000\n",
      "8s - loss: 0.9616 - acc: 0.6248 - val_loss: 1.4583 - val_acc: 0.3719\n",
      "Epoch 1312/3000\n",
      "8s - loss: 0.9419 - acc: 0.6287 - val_loss: 1.4539 - val_acc: 0.3692\n",
      "Epoch 1313/3000\n",
      "8s - loss: 0.9393 - acc: 0.6298 - val_loss: 1.4569 - val_acc: 0.3706\n",
      "Epoch 1314/3000\n",
      "8s - loss: 0.9556 - acc: 0.6261 - val_loss: 1.4562 - val_acc: 0.3633\n",
      "Epoch 1315/3000\n",
      "8s - loss: 0.9558 - acc: 0.6265 - val_loss: 1.4446 - val_acc: 0.3733\n",
      "Epoch 1316/3000\n",
      "8s - loss: 0.9472 - acc: 0.6312 - val_loss: 1.4481 - val_acc: 0.3706\n",
      "Epoch 1317/3000\n",
      "8s - loss: 0.9480 - acc: 0.6245 - val_loss: 1.4423 - val_acc: 0.3787\n",
      "Epoch 1318/3000\n",
      "8s - loss: 0.9583 - acc: 0.6280 - val_loss: 1.4451 - val_acc: 0.3719\n",
      "Epoch 1319/3000\n",
      "8s - loss: 0.9522 - acc: 0.6222 - val_loss: 1.4404 - val_acc: 0.3792\n",
      "Epoch 1320/3000\n",
      "8s - loss: 0.9433 - acc: 0.6311 - val_loss: 1.4462 - val_acc: 0.3769\n",
      "Epoch 1321/3000\n",
      "8s - loss: 0.9510 - acc: 0.6221 - val_loss: 1.4470 - val_acc: 0.3778\n",
      "Epoch 1322/3000\n",
      "8s - loss: 0.9299 - acc: 0.6360 - val_loss: 1.4437 - val_acc: 0.3738\n",
      "Epoch 1323/3000\n",
      "8s - loss: 0.9439 - acc: 0.6338 - val_loss: 1.4478 - val_acc: 0.3715\n",
      "Epoch 1324/3000\n",
      "8s - loss: 0.9334 - acc: 0.6334 - val_loss: 1.4499 - val_acc: 0.3742\n",
      "Epoch 1325/3000\n",
      "8s - loss: 0.9354 - acc: 0.6350 - val_loss: 1.4452 - val_acc: 0.3769\n",
      "Epoch 1326/3000\n",
      "8s - loss: 0.9378 - acc: 0.6363 - val_loss: 1.4445 - val_acc: 0.3810\n",
      "Epoch 1327/3000\n",
      "8s - loss: 0.9518 - acc: 0.6234 - val_loss: 1.4476 - val_acc: 0.3742\n",
      "Epoch 1328/3000\n",
      "8s - loss: 0.9512 - acc: 0.6228 - val_loss: 1.4370 - val_acc: 0.3778\n",
      "Epoch 1329/3000\n",
      "8s - loss: 0.9492 - acc: 0.6257 - val_loss: 1.4423 - val_acc: 0.3647\n",
      "Epoch 1330/3000\n",
      "8s - loss: 0.9470 - acc: 0.6284 - val_loss: 1.4470 - val_acc: 0.3724\n",
      "Epoch 1331/3000\n",
      "8s - loss: 0.9310 - acc: 0.6385 - val_loss: 1.4506 - val_acc: 0.3756\n",
      "Epoch 1332/3000\n",
      "8s - loss: 0.9476 - acc: 0.6266 - val_loss: 1.4436 - val_acc: 0.3674\n",
      "Epoch 1333/3000\n",
      "8s - loss: 0.9542 - acc: 0.6210 - val_loss: 1.4379 - val_acc: 0.3724\n",
      "Epoch 1334/3000\n",
      "8s - loss: 0.9382 - acc: 0.6378 - val_loss: 1.4396 - val_acc: 0.3765\n",
      "Epoch 1335/3000\n",
      "8s - loss: 0.9440 - acc: 0.6255 - val_loss: 1.4518 - val_acc: 0.3679\n",
      "Epoch 1336/3000\n",
      "8s - loss: 0.9436 - acc: 0.6313 - val_loss: 1.4516 - val_acc: 0.3724\n",
      "Epoch 1337/3000\n",
      "8s - loss: 0.9471 - acc: 0.6298 - val_loss: 1.4498 - val_acc: 0.3719\n",
      "Epoch 1338/3000\n",
      "8s - loss: 0.9519 - acc: 0.6257 - val_loss: 1.4499 - val_acc: 0.3674\n",
      "Epoch 1339/3000\n",
      "8s - loss: 0.9485 - acc: 0.6198 - val_loss: 1.4506 - val_acc: 0.3733\n",
      "Epoch 1340/3000\n",
      "8s - loss: 0.9473 - acc: 0.6308 - val_loss: 1.4538 - val_acc: 0.3633\n",
      "Epoch 1341/3000\n",
      "8s - loss: 0.9411 - acc: 0.6289 - val_loss: 1.4520 - val_acc: 0.3733\n",
      "Epoch 1342/3000\n",
      "8s - loss: 0.9622 - acc: 0.6243 - val_loss: 1.4459 - val_acc: 0.3760\n",
      "Epoch 1343/3000\n",
      "8s - loss: 0.9476 - acc: 0.6257 - val_loss: 1.4469 - val_acc: 0.3756\n",
      "Epoch 1344/3000\n",
      "8s - loss: 0.9418 - acc: 0.6279 - val_loss: 1.4538 - val_acc: 0.3665\n",
      "Epoch 1345/3000\n",
      "8s - loss: 0.9464 - acc: 0.6307 - val_loss: 1.4465 - val_acc: 0.3638\n",
      "Epoch 1346/3000\n",
      "8s - loss: 0.9570 - acc: 0.6208 - val_loss: 1.4479 - val_acc: 0.3674\n",
      "Epoch 1347/3000\n",
      "8s - loss: 0.9480 - acc: 0.6284 - val_loss: 1.4490 - val_acc: 0.3692\n",
      "Epoch 1348/3000\n",
      "9s - loss: 0.9447 - acc: 0.6326 - val_loss: 1.4516 - val_acc: 0.3733\n",
      "Epoch 1349/3000\n",
      "9s - loss: 0.9335 - acc: 0.6304 - val_loss: 1.4493 - val_acc: 0.3742\n",
      "Epoch 1350/3000\n",
      "8s - loss: 0.9523 - acc: 0.6284 - val_loss: 1.4583 - val_acc: 0.3715\n",
      "Epoch 1351/3000\n",
      "8s - loss: 0.9377 - acc: 0.6366 - val_loss: 1.4436 - val_acc: 0.3692\n",
      "Epoch 1352/3000\n",
      "9s - loss: 0.9504 - acc: 0.6241 - val_loss: 1.4567 - val_acc: 0.3624\n",
      "Epoch 1353/3000\n",
      "8s - loss: 0.9476 - acc: 0.6258 - val_loss: 1.4510 - val_acc: 0.3724\n",
      "Epoch 1354/3000\n",
      "8s - loss: 0.9533 - acc: 0.6237 - val_loss: 1.4473 - val_acc: 0.3760\n",
      "Epoch 1355/3000\n",
      "9s - loss: 0.9345 - acc: 0.6379 - val_loss: 1.4436 - val_acc: 0.3665\n",
      "Epoch 1356/3000\n",
      "8s - loss: 0.9525 - acc: 0.6238 - val_loss: 1.4527 - val_acc: 0.3688\n",
      "Epoch 1357/3000\n",
      "8s - loss: 0.9379 - acc: 0.6351 - val_loss: 1.4462 - val_acc: 0.3719\n",
      "Epoch 1358/3000\n",
      "8s - loss: 0.9322 - acc: 0.6362 - val_loss: 1.4489 - val_acc: 0.3751\n",
      "Epoch 1359/3000\n",
      "9s - loss: 0.9431 - acc: 0.6343 - val_loss: 1.4435 - val_acc: 0.3756\n",
      "Epoch 1360/3000\n",
      "9s - loss: 0.9467 - acc: 0.6320 - val_loss: 1.4430 - val_acc: 0.3633\n",
      "Epoch 1361/3000\n",
      "10s - loss: 0.9497 - acc: 0.6293 - val_loss: 1.4532 - val_acc: 0.3724\n",
      "Epoch 1362/3000\n",
      "9s - loss: 0.9482 - acc: 0.6294 - val_loss: 1.4444 - val_acc: 0.3756\n",
      "Epoch 1363/3000\n",
      "8s - loss: 0.9408 - acc: 0.6276 - val_loss: 1.4484 - val_acc: 0.3710\n",
      "Epoch 1364/3000\n",
      "8s - loss: 0.9359 - acc: 0.6281 - val_loss: 1.4433 - val_acc: 0.3814\n",
      "Epoch 1365/3000\n",
      "8s - loss: 0.9482 - acc: 0.6275 - val_loss: 1.4471 - val_acc: 0.3683\n",
      "Epoch 1366/3000\n",
      "8s - loss: 0.9376 - acc: 0.6359 - val_loss: 1.4544 - val_acc: 0.3710\n",
      "Epoch 1367/3000\n",
      "8s - loss: 0.9424 - acc: 0.6317 - val_loss: 1.4486 - val_acc: 0.3656\n",
      "Epoch 1368/3000\n",
      "8s - loss: 0.9396 - acc: 0.6265 - val_loss: 1.4531 - val_acc: 0.3602\n",
      "Epoch 1369/3000\n",
      "9s - loss: 0.9543 - acc: 0.6284 - val_loss: 1.4504 - val_acc: 0.3629\n",
      "Epoch 1370/3000\n",
      "8s - loss: 0.9406 - acc: 0.6321 - val_loss: 1.4437 - val_acc: 0.3742\n",
      "Epoch 1371/3000\n",
      "8s - loss: 0.9430 - acc: 0.6301 - val_loss: 1.4535 - val_acc: 0.3665\n",
      "Epoch 1372/3000\n",
      "8s - loss: 0.9425 - acc: 0.6303 - val_loss: 1.4484 - val_acc: 0.3719\n",
      "Epoch 1373/3000\n",
      "8s - loss: 0.9663 - acc: 0.6206 - val_loss: 1.4404 - val_acc: 0.3783\n",
      "Epoch 1374/3000\n",
      "8s - loss: 0.9230 - acc: 0.6438 - val_loss: 1.4521 - val_acc: 0.3683\n",
      "Epoch 1375/3000\n",
      "8s - loss: 0.9386 - acc: 0.6316 - val_loss: 1.4425 - val_acc: 0.3701\n",
      "Epoch 1376/3000\n",
      "8s - loss: 0.9546 - acc: 0.6293 - val_loss: 1.4484 - val_acc: 0.3710\n",
      "Epoch 1377/3000\n",
      "8s - loss: 0.9506 - acc: 0.6291 - val_loss: 1.4418 - val_acc: 0.3756\n",
      "Epoch 1378/3000\n",
      "8s - loss: 0.9431 - acc: 0.6260 - val_loss: 1.4420 - val_acc: 0.3683\n",
      "Epoch 1379/3000\n",
      "8s - loss: 0.9533 - acc: 0.6285 - val_loss: 1.4361 - val_acc: 0.3792\n",
      "Epoch 1380/3000\n",
      "8s - loss: 0.9410 - acc: 0.6286 - val_loss: 1.4435 - val_acc: 0.3751\n",
      "Epoch 1381/3000\n",
      "8s - loss: 0.9540 - acc: 0.6202 - val_loss: 1.4444 - val_acc: 0.3760\n",
      "Epoch 1382/3000\n",
      "8s - loss: 0.9475 - acc: 0.6300 - val_loss: 1.4500 - val_acc: 0.3756\n",
      "Epoch 1383/3000\n",
      "9s - loss: 0.9363 - acc: 0.6320 - val_loss: 1.4517 - val_acc: 0.3679\n",
      "Epoch 1384/3000\n",
      "8s - loss: 0.9507 - acc: 0.6264 - val_loss: 1.4514 - val_acc: 0.3710\n",
      "Epoch 1385/3000\n",
      "9s - loss: 0.9590 - acc: 0.6250 - val_loss: 1.4417 - val_acc: 0.3765\n",
      "Epoch 1386/3000\n",
      "8s - loss: 0.9488 - acc: 0.6253 - val_loss: 1.4441 - val_acc: 0.3674\n",
      "Epoch 1387/3000\n",
      "8s - loss: 0.9537 - acc: 0.6293 - val_loss: 1.4452 - val_acc: 0.3715\n",
      "Epoch 1388/3000\n",
      "8s - loss: 0.9228 - acc: 0.6436 - val_loss: 1.4514 - val_acc: 0.3661\n",
      "Epoch 1389/3000\n",
      "8s - loss: 0.9477 - acc: 0.6263 - val_loss: 1.4480 - val_acc: 0.3701\n",
      "Epoch 1390/3000\n",
      "9s - loss: 0.9402 - acc: 0.6332 - val_loss: 1.4427 - val_acc: 0.3701\n",
      "Epoch 1391/3000\n",
      "8s - loss: 0.9335 - acc: 0.6326 - val_loss: 1.4526 - val_acc: 0.3719\n",
      "Epoch 1392/3000\n",
      "8s - loss: 0.9501 - acc: 0.6283 - val_loss: 1.4467 - val_acc: 0.3656\n",
      "Epoch 1393/3000\n",
      "9s - loss: 0.9293 - acc: 0.6370 - val_loss: 1.4526 - val_acc: 0.3683\n",
      "Epoch 1394/3000\n",
      "8s - loss: 0.9467 - acc: 0.6281 - val_loss: 1.4470 - val_acc: 0.3701\n",
      "Epoch 1395/3000\n",
      "8s - loss: 0.9417 - acc: 0.6285 - val_loss: 1.4537 - val_acc: 0.3647\n",
      "Epoch 1396/3000\n",
      "8s - loss: 0.9522 - acc: 0.6293 - val_loss: 1.4483 - val_acc: 0.3683\n",
      "Epoch 1397/3000\n",
      "9s - loss: 0.9456 - acc: 0.6290 - val_loss: 1.4469 - val_acc: 0.3751\n",
      "Epoch 1398/3000\n",
      "8s - loss: 0.9348 - acc: 0.6345 - val_loss: 1.4470 - val_acc: 0.3778\n",
      "Epoch 1399/3000\n",
      "8s - loss: 0.9220 - acc: 0.6415 - val_loss: 1.4500 - val_acc: 0.3674\n",
      "Epoch 1400/3000\n",
      "8s - loss: 0.9389 - acc: 0.6305 - val_loss: 1.4483 - val_acc: 0.3652\n",
      "Epoch 1401/3000\n",
      "8s - loss: 0.9362 - acc: 0.6282 - val_loss: 1.4477 - val_acc: 0.3805\n",
      "Epoch 1402/3000\n",
      "8s - loss: 0.9535 - acc: 0.6287 - val_loss: 1.4503 - val_acc: 0.3747\n",
      "Epoch 1403/3000\n",
      "8s - loss: 0.9442 - acc: 0.6316 - val_loss: 1.4470 - val_acc: 0.3710\n",
      "Epoch 1404/3000\n",
      "8s - loss: 0.9525 - acc: 0.6283 - val_loss: 1.4497 - val_acc: 0.3670\n",
      "Epoch 1405/3000\n",
      "8s - loss: 0.9323 - acc: 0.6313 - val_loss: 1.4576 - val_acc: 0.3724\n",
      "Epoch 1406/3000\n",
      "9s - loss: 0.9381 - acc: 0.6325 - val_loss: 1.4434 - val_acc: 0.3733\n",
      "Epoch 1407/3000\n",
      "8s - loss: 0.9383 - acc: 0.6318 - val_loss: 1.4500 - val_acc: 0.3747\n",
      "Epoch 1408/3000\n",
      "8s - loss: 0.9219 - acc: 0.6402 - val_loss: 1.4456 - val_acc: 0.3688\n",
      "Epoch 1409/3000\n",
      "9s - loss: 0.9286 - acc: 0.6369 - val_loss: 1.4554 - val_acc: 0.3724\n",
      "Epoch 1410/3000\n",
      "9s - loss: 0.9612 - acc: 0.6254 - val_loss: 1.4448 - val_acc: 0.3710\n",
      "Epoch 1411/3000\n",
      "8s - loss: 0.9603 - acc: 0.6228 - val_loss: 1.4409 - val_acc: 0.3837\n",
      "Epoch 1412/3000\n",
      "8s - loss: 0.9312 - acc: 0.6396 - val_loss: 1.4445 - val_acc: 0.3729\n",
      "Epoch 1413/3000\n",
      "8s - loss: 0.9525 - acc: 0.6279 - val_loss: 1.4460 - val_acc: 0.3692\n",
      "Epoch 1414/3000\n",
      "8s - loss: 0.9501 - acc: 0.6251 - val_loss: 1.4440 - val_acc: 0.3706\n",
      "Epoch 1415/3000\n",
      "8s - loss: 0.9303 - acc: 0.6303 - val_loss: 1.4519 - val_acc: 0.3719\n",
      "Epoch 1416/3000\n",
      "8s - loss: 0.9311 - acc: 0.6299 - val_loss: 1.4470 - val_acc: 0.3774\n",
      "Epoch 1417/3000\n",
      "9s - loss: 0.9488 - acc: 0.6303 - val_loss: 1.4400 - val_acc: 0.3792\n",
      "Epoch 1418/3000\n",
      "8s - loss: 0.9349 - acc: 0.6374 - val_loss: 1.4425 - val_acc: 0.3756\n",
      "Epoch 1419/3000\n",
      "8s - loss: 0.9410 - acc: 0.6279 - val_loss: 1.4534 - val_acc: 0.3724\n",
      "Epoch 1420/3000\n",
      "8s - loss: 0.9520 - acc: 0.6256 - val_loss: 1.4434 - val_acc: 0.3724\n",
      "Epoch 1421/3000\n",
      "8s - loss: 0.9336 - acc: 0.6385 - val_loss: 1.4509 - val_acc: 0.3602\n",
      "Epoch 1422/3000\n",
      "8s - loss: 0.9403 - acc: 0.6348 - val_loss: 1.4464 - val_acc: 0.3747\n",
      "Epoch 1423/3000\n",
      "8s - loss: 0.9542 - acc: 0.6259 - val_loss: 1.4451 - val_acc: 0.3710\n",
      "Epoch 1424/3000\n",
      "9s - loss: 0.9306 - acc: 0.6394 - val_loss: 1.4452 - val_acc: 0.3697\n",
      "Epoch 1425/3000\n",
      "8s - loss: 0.9378 - acc: 0.6311 - val_loss: 1.4396 - val_acc: 0.3733\n",
      "Epoch 1426/3000\n",
      "8s - loss: 0.9405 - acc: 0.6284 - val_loss: 1.4411 - val_acc: 0.3747\n",
      "Epoch 1427/3000\n",
      "8s - loss: 0.9458 - acc: 0.6332 - val_loss: 1.4408 - val_acc: 0.3810\n",
      "Epoch 1428/3000\n",
      "8s - loss: 0.9273 - acc: 0.6297 - val_loss: 1.4370 - val_acc: 0.3701\n",
      "Epoch 1429/3000\n",
      "8s - loss: 0.9364 - acc: 0.6311 - val_loss: 1.4354 - val_acc: 0.3796\n",
      "Epoch 1430/3000\n",
      "8s - loss: 0.9393 - acc: 0.6356 - val_loss: 1.4448 - val_acc: 0.3769\n",
      "Epoch 1431/3000\n",
      "9s - loss: 0.9517 - acc: 0.6269 - val_loss: 1.4474 - val_acc: 0.3738\n",
      "Epoch 1432/3000\n",
      "10s - loss: 0.9417 - acc: 0.6326 - val_loss: 1.4569 - val_acc: 0.3765\n",
      "Epoch 1433/3000\n",
      "9s - loss: 0.9449 - acc: 0.6316 - val_loss: 1.4463 - val_acc: 0.3733\n",
      "Epoch 1434/3000\n",
      "9s - loss: 0.9473 - acc: 0.6318 - val_loss: 1.4544 - val_acc: 0.3692\n",
      "Epoch 1435/3000\n",
      "8s - loss: 0.9365 - acc: 0.6372 - val_loss: 1.4436 - val_acc: 0.3751\n",
      "Epoch 1436/3000\n",
      "8s - loss: 0.9493 - acc: 0.6289 - val_loss: 1.4554 - val_acc: 0.3710\n",
      "Epoch 1437/3000\n",
      "9s - loss: 0.9406 - acc: 0.6305 - val_loss: 1.4507 - val_acc: 0.3729\n",
      "Epoch 1438/3000\n",
      "8s - loss: 0.9400 - acc: 0.6345 - val_loss: 1.4563 - val_acc: 0.3715\n",
      "Epoch 1439/3000\n",
      "8s - loss: 0.9482 - acc: 0.6286 - val_loss: 1.4494 - val_acc: 0.3738\n",
      "Epoch 1440/3000\n",
      "8s - loss: 0.9403 - acc: 0.6314 - val_loss: 1.4620 - val_acc: 0.3688\n",
      "Epoch 1441/3000\n",
      "8s - loss: 0.9503 - acc: 0.6304 - val_loss: 1.4516 - val_acc: 0.3670\n",
      "Epoch 1442/3000\n",
      "8s - loss: 0.9248 - acc: 0.6420 - val_loss: 1.4582 - val_acc: 0.3706\n",
      "Epoch 1443/3000\n",
      "9s - loss: 0.9508 - acc: 0.6217 - val_loss: 1.4460 - val_acc: 0.3706\n",
      "Epoch 1444/3000\n",
      "9s - loss: 0.9427 - acc: 0.6351 - val_loss: 1.4480 - val_acc: 0.3692\n",
      "Epoch 1445/3000\n",
      "8s - loss: 0.9394 - acc: 0.6321 - val_loss: 1.4505 - val_acc: 0.3670\n",
      "Epoch 1446/3000\n",
      "8s - loss: 0.9484 - acc: 0.6286 - val_loss: 1.4477 - val_acc: 0.3733\n",
      "Epoch 1447/3000\n",
      "8s - loss: 0.9363 - acc: 0.6366 - val_loss: 1.4584 - val_acc: 0.3661\n",
      "Epoch 1448/3000\n",
      "10s - loss: 0.9300 - acc: 0.6347 - val_loss: 1.4478 - val_acc: 0.3701\n",
      "Epoch 1449/3000\n",
      "9s - loss: 0.9434 - acc: 0.6283 - val_loss: 1.4476 - val_acc: 0.3719\n",
      "Epoch 1450/3000\n",
      "10s - loss: 0.9316 - acc: 0.6422 - val_loss: 1.4483 - val_acc: 0.3701\n",
      "Epoch 1451/3000\n",
      "9s - loss: 0.9356 - acc: 0.6349 - val_loss: 1.4502 - val_acc: 0.3688\n",
      "Epoch 1452/3000\n",
      "9s - loss: 0.9331 - acc: 0.6391 - val_loss: 1.4432 - val_acc: 0.3715\n",
      "Epoch 1453/3000\n",
      "9s - loss: 0.9366 - acc: 0.6345 - val_loss: 1.4519 - val_acc: 0.3679\n",
      "Epoch 1454/3000\n",
      "8s - loss: 0.9426 - acc: 0.6325 - val_loss: 1.4369 - val_acc: 0.3706\n",
      "Epoch 1455/3000\n"
     ]
    }
   ],
   "source": [
    "if model_type == \"CNN-non-static\":\n",
    "    embedding_layer = model.get_layer(\"embedding\")\n",
    "    embedding_layer.set_weights(embedding_wts)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(), metrics=[\"accuracy\"])\n",
    "\n",
    "res = model.fit(x_train, y_train, \n",
    "          batch_size = batch_size,\n",
    "          epochs=3000,\n",
    "          validation_data=(x_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('say done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Computing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 26.5422498704\n",
      "Testing Accuracy 26.9683257919\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "predictions = model.predict(x_train)\n",
    "pred_train = np.argmax(predictions, axis=1)\n",
    "train_label = np.argmax(y_train, axis=1)\n",
    "print('Training Accuracy', np.sum(pred_train == train_label) / N_train * 100)\n",
    "\n",
    "# # Training Accuracy\n",
    "# predictions = model.predict(x_valid)\n",
    "# pred_valid = np.argmax(predictions, axis=1)\n",
    "# valid_label = np.argmax(y_valid, axis=1)\n",
    "# print('Validation Accuracy', np.sum(pred_valid == valid_label) / N_valid * 100)\n",
    "\n",
    "# Test Accuracy\n",
    "predictions = model.predict(x_test)\n",
    "pred_test = np.argmax(predictions, axis=1)\n",
    "test_label = np.argmax(y_test, axis=1)\n",
    "print('Testing Accuracy', np.sum(pred_test == test_label) / N_test * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "date = str(datetime.date.today() )\n",
    "time = str(datetime.datetime.now().time())[:-7]\n",
    "\n",
    "filename = '/home/shikhar/Datasets/Models/32_' + model_type + '_' + date + '_' +time;\n",
    "with open( filename, 'wb') as output:\n",
    "    pickle.dump([model.get_config(), model.get_weights(), model.history.history], output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAGRCAYAAADYce9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xl8E2XiBvBnJkdzNC09gVIOOUq1XBVhUTwAcV2Xy12g\nKui6ul4o6HrCCsLigYKgorKoLMp6IAK6LO6qrIs/UBQVBUSLXMphKVdJjzR3Zub3xyTTpBdp6ZHA\n8/185jNnJm/ytpkn77wzERRFUUBEREREMUts7QIQERERUf0Y2IiIiIhiHAMbERERUYxjYCMiIiKK\ncQxsRERERDGOgY2IiIgoxjGwEVGrmz17NnJyclq7GGeNgwcPQhRFfPHFF61dFCKKEgMbETXa0KFD\ncdttt9VY3tBA8OCDD+LLL79s6uLVye124/HHH0ffvn1htVqRnp6OCy+8EC+++CI8Hg8ANUSKoohr\nr722xuMNBgNef/11bb5Lly4QRREfffRRxHZvvvkmRDE2P2YFQWjtIhBRA8TmJwkRxb2GBAKLxYLU\n1NRmLE0Vh8OBiy66CIsWLcKUKVOwefNmfPvtt3jggQewatUq/Pe//9W2NZlMWL16Nb766qt69ykI\nAsxmMx566CGE34tcEIRGBSO/39/gxzQU75lOFF8Y2IioWYQHgkAggPvuuw8dO3aEyWRCVlYWJkyY\noK2fPXs2evToUWN+7dq1OPfcc5GYmIihQ4di3759Ec/x9ttvo3v37jCbzbj44ovxn//855Qtew8/\n/DD27NmDr776Crfccgv69OmDzp07Y+zYsdi4cSOGDBmibZudnY2xY8fi/vvvP+XrveWWW3Dw4EG8\n+uqr0bw9mlBr5PLlyzFixAgkJiZi5syZAIDbbrsN3bt3h8ViQbdu3TB9+nT4fL4Gv08rV65Ejx49\ntPdpx44dDSojEbU+BjYianbPP/88Vq9ejeXLl2Pfvn14//33MWjQoIhtqrdEHTlyBC+99BLefvtt\nbN68GQ6HA3/605+09d9++y2uv/56TJw4ETt27MBDDz2EP//5z/W2aCmKgrfffhvXX389OnXqVOs2\nSUlJEfNPPfUUvvnmG/zzn/+s9zW2bdsWDz30EB555BG43e56t63NtGnTMHHiRBQWFuKOO+6Aoiho\n27YtVqxYgV27dmHhwoVYtmwZnnzyyYjHnep92rZtG6677jpcc8012LFjBx544AHcc889PCVKFGf0\nrV0AIjrzHTp0CDk5ObjkkksAqC1X/fv3r/cxPp8Pb775pnaq9KGHHsKECRPg8/lgNBrx7LPP4uKL\nL8bs2bMBAD169MCRI0dw55131rnPkpIS2O12nHvuuVGX/ZxzzsGdd96JqVOnYvTo0dDpdHVue999\n92Hx4sWYN28eZs2aFfVzAMAdd9wR0eoIAI899pg23alTJzz44INYvHhxxL5P9T4988wzuPDCC/H4\n448DUN+nw4cP4+67725Q+YiodbGFjYia3U033YQdO3age/fumDRpEt57771T9tPKysqK6NeWlZUF\nRVFw/PhxAMDOnTtrtNJdeOGF9fbNCq1raOvSI488gpKSEixevLje7cxmMx577DEsWLAAx44dq7G+\nV69esNlssNls6N27d8S6AQMG1Nh+yZIlGDRoENq1awebzYa//OUvOHjwYMQ20bxPgwcPjnjMxRdf\nzD5sRHGGgY2IGi05ORnl5eU1lpeVlQFQO+0DQN++fXHgwAEsWLAACQkJ+POf/4x+/fqhsrKyzn0b\njcaI+VDIkmW5xrJoZWRkICUlBYWFhQ16XEpKCqZPn45HH30UFRUV9W77xz/+Ed26dcOMGTNqrPvw\nww/x3Xff4bvvvsMHH3wQsc5qtUbMr1q1CpMnT8Z1112HDz/8ENu3b8fMmTNrBN1TvU+KovD0J9EZ\ngIGNiBotNzcX3377bY3Wmq+++gp6vR7du3fXllksFowZMwbPPfcctmzZgh9//BEbN25s9HOfd955\n2Lx5c8SyzZs31xtOBEHAhAkT8NZbb9VoqQqpK5BNmTIFNpsNTzzxxCmfY968eXjttdfw/fffR6zr\n2LEjunbtiq5du6Jjx4517gMAPvvsM5x//vm45557kJ+fj27dumH//v31PqY2eXl5+PzzzyOWbdq0\niSGOKM4wsBFRo9155504duwYbrrpJmzduhU///wz3n77bcycORM333yz1oF//vz5WL58OXbu3IkD\nBw5g6dKl0Ov1Db5ZbngwvO+++/D5559j1qxZ2Lt3L9auXYtnnnkGQP0tb0888QR69OiBQYMGYcmS\nJdixYwcOHDiAf/7zn7jsssuwYcOGWh9nNBrxxBNP4Pnnn49o5avNFVdcgeHDh+OFF15o0OsL17Nn\nT3z//fdYu3Ytfv75ZyxcuPCUFz6EhL9P9957LzZv3owZM2Zg7969+Oc//6m9T0QUPxjYiKjROnXq\nhC+++AKlpaUYPXo0+vbti6eeegpTp07FokWLtO2SkpLw7LPP4qKLLkKfPn3wr3/9C++9917ErTyi\nER7Ezj//fLz11ltYvnw5+vTpg7lz5+KJJ56AoijaqdjaJCUlYfPmzbjzzjvxwgsv4MILL0T//v0x\nb948XHvttbjyyivrfOy1116Lvn371mhRrC0gzp8/Hz6fL6qWrNq2uf3223HDDTfg5ptvxvnnn48t\nW7ZoF1g0ZH/nn38+li9fjnfeeQd9+vTBvHnz8Nxzz0W1HyKKHYLSQj1PFy9ejK1btyI5ORnz58+v\nsd7lcuGFF15ASUkJZFnGqFGjIu6HRER0Kq+//jr+9Kc/4eTJkzVuz0FEFM9arIVt6NChmD59ep3r\n161bh44dO+Lpp5/GrFmz8Prrr0OSpKj23dAOxBRbWH/xq7XrbsGCBdi6dSsOHDiAlStXYtq0aSgo\nKGBYi1Jr1x+dHtZf/GpM3bVYYMvNza1xFVQ4QRC0m016PB7YbLZ673cUjn+08Y31F79au+527NiB\nUaNG4dxzz8WMGTPwhz/8AUuXLm3VMsWT1q4/Oj2sv/jVmLqLmRvn/uY3v8HcuXNx++23w+Px4M9/\n/nNrF4mIYtw//vGP1i4CEVGLiJmLDrZv345zzjkHL7/8MubOnYulS5fC4/G0drGIiIiIWl3MtLBt\n2LABV199NQCgXbt2yMzMxOHDh9GtW7ca2xYWFkY0JxYUFLRYOanpsf7iF+suvrH+4hvrL34VFBRg\n5cqV2nxeXh7y8vLqfUyLBjZFUer8OZT09HR8//33yM3NRVlZGY4cOYK2bdvWum1tL6y4uLjJy0st\nw2azweFwtHYxqBFYd/GN9RffWH/xKysrq8GBu8Vu67Fw4ULs3LkTDocDycnJKCgoQCAQgCAIGD58\nOEpLS/G3v/0NpaWlAICrr74aF198cdT7Z2CLX/zQiV+su/jG+otvrL/4lZWV1eDHtFhga24MbPGL\nHzrxi3UX31h/8Y31F78aE9hi5qIDIiIiIqodAxsRERFRjIuZq0SbQ2JiYlS/40ctS1EUVFZWtnYx\niIiI4sYZHdgEQeD5/Rhks9lauwhERERxhadEiYiIiGIcAxsRERFRjGNgIyIiIopxDGxnCFmWkZOT\nw/vRERERnYHO6IsOYllOTo52BavL5YLRaIROp4MgCJg7d672u6rREkURe/bsaY6iEhERUStjYGsl\n4eHqwgsvxPz58zF48OA6t5ckCTqdriWKRkRERDGGp0RjgKIoqP4LYfPmzcOkSZNw1113ITc3F++9\n9x6+/fZbjBo1Cueddx769++PmTNnQpIkAGqgy87OxuHDhwEAU6ZMwcyZM3HDDTegZ8+eGDNmDIqK\niup8/ttuuw35+fnIy8vD+PHjsW/fPm292+3GrFmzMHDgQJx33nkYN24c/H4/AODLL7/EqFGjcO65\n52LgwIF47733muMtIiIiOqsxsMWwdevW4fe//z127dqF0aNHw2Aw4LHHHkNhYSHWrFmDDRs24I03\n3tC2r36T4DVr1mDq1KnYuXMnsrKyMG/evDqf64orrsAXX3yBbdu2ITc3F3fffbe2btasWdi9ezc+\n+OADFBYWYurUqRBFEYcOHcKNN96IO+64A4WFhVi3bh1yc3Ob/o0gIiI6yzGwxbABAwbg8ssvBwAk\nJCSgT58+6NevHwRBQMeOHTFhwgR8+eWX2vbVW+lGjBiBXr16QafT4Xe/+x127txZ6/MIgoDx48fD\nbDbDaDTi3nvvxY4dO+B2uyHLMlavXo3HH38c6enpEAQBAwYMgE6nw3vvvYehQ4dixIgREEURKSkp\nOO+885rvDSEiIjpLnfV92KRbR5/2PnRL1jZBSWrKysqKmN+3bx8effRRfP/993C73ZAkCfn5+XU+\nPjMzU5s2m81wOp21bifLMubMmYMPPvgApaWlEAQBgiDAbrdDr9fD7/ejU6dONR5XXFyMzp07N/LV\nERERUbTO+sDWXGGrKVQ/xTlt2jT0798fL7/8MsxmM1566SWsX7/+tJ9n1apV2LBhA1atWoUOHTrA\nbrejT58+AICMjAwYjUYcPHgQPXr0iHhcVlYWfvzxx9N+fiIiIqofT4nGkcrKSthsNpjNZuzduxdv\nvvlmk+zX6XTCaDSiTZs2cLlceOqpp7SwKIoixo8fj1mzZuHEiROQZRlbtmyBJEkYO3YsNm7ciA8/\n/BCSJMFut9d52pWIiIgaj4EtBlRvSavLzJkzsXLlSvTs2RN/+ctfMGbMmDr3E+0+AeCaa65BZmYm\nzj//fFx++eUYOHBgxPpZs2ahe/fu+M1vfoNevXph7ty5UBQFHTt2xLJly7Bo0SLk5eXhqquuwu7d\nu6N+XiIiIoqOoFTvqR6narvDv81mg8PhaIXSUH2q1wvrKX6x7uIb6y++sf7iV/U+6tFgCxsRERFR\njGNgIyIiIopxDGxEREREMY6BjYiIiCjGMbARERERxTgGNiIiIqIYx8BGREREFOMY2IiIiIhiHAPb\nGUKWZeTk5NR6A+FTOXDgALKzs5uhVERERNQUzvoff28tOTk52s9HuVwuGI1G6HQ6CIKAuXPn4uqr\nr27Q/kRRxJ49expdnob8lBURERG1LAa2VhIeri688ELMnz8fgwcPrnN7SZKg0+laomhEREQUYxjY\nYoCiKKj+k67z5s3D/v37IYoi1q9fj8ceewxdu3bFX//6V/z0008wm80YMWIEZs2aBZ1OB0mS0Llz\nZ3z11Vfo0KEDpkyZgpSUFOzfvx9ff/01cnNzsWjRoqhOfR45cgTTpk3DN998g9TUVEyePBnXXHMN\nAGDr1q14+OGHceDAAZjNZowbNw7Tp0+H2+3Ggw8+iA0bNkCWZXTt2hVvvPEGUlJSmuU9IyKi2CDL\nMrxeL3w+X41x+LQkSTAajVENjW2gUBQFgUAAfr8fgUBAG8LnZVnWjrmh429dg9FohMVigdls1sai\n2Dq9yRjYYti6deuwZMkSLFq0CF6vF7t378Zjjz2Gvn37oqioCBMnTkTXrl3xxz/+EUDN05pr1qzB\n8uXLce6552Ly5MmYN28enn/++VM+76RJk9CnTx/8/e9/x+7du3HdddehS5cu+NWvfoVHHnkEkyZN\nwpgxY+ByubSWwnfeeQcejwdbt26FwWDADz/8AJPJ1OTvCRFRuEAggIqKCm1wOBwoLy+Hw+GAXq9H\nYmJirUNrHnirUxQFkiRBlmUA6md56PM8fBy+vKmeNxAIwOv1wuv1wuPxaNM+nw9+v18LXdWH0Dqv\n1xsRxBISEiKmQ/Oh99vv98PtdqO8vLzOfft8vhqvufrrrz4vSRL8fj8kSYJer9cGg8EQMa/X6yGK\nYp37rr5fv98Pl8ulDV6vVwtx4YPZbEaHDh0a9aPu0WJgi2EDBgzA5ZdfDgBISEhAnz59tHUdO3bE\nhAkT8OWXX2qBrXor3YgRI9CrVy8AwO9+9zvMmzfvlM956NAhfPfdd1ixYgUMBgN69eqFa665Bu++\n+y5+9atfwWAwYP/+/SgtLUVKSgr69esHADAYDLDb7fj555+Rm5uL3r17N8VbQGcoRVHg8/ng8Xjg\ndru1cWgIfSharVZYrVbtIGu1WmOya4Asy/D5fBBFUTsgtNTzhg60oYOtJEl1HpCqL/d6vZBlGSaT\nqcn7sSqKAlmWIUkSAoEAJEnShtB8aBxqzQi1fNQ1SJIEp9MZEdC8Xi8SExORlJSkDd26dUNSUhIC\ngQAqKytRWVkJu92OQ4cOobKyEk6nEx6PBxaLRfvbMhqNEWc7apuub76+x4S/9toGWZYhiqL2t13X\n84UTBAF6vR46na5GIAkNOp0OBoMBOp1OC2bhoczj8UAQBC1YmUymiJAVGqxWKwwGQ52tYQaDocn/\nfsL/Lup6X8OHUDgL9QVvLrIsw+PxRIQ4l8ulfXY1p7M+sI15a9dp7+NfE3OboCQ1VU/q+/btw6OP\nPorvv/8ebrcbkiQhPz+/zsdnZmZq02azGU6n85TPeezYMaSmpka0jmVnZ2P9+vUAgGeeeQbz58/H\npZdeis6dO+O+++7DsGHDUFBQgOPHj+OOO+5AZWUlxo4di6lTp8bMN9gziaIo2oEqdBAGUO9BWqfT\nwWg0tsjFJX6/H5WVlXA4HBFDZWVlRCjT6XQwm80wmUwwm80R0zabDT6fDxUVFSguLobT6URlZSVc\nLhcSEhJqDXHRHBQlSYIgCDCbzdoBKnw6NJjNZhiNRgCAx+OB0+nUhtABP3ze7XZDr9dDlmUEAoGI\ng2nogFp9OlQv4ePq06Eh1CoRCmahwefzwWg0RpRdFMWIAASg1iAUej+cTif8fj9MJpPWUhB++ic0\n6PX6iNNd9Q2h018Aan3t4ePQa6zt77b637UoirBarejSpQuSkpJgs9mQmJjYqL/r0GsPBTq/31+j\n9Saa6Wi2C73++oZoX0MouMiyDIvFgtLS0ohTf6EgXH3Q6/U1QpnJZIJeH5sxIBa/mAHq32OoVa2l\ntVhNLV68GFu3bkVycjLmz59f6zaFhYX4xz/+AUmSkJSUhFmzZjV7uZorbDWF6v/A06ZNQ//+/fHy\nyy/DbDbjpZde0oJUU2nXrh3sdjvcbjfMZjMA4PDhw2jfvj0AoGvXrvjb3/4GAFi7di1uvfVW/Pjj\njzAajbj33ntx7733oqioCBMmTECPHj0wbty4Ji3f2UaSJNjtdpw4cQIlJSU4ceIETpw4AYPBALPZ\nXG9rRPhBOvShHX6aoq4h9AEe/o2+rtYEg8GAkpKSiGDm9/uRmJgIm82mDVlZWUhMTNRCQGMPFIqi\nwOVyRQSnyspKBAIBrTXBZDJFBKHqQ+gbcmgoLS2tEYQ8Ho92ADcYDBEtfVarFampqejYsaO2zGKx\nRLSORNOyFNpGlmVtqGveZrMhIyMjIpiFDryn86XIZrPB4XBAkiQtSIe3FrhcLpSXl8PtdiMQCNT4\nW0lMTIyYDz8l1pItjY2h0+m0Frl4EjouhL6EtUZwoNbRYoFt6NChuOqqq/Diiy/Wut7lcmHp0qWY\nMWMGUlNTUVFR0VJFixuVlZWw2Wwwm83Yu3cv3nzzTS1Ina7QQbhjx47o06cPnnrqKUyfPh179uzB\nO++8g1deeQUA8O6772Lo0KFITU2FzWbTvh1//vnnSE9PR05ODiwWi9Y0XZtQkIjFW4mETtVVP2iF\njz0eT1SdVkPrqoek8G+44cuMRiMqKioigllZWRmSkpKQkZGBjIwMdOnSBenp6Y36kA6dtquvZaS0\ntDSipQGouz8NoLbcJiUloUOHDlo4M5vNzVa3giBo4Sm8Bbk5hE7JNDRYhreohFrpYp1Op9NaLIko\nNrVYYMvNzcWJEyfqXL9p0yb86le/QmpqKgA0ybee6uf8Y1W0B7eZM2di2rRpeOGFF9C7d2+MGTMG\nX3/9da37aegBM3z7xYsXY+rUqcjPz0dKSgoefvhhDBo0CADwySefYPbs2fD5fMjOzsZLL70EvV6P\nY8eOYdq0aTh+/DisVivGjBlT573kjhw5gn/84x/Q6/Xa1UDhrUFA3X1B9Hp9jVaGugZRFGtcrVTX\n1Uvhfaj0en2N00IWiwVt2rRB+/bttX2fqrNqeKfV8H4jXq8XDocDJSUlNZbbbDakp6ejffv26NOn\nD9LS0prslIUoitp701RCLTRnolg9JUNEZydBacFUc+LECcydO7fWU6LLli2DJEkoKiqCx+PBVVdd\nhUsvvTTqfYff4d/j8WDXrl1aaw/FFpvNhvLycu0qI6vVCqfTGVU/kUAgUOPUldfr1Tqqh8Yej0e7\ncqn6VUt1XckU3leHonMmB7azAesvvrH+4ldjriaNmSOTLMvYv38/Zs6cCa/XixkzZiAnJwft2rWL\n6vGKouDIkSP44Ycf8PPPP6NLly4YOHCgdnkwxRZRFLWgFDq1Go1Qh3MiIqKzScwEttTUVCQlJWmt\nHueeey4OHDhQa2ArLCxEYWGhNl9QUIAVK1ZoV01eddVVWidgBrbYo9PpYLPZtHmj0RgxT/GDdRff\nWH/xjfUX31auXKlN5+XlIS8vr97tWzSw1XYvmZABAwbg1VdfhSzL8Pv92Lt3L0aOHFnrtrW9sEsu\nuQQdOnSAIAiQJAkOh4N/yDEqVD8hbNaPX6y7+Mb6i2+sv/hls9lQUFDQoMe0WGBbuHAhdu7cCYfD\ngUmTJqGgoEC7X9Hw4cPRoUMH9O3bFw888ABEUcTw4cOj+hmlkIZsS0RERBRPWvSig+YUftFBCL99\nxKbq9cJ6il+su/jG+otvrL/41ZiLDmL3roZEREREBICBjYiIiCjmMbARERERxTgGtjhVVFSE7Oxs\n7cedb7jhBqxevTqqbYmIiCi+MLC1kokTJ2LBggU1lq9btw75+flRhavwn5N644036v2h9Vj83U4i\nIiKKDgNbKykoKMC7775bY/m7776LsWPHRn3nfyIiIjrzMRW0kiuvvBJlZWURP95eXl6O9evXay1l\n69evx5VXXonc3FwMHDgQzzzzTJ37GzduHFasWAFA/ZmvRx99FL1798bgwYPxv//9r96yLFq0CIMH\nD0bPnj0xbNgwfPTRRxHr33rrLQwZMkRb/8MPPwBQb6Vy6623ok+fPujduzceeeSRRr0XREREVL+Y\n+Wmqs43JZMLIkSOxevVqDBw4EACwdu1adO/eHbm5uQAAq9WK559/Hj179sSuXbtw3XXXoVevXvj1\nr39d777ffPNNfPLJJ/j4449hNptxyy231Lt9ly5dsGbNGmRkZOD999/HlClT8MUXX2jzzz77LF57\n7TX07t0bBw8ehF6vhyzLuPHGG3HJJZfghRdegCiK+O6775rmzSEiIqIIbGFrRePHj8f7778Pr9cL\nQD0dOn78eG39oEGD0LNnTwBAbm4uRo8ejc2bN59yv//+979xyy23oF27dkhOTsaUKVPq3X7EiBHI\nyMgAAIwaNQrnnHMOtm3bBgBYsWIF7rzzTvTu3RsA0LlzZ3To0AHbtm3D8ePHMWPGDJhMJhiNRgwY\nMKDhbwIRERGd0lnfwvb+O2WnvY9R17Rp1OMGDBiAtLQ0rFu3Dv369cOOHTuwdOlSbf22bdswZ84c\n7N69G36/Hz6fr87fVw137NixiLsod+jQod7tV61ahSVLlqCoqAgA4HK5UFpaCkA97dm5c+cajyku\nLkZ2djb72hEREbWAsz6wNTZsNZWxY8di1apV+Omnn3DppZciLS1NWzd58mTcfPPNWL58OQwGA2bN\nmqUFqfpkZmZG/FTX4cOH69z28OHDmDp1KlauXIkLLrgAAPDrX/8aoV8sy8rKwsGDB2s8LisrC4cP\nH4YsywxtREREzYxH2lY2fvx4bNq0CcuXL484HQoATqcTycnJMBgM2LZtG9asWROxvq6fgR01ahRe\nffVVHDlyBGVlZVi0aFGdz+9yuSAIAlJTUyHLMt555x3s3r1bW3/dddfhpZdewvfffw8AOHDgAA4f\nPoz8/HxkZmZizpw5cLvd8Hq92LJlS2PfBiIiIqoHA1sry87ORv/+/eF2u2tcTDBnzhw8/fTTyM3N\nxcKFCzF69OiI9eH3VgufnjhxIi677DJcccUV+O1vf4vf/va3dT5/jx49cPvtt2PUqFHo168fdu/e\nHdEXbeTIkbj77rtx1113oWfPnrjllltQVlYGURSxbNky7N+/HwMGDMCAAQPw/vvvn+7bQURERLUQ\nlLqaaeJM+CnAEJvNBofD0QqlofpUrxfWU/xi3cU31l98Y/3Fr/B+5tFiCxsRERFRjGNgIyIiIopx\nDGxEREREMY6BjYiIiCjGMbARERERxTgGNiIiIqIYx8BGREREFOMY2IiIiIhiHANbnCoqKkJ2djZk\nWQYA3HDDDVi9enVU21Y3aNAgbNq0qdnKSkRERKeHga2VTJw4EQsWLKixfN26dcjPz68zXIUL/zmq\nN954A+PGjYtqWyIiIoovDGytpKCgAO+++26N5e+++y7Gjh0LUWTVEBERkYqpoJVceeWVKCsrw9df\nf60tKy8vx/r167WWsvXr1+PKK69Ebm4uBg4ciGeeeabO/Y0bNw4rVqwAAMiyjEcffRS9e/fG4MGD\n8b///S/qcvl8PsycORP9+/dH//79MWvWLPj9fgCA3W7HjTfeiPPOOw95eXkYO3as9rhFixahf//+\n6NmzJy677DJ8/vnnDXo/iIiIqG761i7A2cpkMmHkyJFYvXo1Bg4cCABYu3YtunfvjtzcXACA1WrF\n888/j549e2LXrl247rrr0KtXL/z617+ud99vvvkmPvnkE3z88ccwm8245ZZboi7XwoULsX37dnz8\n8ccAgJtuugkLFy7EAw88gJdffhlZWVn44YcfoCgKtm7dCgD46aefsGzZMnz00UfIyMjA4cOHIUlS\nY94WIiIiqgVb2FrR+PHj8f7778Pr9QJQT4eOHz9eWz9o0CD07NkTAJCbm4vRo0dj8+bNp9zvv//9\nb9xyyy1o164dkpOTMWXKlKjLtGbNGtx3331ITU1Famoq7rvvPu3UrcFgwPHjx3Ho0CHodDoMGDAA\nAKDT6eD3+7Fr1y4EAgF06NABnTp1ivo5iYiIqH5nfQvb888/f9r7uPvuuxv1uAEDBiAtLQ3r1q1D\nv379sGPJ0BpHAAAgAElEQVTHDixdulRbv23bNsyZMwe7d++G3++Hz+fDyJEjT7nfY8eOISsrS5vv\n0KFD1GU6evRoxPYdOnTAsWPHAACTJk3CggULMGHCBAiCgAkTJuCuu+5Cly5dMHv2bDzzzDPYs2cP\nhgwZgpkzZ6Jt27ZRPy8RERHV7awPbI0NW01l7NixWLVqFX766SdceumlSEtL09ZNnjwZN998M5Yv\nXw6DwYBZs2ahtLT0lPvMzMxEcXGxNn/48OGoy9OuXTsUFRWhR48e2mNDwctqtWLmzJmYOXMm9u7d\ni3HjxqFfv34YPHgwxowZgzFjxsDpdOKhhx7CnDlzsHDhwqifl4iIiOrGU6KtbPz48di0aROWL18e\ncToUAJxOJ5KTk2EwGLBt2zasWbMmYr2iKLXuc9SoUXj11Vdx5MgRlJWVYdGiRVGXZ8yYMVi4cCHs\ndjvsdjuee+457eKC//3vfzhw4AAAwGKxQK/XQ6fT4aeffsLnn38On88Hg8EAk8kEnU7XgHeBiIiI\n6nPWt7C1tuzsbPTv3x+7du2qcTHBnDlzMHv2bMyYMQODBg3C6NGjUV5erq0Pv7da+PTEiROxf/9+\nXHHFFUhKSsLtt9+OL774os4yhD/2nnvuQWVlJYYPHw5BEDBy5EitFXL//v2YMWMG7HY7kpOTceON\nN2LQoEH48ccf8eSTT2Lfvn3Q6/W44IILMG/evNN+b4iIiEglKHU108SZ8FOAITabDQ6HoxVKQ/Wp\nXi+sp/jFuotvrL/4xvqLX+H9zKPVYqdEFy9ejFtvvRUPPPBAvdvt27cP1157Lb766qsWKhkRERFR\nbGuxwDZ06FBMnz693m1kWcby5cvRr1+/FioVERERUexrscCWm5sLq9Va7zYfffQRBg0ahKSkpBYq\nFREREVHsi5mrRO12O7Zs2YIrrriitYtCREREFFNiJrAtW7YMEydO1K5YPEOuhSAiIiI6bTFzW4+f\nf/4Zzz33HBRFgcPhwLZt27RbRFRXWFiIwsJCbb6goAA2m63GdrwXWGzS6XQR9WU0GmutP4p9rLv4\nxvqLb6y/+LZy5UptOi8vD3l5efVu36KBTVGUOlvOXnzxRW36b3/7G/r3719rWANqf2G1XdrMP+TY\nJEkSb+txhmDdxTfWX3xj/cUvm82GgoKCBj2mxQLbwoULsXPnTjgcDkyaNAkFBQUIBAIQBAHDhw9v\nludUFIWhLQbxdDcREVHDnNE3zqX4wG+J8Yt1F99Yf/GN9Re/YvrGuURERETUOAxsRERERDGOgY2I\niIgoxjGwEREREcU4BjYiIiKiGMfARkRERBTjGNiIiIiIYhwDGxEREVGMY2AjIiIiinEMbEREREQx\njoGNiIiIKMYxsBERERHFOAY2IiIiohjHwEZEREQU4xjYiIiIiGIcAxsRERFRjGNgIyIiIopxDGxE\nREREMY6BjYiIiCjGMbARERERxTgGNiIiIqIYx8BGREREFOMY2IiIiIhiHAMbERERUYxjYCMiIiKK\ncQxsRERERDGOgY2IiIgoxjGwEREREcU4BjYiIiKiGMfARkRERBTjGNiIiIiIYhwDGxEREVGMY2Aj\nIiIiinH6lnqixYsXY+vWrUhOTsb8+fNrrN+0aRP+9a9/AQBMJhNuvfVWdOrUqaWKR0RERBSzWqyF\nbejQoZg+fXqd6zMzMzF79mw8/fTTGDt2LF5++eWWKhoRERFRTGuxwJabmwur1Vrn+pycHFgsFgBA\njx49YLfbW6poRERERDEtJvuwrV+/Hv369WvtYhARERHFhJgLbD/88AM2bNiAiRMntnZRiIiIiGJC\ni110EI2DBw/ilVdewcMPP4zExMQ6tyssLERhYaE2X1BQAJvN1hJFpGZgNBpZf3GKdRffWH/xjfUX\n31auXKlN5+XlIS8vr97tow5sDofjtP8wFEWBoii1rispKcGCBQswefJktGvXrt791PbCHA7HaZWN\nWo/NZmP9xSnWXXxj/cU31l/8stlsKCgoaNBjog5skyZNQp8+fXDppZfiggsugF7fsMa5hQsXYufO\nnXA4HJg0aRIKCgoQCAQgCAKGDx+O1atXo7KyEkuXLoWiKNDpdHjyyScb9BxEREREZyJBqavJq5qK\nigps2rQJn332GY4ePYpBgwbhsssuQ25ubnOXMSrFxcWtXQRqJH5LjF+su/jG+otvrL/4lZWV1eDH\nRB3YwhUXF+PTTz/FZ599BkEQcMkll2DYsGHIyMhocAGaCgNb/OKHTvxi3cU31l98Y/3Fr8YEtkZd\nJVpWVoaysjK43W60bdsWdrsdDz30ENasWdOY3RERERFRPaLuiPbLL7/gs88+w2effQaTyYTLLrsM\n8+fPR2pqKgBg7NixePDBB3H11Vc3W2GJiIiIzkZRB7ZZs2Zh8ODBuP/++9G9e/ca6zMzM/Hb3/62\nSQtHRERERA3owxYIBBp8ZWhLYh+2+MV+GPGLdRffWH/xjfUXv5q1D9vrr7+O3bt3RyzbvXs3li1b\n1uAnJSIiIqLoRR3YPv/8c3Tr1i1iWdeuXbFp06YmLxQRERERVYk6sAmCAFmWI5bJslznLxcQERER\nUdOIOrDl5uZixYoVWmiTZRmrVq2KmRvnEhEREZ2por6K4KabbsJTTz2F22+/Henp6SgpKUFKSgqm\nTp3anOUjIiIiOutFHdjS0tIwd+5c7Nu3DydPnkRaWhq6d+8OUWzUvXeJiIiIKEoNuk+HKIrIyclp\nrrIQERERUS2iDmwulwurVq3Czp074XA4Ii42WLx4cbMUjoiIiIgacNHB3//+d+zfvx/jxo1DZWUl\nbr75ZqSnp2PEiBHNWT4iIiKis17UgW3Hjh24//77MWDAAIiiiAEDBuDee+/FZ5991pzlIyIiIjrr\nRR3YFEWBxWIBAJhMJjidTrRp0wZHjx5ttsIRERERUQP6sHXu3Bk7d+5E7969kZubi6VLl8JkMqF9\n+/bNWT4iIiKis17ULWy33347MjIyAAA333wzjEYjnE4nJk+e3GyFIyIiIqIoW9hkWcaGDRvw+9//\nHgCQlJSEO+64o1kLRkRERESqqFrYRFHEunXroNPpmrs8RERERFRN1KdEL7vsMnz88cfNWRYiIiIi\nqkXUFx3s27cPH330EdauXYu0tDQIgqCtmz17drMUjoiIiIgaENguv/xyXH755c1ZFiIiIiKqRdSB\nbciQIc1YDCIiIiKqS9SB7ZNPPqlz3bBhw5qkMERERERUU9SBrfpPUJWVleHo0aPIzc1lYCMiIiJq\nRlEHtlmzZtVY9sknn+Dw4cNNWiAiIiIiihT1bT1qM2TIkHpPlRIRERHR6Yu6hU2W5Yh5n8+HTz/9\nFFartckLRURERERVog5s1113XY1lqampuP3225u0QEREREQUKerA9uKLL0bMJyQkICkpqckLRERE\nRESRog5sOp0ORqMRiYmJ2rLKykr4fD6kpqY2S+GIiIiIqAEXHTz99NOw2+0Ry+x2O+bPn9/khSIi\nIiKiKlG3sBUXF6NTp04Ryzp16hT1bT0WL16MrVu3Ijk5uc6Q9+qrr2L79u1ISEjAXXfdhS5dukRb\nPCIiIqIzVtQtbElJSTh69GjEsqNHj8Jms0X1+KFDh2L69Ol1rt+2bRuOHTuG559/HrfddhuWLFkS\nbdGIiIiIzmhRB7ahQ4diwYIF+Pbbb1FUVIRvvvkGCxYsiPpXDnJzc+u9BciWLVtw2WWXAQB69OgB\nl8uFsrKyaItHREREdMaK+pTo1VdfDb1ejzfeeAMnT55Eeno6hg4dipEjRzZJQex2O9LS0rT51NRU\n2O12tGnTpkn2T0RERBSvog5soihi9OjRGD16dHOWJ4IgCLUuLywsRGFhoTZfUFAQ9alZij1Go5H1\nF6dYd/GN9RffWH/xbeXKldp0Xl4e8vLy6t0+6sC2Zs0a9OrVC927d9eW7du3D4WFhRgzZkwjihop\nNTUVJ0+e1OZPnjyJlJSUWret7YU5HI7TLgO1DpvNxvqLU6y7+Mb6i2+sv/hls9lQUFDQoMdE3Yft\ngw8+QHZ2dsSy7OxsfPDBB1E/maIoUBSl1nUXXHABNm7cCADYs2cPrFYrT4cSERERoQEtbIFAAHp9\n5OZ6vR4+ny+qxy9cuBA7d+6Ew+HApEmTUFBQgEAgAEEQMHz4cJx//vnYtm0bpkyZApPJhEmTJjXs\nlRARERGdoaIObF27dsW6deswYsQIbdl///tfdO3aNarH33PPPafc5k9/+lO0xSEiIiI6a0Qd2G68\n8UY8/vjj+PTTT9G2bVscO3YMZWVleOSRR5qzfERERERnPUGpq1NZLTweD7799lucPHkSaWlp6N+/\nP0wmU3OWL2rFxcWtXQRqJHacjV+su/jG+otvrL/4lZWV1eDHRN3CBgAmkwmDBw/W5n/55Rds3LgR\n119/fYOfmIiIiIii06DABgAVFRXYtGkTPv30U+zfvx/5+fnNUS4iIiIiCooqsAUCAXz77bfYuHEj\ntm/fjrS0NJSWluLJJ5+M+qIDIiIiImqcUwa2pUuX4osvvoBOp8OgQYPw17/+FTk5ObjtttsifkqK\niIiIiJrHKQPbf//7XyQmJmL8+PEYPHgwLBZLS5SLiIiIiIJOGdheeOEFfPrpp1i7di2WLVuG/Px8\nXHzxxXX+YgERERERNa0G3dbjxx9/xMaNG/Hll1/C7XZj6NChGDlyZI2frGoN3+87CKNOhFEnwKAT\nINbxw/EUe3hpevxi3cU31l98Y/3Fr8bc1qNBgS3E5/Ph66+/xsaNG/HDDz/g7bffbvATN7Vfv/gp\nfJIMv6TALynQiwKMOiEY4MSwaQE6QYBeFKATBegEqGNRgF4QIIpQ1wkCdCKgEwSIwW3EiOnq6wCf\npMATkOENqGOPX4ZHCo4DCrySDLdfhjcgw6gXkZSgQ1KCDskmHZIS9GHTOiSb9Np6i0GEcAYHUH7o\nxC/WXXxj/cU31l/8apbAtmLFCuTn5yMnJ6fW0GC325GamtrgJ25q4TfOVRQFflmBLxjefJIMn6QE\nBxmyDAQUBZKsQApOy7KCgKxAUgBJm1YgB+dlBeq8DG25HNxHaJ1RJ8KkF5CgF2HWi0jQq/MmvRgx\nJOgF+CQFFV4J5Z4AKrwSKjwSyr1ScDqAcq8Eh1dCuUeCUScgJ92M3HQzctJN6JFmhtkgNsv7KMlq\n2HT51XDp8stwB2T4JBnpFgPaJhqQaNQ16XPyQyd+se7iG+svvrH+4lez3Dg3ISEBb731Fo4cOYLe\nvXsjPz8f/fr1g81mA4CYCGvVCUKoda21S1K/9rbotitx+bG7xI3dJ9x467sSHCjzoL3NiJ7pZm3I\nshlqDdQBWUGpO4CTrgBOuv2wu0LTAZR5AlooUwOaBJ+kwBQMnGaDCEtw0IsCTroDOOLwQy8CbRON\naJeoBrh2icbg2IB0qwF6MfrWQJl9IYmIiE4p6lOiTqcT3333HbZu3YodO3YgMzMT+fn5yM/Pj4l7\nsZ1NP03ll2T8XOrFnhI3dpW4safEDXdAQU6aCRlWA+zuAE66/DjpCqDSJyEpQY80ix6pZnWcZjYg\n1aJHilmvBTKLQQ1oJr1Yb/8/RVHg8Eo4WunH0Uo/jlX6gmN12u6WkGLSQScKwRbIYEtksBVSmw+2\nZgKAQScg0SDCatQh0aiDLaFqOtEoBsfqYDKop7MNogi9CBh04WMBBjF02htn9GnkWMFv+PGN9Rff\nWH/xq8X6sCmKgn379mHbtm3Ytm0b7HY7brzxRlx00UUNLkBTOZsCW21OuvzYU+JBqSegBbNUsx5t\nTHroGtDidbr8koKTLj8UAKIAiEJYX8FgH0FdcFlovdFsxZGTZaj0yaj0Saj0SXD6ZDi8oWlJW+cN\nyPDL6qnugKye+g5IwXHYclkBLEYRGRYDMqwGZFr1wbFBGyebdHWGOkVR4JWUiFPWFcFT1m6/jMQE\nEW1M+uCg9jlMNJ7ZfQ1rwwNGfGP9xTfWX/xqscBWXXl5OVwuF9q3b3+6u2q0sz2wxbPm+NCRZAVO\nv4wTTj+OO/0RY3U6AG9ARkYwwNmMIhw+GRWhgOaVAADJCTokmXSwJejV6QQdzAYRDq+EMo/aBzE0\n9koKkhN0aGPWoY1Jj2STDskJepgNar/FBJ3arzFBJ8CoCy4Lzifo1QtjfJICp0+Gy6+GVmdw7PJL\ncPrliHVGnaC2mFoMSA8G9HSL2npqbaELVXjAiG+sv/jG+otfzfrj7//+97/Rq1cvdOnSBXv27MGz\nzz4LnU6Hu+++Gzk5OUhOTm7wkxM1F50oaFfZdks11bqN2y/jhMuPE5V+OHxScPuqq3UT9A27sMMn\nySj3SCjzBLRxmUdtFXS6JHglBd6ADK+kwBcce6uNjToBVoMIi1EHq0GE1SjCatBprYVd2oROYevg\nk2S1P6IrgMLjLpS4ArC7AihxBQAoSLMYkBZsbbUYRARkwC8r2kU1oSHUSikpVa2ToiBAH2wN1YsC\nRFGAPnhFdOgKa70IWBISYBQk2ILvtXpKOzgET2MbdLUHR0lWgv0npYi+lKELXmRFgSgIEAS1tRZQ\nyyUAwWXqtCgAEKAuD04EF2nTCK4L7cugU19H6DS6XhccV5sXBUG7wCh8rChhFyIpQOhrrznYtaAh\n/TiJiKIRdWD7z3/+g2HDhgEA3n77bYwcORJmsxnLli3DnDlzmq2ARM3FbBDRKTkBnZITmmR/Rp2I\nDKuIDKuhSfZ3Olx+CSWhC0xcfrj9ckRIqW8QBWjhTZIRDHGR86H1oiEBJyucKPdI+KXcp53GdgSv\ncq70STDqRK1fojegwO2X4PKrp7bNBhEWvRpALcaqvpTmYF9KBVWBSIGijhVARlVokhVAXVsVnKqm\nlYhlQNVV4H4ZCMgyAhKCp9RldZkUHAdftxgRDtXT+qIgQETVaX9RUPcfusJaLwoRF+5oY73aQms1\nitpV16HT9E115bcS7DMaCAbxQLCuAlJ4UFfXZwb0sAlKnaGaiGJH1IHN5XLBYrHA7XbjwIEDeOSR\nRyCKIl5//fXmLB8RNYLFoEOnZF2ThdG6nOqUjKKorWgOr3pKN0EnwGJU7y2YoBPOyD5/iqLeQij8\ntjjhrYju4KntQ+VefHO4EseDp+tNehGZ1qoQlxkW5vySggpvAI7g6XqHT+1X6QiG4wpv1dgnKVWt\no6GQXmNaXe/0H8XxSh8yEw3ITjKiY3ICspOMyE42Ijspod4QKckK7O4Ajlf6tddw3OnH8Uo/yjwB\nRNvXRgBg0oeFdYMuLMiLWqtlaFq9X2bkvTDFsLFOrJo3BUNzY2+krigKHD4ZdpcfdncgeEFXALKi\noG3Y1fEpZj1v1k7NLurAlpaWht27d+OXX37BueeeC1EU4XK5IIrNcz8wIop/giDAatTBGuv32GlC\ngiBo/RPbmKN7jKIoKPNIOO5Ur7g+7vTjQKkXXxVVosTph1GnnuIPnXq2JejQMTkhYj40bkgQttls\nOFlWjuIKH4oqfCgq9+Gb4kr8a5cPhyt8SErQITs5AR2TjLAaRRx3BrS+oCddASQn6JCZWHUhT890\nMy7unIQUky7qACMrCjwBJSLYhsJtefCKdLdfhjugtswG5GqnqKvdGzN0VbosK9oNyy3Bq9CtoXHw\n6vPweb+k4KRb7VYQCmd2VwBGvYA0s9pHNNViQKpZD1EAth9xalfKu/yyFrbV2x1V3faojVkPv6SW\nwxeo2Q3CG1DvExq6oMqoE4L366y6j2dC2D08Q/f4TNCJwfuAKsFuAvW/36EWaa0bRNhFWhGDpMCg\nE7WbuDe0a0iIJCso81SFXLs7AE9AVt/HYH/bNIu+0ftvLoqioNih3kprT4kbChB2wZoemdbWC+hR\nB7brr78ezzzzDPR6Pe6//34AwNatW9G9e/dmKxwR0dlAEASkmNVb7fRMjzLlNRGjTkSXFBO6pET2\n9ZRkBSecfhRV+PBLuRcuv4zzMswYck4SMq3qhS4GXWwdbGsT6isZuvpcvZAn8qKewxU+6EUB6RY9\nctLMakALXsgTTaDwBGQcq/TjaKUvOPZjx1E10JV7AhEXGWnTtYz1ogCnT1KDZiD4SzmhaW0Ihr2A\nrHYXqKU8oX6e4dOSrI61fpqhPpvVukroREHrj1vhlaAXhapf4EnQIcmk1y7GSk5Qr7QP3UYqvBWy\nwhtAolEXvGOBGnRNegH77V6cdFdtb9AFA3HYxVNpFj2STXpI1W6AH7pDgLpMDbqhfrlpwS4GbRMN\naGuN/p6gbr+MvSfVW2TtPuHG7pMeJOgE7R6nelHAcacfP9s92pcVp09GmkVfddeBYGt4jzQTOjbj\nWY3Tuko0EAgAAPT6qHNfs+FVovGLVzrFL9ZdfGP9xbfq9acodfflDN1iqSFCXRoqgr+6U+4NVP0q\nT/AXeaBAC7ehq9ZTg18+ThWYwk85h27oHgp/obBoCP2spFj1M5NVy8Tgb4cDdldAbfF0+nHM4UOp\nR0KaRY+21rAgl2hEhkWPI5XBm9GXuFFc4cM5KSbkZpjRM92EnulmpFnq74fsDQQvWHMG1LsOVKpB\nrnc7C4Z3axPVe9usV4kWFRUhMTERbdq0gcfjwdq1ayGKIkaNGhUTgY2IiOhsJgQvjkGNnNS403fh\nXRqi/WWehu4/dDV/l5Sm3bdfUlDi8ke0fH75iwPHnX5kWg3IzTBjWNdkdE1JaHBLcYJeRHZSArKT\nmrePcHVRJ62FCxfi3nvvRZs2bfD666/jyJEjMBgMeOWVVzBlypTmLCMRERFR1Aw6Ae1tRrS3GQFY\nW7s4TSLqwHbixAlkZWVBURRs2bIFCxYsgNFoxOTJk5uzfERERERnvagDm8FggNvtRlFREdLS0pCU\nlARJkuD3+5uzfERERERnvagD2+DBg/Hoo4/C7XbjN7/5DQBg//79yMzMbLbCEREREVEDAtsf//hH\nfPfdd9DpdOjVqxcAtcPgjTfe2GyFIyIiIqIGBDYA6Nu3L0pKSrBnzx6kpqaiW7duzVUuIiIiIgqK\nOrCVlpbiueeew969e5GYmAiHw4GcnBzcc889SE1Nbc4yEhEREZ3Vor75yJIlS9C5c2e8+uqreOWV\nV/Daa6+hS5cuWLJkSXOWj4iIiOisF3Vg2717N/7whz/AZFJ/vsRkMuH666/Hnj17mq1wRERERNSA\nwGa1WlFUVBSxrLi4GBaLpckLRURERERVou7DNnr0aDz22GMYNmwYMjIycOLECWzYsAHXXHNN1E+2\nfft2LFu2DIqiYOjQobj66qsj1peUlGDRokVwuVyQZRkTJkxAfn5+9K+GiIiI6AwUdWAbPnw42rVr\nh02bNuHQoUNISUnB5MmTsWvXrqgeL8syli5dipkzZyIlJQV/+ctfMGDAAHTo0EHb5r333sNFF12E\nK664AkVFRXjyySexaNGihr8qIiIiojNIg27r0atXL+0ebADg9/sxZ86cqFrZ9u3bh/bt2yMjIwOA\neiPeLVu2RAQ2QRDgdrsBAC6Xi1efEhEREaGBge102O12pKWlafOpqanYt29fxDbjx4/H448/jg8/\n/BBerxePPPJISxWPiIiIKGZFfdFBcxAEIWJ+06ZNGDJkCBYvXoxp06bhhRdeaKWSEREREcWOU7aw\n/fDDD3WuCwQCUT9RamoqSkpKtHm73Y6UlJSIbf7v//4P06dPBwDk5OTA7/ejoqICSUlJEdsVFhai\nsLBQmy8oKIDNZou6LBRbjEYj6y9Ose7iG+svvrH+4tvKlSu16by8POTl5dW7/SkD2+LFi+tdn56e\nHlXBunfvjqNHj+LEiRNISUnB559/jnvuuafGvnbs2IEhQ4agqKgIfr+/RlgDan9hDocjqnJQ7LHZ\nbKy/OMW6i2+sv/jG+otfNpsNBQUFDXqMoCiK0kzlqWH79u147bXXoCgKhg0bhquvvhorV65Et27d\n0L9/fxQVFeHll1+Gx+OBKIq4/vrr0bt376j2XVxc3Mylp+bCD534xbqLb6y/+Mb6i19ZWVkNfkyL\nBrbmxMAWv/ihE79Yd/GN9RffWH/xqzGBrVUvOiAiIiKiU2NgIyIiIopxDGxEREREMY6BjYiIiCjG\nMbARERERxTgGNiIiIqIYx8BGREREFOMY2IiIiIhiHAMbERERUYxjYCMiIiKKcQxsRERERDGOgY2I\niIgoxjGwEREREcU4BjYiIiKiGMfARkRERBTjGNiIiIiIYhwDGxEREVGMY2AjIiIiinEMbEREREQx\njoGNiIiIKMbpW7sAREREp6IE/MCJo4DeAFhtgNkCQRBau1hxQZEkQBTP+vdLkSXA5wV0BggGw+nt\nS1EArxtwVgKVDsDpAJJTIXTo1ESlrYmBjYiI6qVIEuD3AgnmZj/oK7IElBwDDh+CcvggcPigOi45\nBqSkAZKkHiADPsCSqIa3RBtgtUFItAHWJG0eCSYIer0a8nR6IDRd5zg46HRxG26UgB8oPgTlwD7g\n4D51XHwI0OmAtEwgLRNCWiaQHhyntQXSMgBbcq2vWQsmjgqgogxwlENxlGvTkAJAghkwmQGzBTCZ\nIZjUsTpYAHNw2pAAyJL6GElWx7Kk1mlo0NZLQMAP+H2A3w8lOIbfp9a9v2od/D7A6wG8HijBccTg\n8wAej7pPoxEIBNQXp5XRDCSYtGkhIWy5FAAqHVCcDjWcOYPhzFmp/t1YEwGL+jcoDBrCwEZERM1L\nURT1AHysGMrRIuDYYShHDwPHDgMlxwFRBAQBaJMGtEmFkJwKpKQCbVKB5DQIKalAsjovGIzqPuXg\nQdnvCx58g0PAB/iDy71uKEd+qQpoR34BbMlAVicIHToDfQdA/O14oF0Hbb9AMJhorRsVVQfV0Pyx\nYsDvgxzwqwfousZSoKpsgeCgKGEBTg8YDJGBzmQCEpMgWG1AYpI2CLakiHmY1ICr+LxAeak6VJRC\n0abLoJTZ1fBTbgdcTiCpDdAmDUJKmhpQ26RFzienQNCrrUOKJEEp2l8znKW3hdC5O9ClO8SLLgey\nzzjcFXgAAB5wSURBVFGD0MnjwMnjUEqOAyePQf55t1q3J4+rdZGWqYY3QawKZI5yQABga6OWzZYM\nwZYMJCWr2+v1gMetDhVlgMcN2eOqWqYNLvU5RJ0aHnW64LRe/dvS6ast1wEGo/reG4xq3esNEctg\nMAAWK6BvowauBBPE4LjWwWDUQqni91eVyxtZVsXjVoOex62+vnbZEBOT1HBmDY0TI/4eW4KgKIrS\nos/YTIqLi1u7CNRINpsNDoejRZ5LkWWgohSwlwClJ6GUnlCnXU7AbAWsVvWbuSURgjWx6hu8JRGw\nWCHodC1STq28kqQefBwOoLI8+O22ouqbrSCoH66CEDmEDq6hdXp95DfH0LfJBJP6DdhkAvSGBrcq\n1FZ3iiyrH4LOSvV9dVUCrkoobpf6gak9d82y1PX+KgE/4PWqH6xeb9U3Zp8Hisejnubwe9Wxzxec\n92nzSvi8LAUPEmEHDp0OQujgoROr1ofeRyA4FtSDV/g0wt7z0AHdEDkWQgeY0DKdAVBkQA4O4dPa\nMkmbVgJ+9XX5fcGxt2o++Lq0FghAfZ9Dz2WoXqaqciQE/PAe+rkqmEFQg1HbDhFjZLaHYDCqdVhm\nB8pOqkEjYvqkOl9eqv69SQE1ENV4P4yR80YThPbZVQEtqxMEs6VBf4dNTZElNVAGwkJceKDzuAGn\nA0qlA6is0AalskJtiaqsCLYC+tXXGAgAySlq4ElOhZDcBkhKAdqkQEhKUdclp6ifQY4yoNQOpbRE\ne0+VUvXzCqFwZ01UA+HJ40BKOoQu3YHO3SB07gF0PAeCydzw1+xxASdPqC2ZgBqabclAUhv1f5aa\nVFZWVoMfw8BGra4pA5vi9agfOCXH1G+RpSVAaQkUuzpGuV39UEzNUD/oUtPVb62WRMDt0sIFnJVQ\nQs3frmDwcDvVcGFJVJv+zRbAbFUPLmarNh9aJ1isaigJtTD4fVCqH2yrzStOR/ADv1wdu53qN8jE\nZMCWpH67DU0bjMEDvaK2CChycFxtXlbUFg2PB0rom2ToVIHHXfXtUlHU12dMCJ4+MlQFGm1aX3Vq\nSaeDwWCE31GuhjO3Ux17XFXvk8UaDL2J6mmSgD/y22t4eTwewKBX3zNjgnr6wudRAxpCZTOp4TJ8\nnJAAwWhST3UYE9TTLtq0OhbC50VdradlFO20TEANSqExFECB+v6EphF6j8OmI1qTAlWnawJ+9dt8\n6PROqGUnFPJCgxA2rYVFERAFCHqj+poMoXFCjXnBaFTDEJTgc4aev1oLV9hpJmNyMnwpGRDaZavB\nLDHptE8FKrKs1mewdSpeTy02Ba0OmrC/nSJLamirKIftnO6olOQm2S+1rMYENp4SpUZTFEU92DrK\n1W+UjuA3TGeFegCLaP1RDzw1WoREEb5Em7ovY4J6ADYmVAUHYwKQoAYIQRDUg6r9RDCQHasKZyeO\nqtMet9pMn9EOQpoaypDdGWJKBpCarp5aaGRn04iWI7crODjVVge3U513VgAlRwG3C7LbqZZHp9cO\nrIIhLDiEDrbWJKCNATAaIVptEeEM1kS15acFqK1YwSAXCi6B/2/v3mPjKA9+j/9mZm++rO21nYQk\nPsFASPvG6UlEsApEJSVpyxFCQKvWqK1S0eYPVFFISksgRVyiuirlUkAKogXRhleoAqt/pCISR1Ub\nUqSUqPAGlNYoB7lcG2ISe+P4tteZOX/M7MWXJE5I1rPO9yNt5rKT3Wf3eebZ3zwz6y27lqSwrnh9\nSV7hWFS2TD+U+eGs5sxGIl3X9YJrZtwLb6FQ8VRG4RTQuTTXYsVMXk9NPK78WR7dNkzTO2iBt7+f\n5dNmhmmVTpPW1nmj7zgvENgCyM3nS9c0DCW9EJSZfD2Af569cCvcn8+VjtSLIekky/5IyeQRFKOw\nvjCaYhjeqFNh+L8w7B8Ke+Gi/BqOurg3QlA+4uM4U0eB/NM9OUNyxkb901cZ/yLRjH/qy7+5jvfh\nnct6pxJaF8hoXSDNWyB9YbXM1gVS6wXe8L15bv5ajWH6waS2fuL6c/JslWcUTufVxWf8fyLxuDJn\n6QPDMAwvnEejUsNZeUgAmDPmTGBz/nt7WSDQ9FPJP63hm26IurjOkOR64al4OqH8mymF0w2l0x7F\n00B1ce96p8J8YeShLu6tq63zrjkpXANyPOnN+wFNYyPeKEtTs3eBqX/xqmI13uO1zJeiNTLLv+FS\nuBVPkxVOlZVfI+OWTf3rY/yRkgmjKXbOG8nKl42mOI5UWycz3li6oDbecFYuuqybwSlRN5/3To9F\nohUZbQEAIEjmTGBT+1JvxEjyRo8KFwJPd5NKwW26S/jK1pnlF8lO/nZKKFI2H/JGhIrXPBWugfKv\ngxoZlvoPySlcDxWJymjyv1V14VKZK71wpqZmKd5U8YvbJwvaqJH31fz6U28IAMAcNGcCm3n1/5nt\nIvink0qhImihBwAAVCd+mgoAACDgCGwAAAABR2ADAAAIuIpew/b2229rx44dcl1X11xzjW666aYp\n2/z973/XH//4RxmGoQsvvFB33HFHJYsIAAAQOBULbI7j6LnnntP999+vRCKhrVu3qrOzU4sXLy5u\n09/frz/96U/q7u5WbW2thoeHK1U8AACAwKrYKdG+vj4tXLhQ8+bNUygU0po1a/TGG29M2OYvf/mL\nrr32WtXWen8lu6GBv54JAABQsRG2ZDKplpaW4nJzc7P6+vombHP48GFJ0n333SfXdfXNb35Tq1at\nqlQRAQAAAmlWv3Qw+cdwbdtWf3+/tm3bpjvuuEO//e1vNT4+PkulAwAACIaKjbA1NzdrYGCguJxM\nJpVIJCZs09LSomXLlsk0Tc2fP1+LFi1Sf3+/Lr744gnb9fb2qre3t7jc1dWleHzmv3+IYIlEItRf\nlaLuqhv1V92ov+rW09NTnO/o6FBHR8dJt69YYFu6dKn6+/t19OhRJRIJ7d27V5s2bZqwTWdnp/bu\n3au1a9dqeHhYhw8f1vz586c81nQv7FS/RYngis/gt0QRTNRddaP+qhv1V73i8bi6urpO6/9ULLCZ\npqmNGzequ7tbrutq3bp1amtrU09Pjy655BKtXr1aq1at0oEDB3TnnXfKsixt2LBB9fX8fiQAADi/\nGa473a+fV59PPvlktouAM8RRYvWi7qob9VfdqL/qtWjRotP+P/zSAQAAQMAR2AAAAAKOwAYAABBw\nBDYAAICAI7ABAAAEHIENAAAg4AhsAAAAAUdgAwAACDgCGwAAQMAR2AAAAAKOwAYAABBwBDYAAICA\nI7ABAAAEHIENAAAg4AhsAAAAAUdgAwAACDgCGwAAQMAR2AAAAAKOwAYAABBwBDYAAICAI7ABAAAE\nHIENAAAg4AhsAAAAAUdgAwAACDgCGwAAQMAR2AAAAAKOwAYAABBwBDYAAICAI7ABAAAEHIENAAAg\n4AhsAAAAAUdgAwAACDgCGwAAQMBVNLC9/fbb2rx5szZt2qSdO3eecLt9+/bp5ptv1nvvvVfB0gEA\nAARTxQKb4zh67rnndO+99+qxxx7T3r17dejQoSnbpdNpvfLKK7r00ksrVTQAAIBAq1hg6+vr08KF\nCzVv3jyFQiGtWbNGb7zxxpTtXnzxRd14440Kh8OVKhoAAECghSr1RMlkUi0tLcXl5uZm9fX1Tdjm\ngw8+UDKZ1GWXXaaXX365UkWbMcdxlcu6yuVc5TKusjl/Oesqn3NVU2uqMWGpLm7KNI0zeg7XcTV8\n3NGxgbySA3klB20ZhtQ6P6SW+SG1zg8pVsOlhwAAnE8qFtimYxilUOO6rp5//nnddtttZ/x4ruuF\nqfS4q9S4o3TK8af+8rijTMaVYUimKRmGVwbDlExDMkyjdJ8pGZJyOSmXdZTLurJtKRQ2FIkYCpff\nwoZCYUPHP8np3d60UilH8QZLjU2WGhKWGpq8Wzg8NcTlc66ODfrhbMDWUDKvaMxUc2tIrQtCurQj\nJteRBo/kdfjjnP61P6VI1FCrH95a5ocUjQU/wOXzrlJjjsYn3VJjjkKhcVkhR5GIoUjUVDhq+PP+\nLWL6U0OmdWZBeCYcx5XjeFPXkWzbC9COI9m2v86R5LqyQoZCIa/eQyHJChlnHNJPVp5czlXeP0jI\n58qmWVeuK8nw2qkMw2/P3v8tzHvLhqyQFKsxvVvs3L6PJ+K6ruy8lM0WDnQc5XKushn/IChbdsu5\nsixD0ZjXBqIxU9Foab7QHoxJ73k+7yqTdpRJ+9OUq3T5ctp736IxQ7GYqWiN/9gxbxrzp6Fp9lXH\n9sqVzU4sa7bsoM11Xf+1lm6FZbmSK7e4zrIK7cdQKKyy9jTNurAh6yzWWaEu0mlbmYwzo//j2FI2\n4yqbdbwD1oz32rMZx5+W1tl51+snp9mHvf3aLN4fDhuy834bKGvfXnvXlLYfjhjFeoqWTWM13nOc\naD/M57w2kE5P30Ycx+v7TcvwpqZkmkZpapXWhUKGIjHDb5Pe80/XHoOmvH167bFsflL7nCnT8Npp\n0F97Odd1S/uoIzmu17+7ruQ4/v1Oaf8t9bN+vypN2+cWPhfOlYoFtubmZg0MDBSXk8mkEolEcTmV\nSunjjz/Wgw8+KNd1NTQ0pIcfflhbtmzRxRdfPOGxent71dvbW1zu6urSnv87qvExW6Yh1dZbqq0L\nqbbWUm19WM0tlmrqvHWxmOlXlFchjuPKcUsfzK7rTx2vQsMR0+tcoqbCYWNCyDyRXM7RUDKnocGc\njiWzOvxxVkPHcqqpMZVoiaipOax0ytHRTzMaGc6ruSWseQuiWv6/o2pdEFEsZk15zMX/y5s6jquh\nZE6fHs7o8H/SOvA/I6qtC2nBwqgWLIqqqTki05DfsMoalN/IJq+bMdcLLbbtdca27Sqfd+XYrvJl\n62zb61RTY7ZGR/MaG7E1OpJXPueqrt5SXTykunpLDQ0RLVzszYdCYY2NZvxO1PsAGR91NDRYWLaV\nSTvKZhwZZiEge/URDnsfrqVp6T7DNJTLOX7gcfxOf/LUm7fz3p5Z6Jgt0ws1hc7bsgz/Pu/9y+dd\n5f3Akc85yuddmYWyRcxiOUIhb/tim5vQOfrtTIV13nuX9Q8QHMdVOGIqHPE+8MIR058aCoctmZbh\ndcBl4aDYITuFzth7znzOVWo8q9S4rXTKVjhiqqbWUk2tpdpab/8oLIcjRtkHpDPtNJf13j/bTsm2\nHW//mWY/cvz9qLCvmZahaNT0P8An3mprTUUTpsL+h3k+7yqTcpRO20qnHB0/ZiuTsr2QkXKUzTqK\nRL0Q6thSKmXLdfxgWmuppsZSrMZUTW1YTQnvtRVGp9MpR+mUrVTKVnrc0fGkrdR41ls37sgwpFit\npZBlKJv12p5tu6XylpU/GrUUiZqqq/Pa3ISOfco+aBQ7+Hx+YnvMjHtTb93U91tSsR14B4vmhOXC\nfPFMQNbx25LjB0unuC7vB2IrNOI1lBkwLXmvNWb6AdpUNGaprs5bjpStC4UMZTOOMhl/H05789m0\no5Gh0j6dyTjKZRxv3530esIRS5GIqbp6P9xFvP0pl3W9ekvZGhmydcSfT417j+m1CctvF65SKUfp\ncVuuK9XUFu6z/PmwEs3esmUZsm1vv3Ps0oHadMuZjKvhoUJbtJX2+6dI1PQPBKziNBI2vCDglg4G\nC/tFcbn882jyczveYMGU+2xXMoZmXH9SKYBMaZNmeSAxTuujwXa8/t+0Tt03W5Yx5X21Hfmva/Lr\nLIWq4sFOsV/z/in0oyrrXyeG0UnrypYL74Fp+oM2xQGbwiBO6X0p9tflz1s8ICstL1tery9c1jDj\n966np6c439HRoY6OjpNub7iFHv4ccxxHmzZt0v33369EIqGtW7dq06ZNamtrm3b7bdu26Xvf+54u\nuuiiGT3+/zv4sWI15rSjWEHgOq5GRx0ND9kaHrIViRhqbg2pMWF9ptEOx3F1/JitwSN5DRzJa3TE\nmdCgpMlH+u6EBn06LMuQZXkN2rK8I9HyqWX5YccyFKs1VVtXukVjJw678XhcIyMjp3x+1/V26HzO\nC4ulqYrLdr60znXdCSMWlj8aVhrVKLsvpM80QjZ92VQMghNDs4odZemD3bvP8ssVjnjv6UwOEE67\nrI43CuKFlsK0NJ/Pu6VRnunet7KRxXhDndLpcRmGURqZNspGqv2Ra28E+7O9x5M5TmlUxzTlj4x9\n9vesNPrkBXkvSHht5FzUx0wVDoZyJxhxLcyXDmq8aTjijdaFw6X1obB3ADLTfa9alNq2q0zGKY7S\nxmLmOa+/wnNnM/7IXcZVNu3VS/EszuQzOYUzPGVnfEyrfGSvfHRv6shfvGHm9VceyM76a/f3mXz+\n5H2zbeu0Xl/5gY80KWiWjXSV3ze1rzUm9bulfmo2LVq06LT/T8VG2EzT1MaNG9Xd3S3XdbVu3Tq1\ntbWpp6dHl1xyiVavXj3l/5xOlow3TB2VChLDNBRvsBRvsLR4ydl7XNM0lGgJKdES0tL/OnuPG0SG\n4QeHczjkfKaCXLbJDNMonkpqTJx6+5OJx6MaGcmenYKdJtM0FKsxFKs5u49rGF7AqQ8Hq0/xDpgM\nRWOzXZLgKrVtSaps/ZU/d7yxMs/tBZvZ73MK+8x0lxLg7KnYCNu59sknn8x2EXCG5tpR/vmEuqtu\n1F91o/6q15mMsAX/anUAAIDzHIENAAAg4AhsAAAAAUdgAwAACDgCGwAAQMAR2AAAAAKOwAYAABBw\nBDYAAICAI7ABAAAEHIENAAAg4AhsAAAAAUdgAwAACDgCGwAAQMAR2AAAAAKOwAYAABBwBDYAAICA\nI7ABAAAEHIENAAAg4AhsAAAAAUdgAwAACDgCGwAAQMAR2AAAAAKOwAYAABBwBDYAAICAI7ABAAAE\nHIENAAAg4AhsAAAAAUdgAwAACDgCGwAAQMAR2AAAAAKOwAYAABBwBDYAAICAI7ABAAAEXKiST/b2\n229rx44dcl1X11xzjW666aYJ9+/atUu7d++WZVlqaGjQD3/4Q7W2tlayiAAAAIFTscDmOI6ee+45\n3X///UokEtq6das6Ozu1ePHi4jYXX3yxvva1rykSiejPf/6zXnjhBW3evLlSRQQAAAikip0S7evr\n08KFCzVv3jyFQiGtWbNGb7zxxoRtli9frkgkIklatmyZkslkpYoHAAAQWBULbMlkUi0tLcXl5ubm\nkway3bt3a9WqVZUoGgAAQKDN6pcODMOYdv1rr72m9957TzfccEOFSwQAABA8FbuGrbm5WQMDA8Xl\nZDKpRCIxZbsDBw5o586d2rZtm0Kh6YvX29ur3t7e4nJXV5cWLVp09guNionH47NdBJwh6q66UX/V\njfqrXj09PcX5jo4OdXR0nHT7io2wLV26VP39/Tp69Kjy+bz27t2ryy+/fMI277//vp599llt2bLl\npI2wo6NDXV1dxVv5i0b1of6qF3VX3ai/6kb9Va+enp4JOeZUYU2q4AibaZrauHGjuru75bqu1q1b\np7a2NvX09OiSSy7R6tWr9cILLyiTyejxxx+X67pqbW3Vli1bKlVEAACAQKro32FbtWqVnnzyyQnr\nurq6ivP33XdfJYsDAABQFebELx3MZCgRwUX9VS/qrrpRf9WN+qteZ1J3huu67jkoCwAAAM6SOTHC\nBgAAMJcR2AAAAAKuol86OBdO9YPyCJann35a+/fvV2Njox599FFJ0ujoqJ544gkdPXpU8+fP149/\n/GPV1tbOckkx2eDgoLZv366hoSGZpqn169fruuuuo/6qQC6X0wMPPKB8Pi/btnXFFVfoW9/6lo4c\nOaInn3xSo6Ojuuiii3T77bfLsqzZLi5OwHEcbd26Vc3Nzbr77rupvypy2223qba2VoZhyLIs/fKX\nvzztvrOqr2FzHEebNm2a8IPymzdvnvCD8giWgwcPKhaLafv27cXA9sILLygej+vGG2/Uzp07NTY2\npu9+97uzXFJMNjQ0pKGhIbW3tyudTuvuu+/Wli1b9Oqrr1J/VSCTySgajcpxHN1333265ZZbtGvX\nLl1xxRW68sor9eyzz6q9vV1f/epXZ7uoOIFdu3bpvffeUyqV0t13363HH3+c+qsSP/rRj/TQQw+p\nvr6+uO50P/uq+pToTH5QHsHy+c9/XnV1dRPWvfnmm1q7dq0k6ctf/jJ1GFBNTU1qb2+XJMViMS1e\nvFiDg4PUX5WIRqOSvNE227ZlGIZ6e3v1xS9+UZK0du1a/eMf/5jNIuIkBgcH9dZbb2n9+vXFdf/6\n17+ovyrhuq4mj4+dbt9Z1adEp/tB+b6+vlksEc7E8ePH1dTUJMkLBcPDw7NcIpzKkSNH9OGHH2rZ\nsmXUX5VwHEf33HOPPv30U1177bVasGCB6urqZJrecXtLS4uOHTs2y6XEiTz//PPasGGDxsfHJUkj\nIyOqr6+n/qqEYRj6xS9+IcMw9JWvfEXr168/7b6zqgPbdE70g/IAzo50Oq1f//rXuuWWWxSLxWa7\nOJgh0zT18MMPa3x8XI8++qgOHTo0ZRv6z2AqXPfb3t5e/B3t6UZsqL/g6u7uLoay7u7uM/r986oO\nbDP9QXkEW1NTk4aGhorTxsbG2S4STsC2bT322GO6+uqr1dnZKYn6qza1tbVavny53n33XY2Njclx\nHJmmqcHBQfrPgDp48KDefPNNvfXWW8pms0qlUtqxY4fGx8epvypRGElraGhQZ2en+vr6TrvvrOpr\n2Gbyg/IInslHhqtXr9aePXskSXv27KEOA+zpp59WW1ubrrvuuuI66i/4hoeHi6fSstms/vnPf6qt\nrU0dHR3at2+fJOlvf/sbdRdQ3/nOd/T0009r+/bt2rx5s1asWKE77riD+qsSmUxG6XRakneG4sCB\nA1qyZMlp951V/S1RyfuzHr///e+LPyjPn/UItieffFLvvPOORkZG1NjYqK6uLnV2durxxx/XwMCA\nWltbdeedd075YgJm38GDB/XAAw9oyZIlMgxDhmHo29/+tpYuXUr9BdxHH32kp556So7jyHVdXXXV\nVfrGN76hI0eO6IknntDY2Jja29t1++23KxSq6hMvc94777yjl19+ufhnPai/4Dty5IgeeeQRGYYh\n27b1pS99STfddJNGR0dPq++s+sAGAAAw11X1KVEAAIDzAYENAAAg4AhsAAAAAUdgAwAACDgCGwAA\nQMAR2AAAAAKOwAYAZ+jmm2/Wp59+OtvFAHAe4C/sAZgzbrvtNh0/flyWZcl1XRmGobVr1+oHP/jB\nbBcNAD4TAhuAOeWee+7RihUrZrsYAHBWEdgAzHl79uzRX//6V1100UV67bXXlEgktHHjxmKwO3bs\nmJ599lkdPHhQ8XhcN9xwg9avXy9JchxHO3fu1Kuvvqrh4WEtWrRId911l5qbmyVJBw4c0K5duzQy\nMqI1a9Zo48aNkqT+/n795je/0QcffKBQKKQVK1Zo8+bNs/MGAKh6BDYA54W+vj5deeWV+t3vfqd9\n+/bp0Ucf1VNPPaW6ujo98cQTuvDCC/XMM8/oP//5j7q7u7VgwQKtWLFCu3bt0uuvv657771XF1xw\ngT766CNFIpHi4+7fv18PPfSQxsbGdM899+jyyy/XypUr9dJLL2nlypV68MEHlc/n9e9//3sWXz2A\nakdgAzCnPPLIIzLN0vepNmzYINM01djYqOuuu06SdNVVV2nXrl3av3+/li9frnfffVc/+9nPFAqF\n1N7ernXr1um1117TihUrtHv3bm3YsEEXXHCBJGnJkiUTnu/rX/+6ampqVFNTo46ODn3wwQdauXKl\nLMvS0aNHlUwm1dzcrM997nOVexMAzDkENgBzyl133TXlGrY9e/YUT2EWtLa26tixYzp27Jjq6+sV\njUaL982bN0/vv/++JGlwcFALFiw44fM1NjYW56PRqNLptCQvKL744ovaunWr6uvrdf311+uaa675\nzK8PwPmJwAbgvJBMJicsDw4OqrOzU4lEQqOjo0qn04rFYpKkgYEBJRIJSVJLS4v6+/vV1tZ2Ws/X\n2NioW2+9VZJ08OBB/fznP9fy5ctPGv4A4ET4O2wAzgvHjx/XK6+8Itu29frrr+vQoUO67LLL1NLS\nomXLlukPf/iDcrmcPvzwQ+3evVtXX321JGndunV66aWX1N/fL0n66KOPNDo6esrn27dvXzEk1tXV\nyTTNCadqAeB0MMIGYE751a9+JdM0i3+H7Qtf+IIuv/xyXXrppTp8+LA2btyopqYm/eQnP1FdXZ0k\nadOmTXrmmWd06623qr6+XjfffHPxtOr111+vfD6v7u5ujYyMaPHixfrpT396ynL09fVpx44dSqVS\namxs1Pe//33NmzfvnL52AHOX4bquO9uFAIBzac+ePXr11Ve1bdu22S4KAJwRxucBAAACjsAGAAAQ\ncJwSBQAACDhG2AAAAAKOwAYAABBwBDYAAICAI7ABAAAEHIENAAAg4AhsAAAAAff/AbcWS/mtf0QL\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f90bfad7198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.plot(res.history['acc'])\n",
    "plt.plot(res.history['loss'])\n",
    "plt.plot(res.history['val_acc'])\n",
    "plt.plot(res.history['val_loss'])\n",
    "plt.legend(['Train acc','Train loss','Valid acc', 'Valid loss'], loc=2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.title('Using '+ model_type)\n",
    "imgName = 'Images/' + model_type + '_' + date + '_' + time + '.jpg'\n",
    "plt.savefig( imgName, dpi= 200, bbox_inches='tight', transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Continue from a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading saved data\n",
    "import pickle\n",
    "\n",
    "filename = '/home/shikhar/Datasets/Models/3_CNN-static_2017-04-04_11:38:41'\n",
    "with open( filename, 'rb') as input:\n",
    "    out = pickle.load(input)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(), metrics=[\"accuracy\"])\n",
    "model.set_weights(out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9645 samples, validate on 2210 samples\n",
      "Epoch 1/1000\n",
      "15s - loss: 1.6891 - acc: 0.2445 - val_loss: 1.6018 - val_acc: 0.2765\n",
      "Epoch 2/1000\n",
      "8s - loss: 1.5747 - acc: 0.2691 - val_loss: 1.5937 - val_acc: 0.2855\n",
      "Epoch 3/1000\n",
      "8s - loss: 1.5736 - acc: 0.2635 - val_loss: 1.5913 - val_acc: 0.2869\n",
      "Epoch 4/1000\n",
      "8s - loss: 1.5735 - acc: 0.2691 - val_loss: 1.5902 - val_acc: 0.2887\n",
      "Epoch 5/1000\n",
      "8s - loss: 1.5743 - acc: 0.2727 - val_loss: 1.5918 - val_acc: 0.2882\n",
      "Epoch 6/1000\n",
      "8s - loss: 1.5708 - acc: 0.2699 - val_loss: 1.5922 - val_acc: 0.2878\n",
      "Epoch 7/1000\n",
      "8s - loss: 1.5741 - acc: 0.2642 - val_loss: 1.5911 - val_acc: 0.2869\n",
      "Epoch 8/1000\n",
      "8s - loss: 1.5718 - acc: 0.2682 - val_loss: 1.5888 - val_acc: 0.2864\n",
      "Epoch 9/1000\n",
      "8s - loss: 1.5714 - acc: 0.2649 - val_loss: 1.5905 - val_acc: 0.2878\n",
      "Epoch 10/1000\n",
      "8s - loss: 1.5705 - acc: 0.2673 - val_loss: 1.5874 - val_acc: 0.2860\n",
      "Epoch 11/1000\n",
      "8s - loss: 1.5706 - acc: 0.2731 - val_loss: 1.5863 - val_acc: 0.2873\n",
      "Epoch 12/1000\n",
      "8s - loss: 1.5679 - acc: 0.2792 - val_loss: 1.5824 - val_acc: 0.2905\n",
      "Epoch 13/1000\n",
      "8s - loss: 1.5676 - acc: 0.2794 - val_loss: 1.5785 - val_acc: 0.2964\n",
      "Epoch 14/1000\n",
      "8s - loss: 1.5681 - acc: 0.2802 - val_loss: 1.5794 - val_acc: 0.2910\n",
      "Epoch 15/1000\n",
      "8s - loss: 1.5679 - acc: 0.2804 - val_loss: 1.5780 - val_acc: 0.2964\n",
      "Epoch 16/1000\n",
      "8s - loss: 1.5639 - acc: 0.2805 - val_loss: 1.5766 - val_acc: 0.2964\n",
      "Epoch 17/1000\n",
      "8s - loss: 1.5629 - acc: 0.2795 - val_loss: 1.5763 - val_acc: 0.3032\n",
      "Epoch 18/1000\n",
      "8s - loss: 1.5657 - acc: 0.2795 - val_loss: 1.5774 - val_acc: 0.3027\n",
      "Epoch 19/1000\n",
      "8s - loss: 1.5623 - acc: 0.2795 - val_loss: 1.5714 - val_acc: 0.2932\n",
      "Epoch 20/1000\n",
      "8s - loss: 1.5601 - acc: 0.2810 - val_loss: 1.5628 - val_acc: 0.2928\n",
      "Epoch 21/1000\n",
      "8s - loss: 1.5584 - acc: 0.2898 - val_loss: 1.5709 - val_acc: 0.3095\n",
      "Epoch 22/1000\n",
      "8s - loss: 1.5603 - acc: 0.2879 - val_loss: 1.5617 - val_acc: 0.3063\n",
      "Epoch 23/1000\n",
      "8s - loss: 1.5557 - acc: 0.2879 - val_loss: 1.5650 - val_acc: 0.3050\n",
      "Epoch 24/1000\n",
      "8s - loss: 1.5535 - acc: 0.2957 - val_loss: 1.5573 - val_acc: 0.3095\n",
      "Epoch 25/1000\n",
      "8s - loss: 1.5567 - acc: 0.2868 - val_loss: 1.5618 - val_acc: 0.2937\n",
      "Epoch 26/1000\n",
      "8s - loss: 1.5526 - acc: 0.2872 - val_loss: 1.5611 - val_acc: 0.3054\n",
      "Epoch 27/1000\n",
      "8s - loss: 1.5512 - acc: 0.2899 - val_loss: 1.5510 - val_acc: 0.3081\n",
      "Epoch 28/1000\n",
      "8s - loss: 1.5483 - acc: 0.2916 - val_loss: 1.5528 - val_acc: 0.3136\n",
      "Epoch 29/1000\n",
      "8s - loss: 1.5491 - acc: 0.2917 - val_loss: 1.5534 - val_acc: 0.3050\n",
      "Epoch 30/1000\n",
      "8s - loss: 1.5452 - acc: 0.2991 - val_loss: 1.5536 - val_acc: 0.3100\n",
      "Epoch 31/1000\n",
      "8s - loss: 1.5475 - acc: 0.2977 - val_loss: 1.5520 - val_acc: 0.3072\n",
      "Epoch 32/1000\n",
      "8s - loss: 1.5459 - acc: 0.2974 - val_loss: 1.5462 - val_acc: 0.3113\n",
      "Epoch 33/1000\n",
      "8s - loss: 1.5423 - acc: 0.2993 - val_loss: 1.5484 - val_acc: 0.3149\n",
      "Epoch 34/1000\n",
      "8s - loss: 1.5400 - acc: 0.2989 - val_loss: 1.5489 - val_acc: 0.3149\n",
      "Epoch 35/1000\n",
      "8s - loss: 1.5376 - acc: 0.3024 - val_loss: 1.5457 - val_acc: 0.3190\n",
      "Epoch 36/1000\n",
      "8s - loss: 1.5344 - acc: 0.2995 - val_loss: 1.5443 - val_acc: 0.3208\n",
      "Epoch 37/1000\n",
      "8s - loss: 1.5397 - acc: 0.2964 - val_loss: 1.5411 - val_acc: 0.3222\n",
      "Epoch 38/1000\n",
      "8s - loss: 1.5301 - acc: 0.3092 - val_loss: 1.5423 - val_acc: 0.3186\n",
      "Epoch 39/1000\n",
      "8s - loss: 1.5268 - acc: 0.3109 - val_loss: 1.5365 - val_acc: 0.3235\n",
      "Epoch 40/1000\n",
      "8s - loss: 1.5274 - acc: 0.3111 - val_loss: 1.5330 - val_acc: 0.3226\n",
      "Epoch 41/1000\n",
      "8s - loss: 1.5228 - acc: 0.3111 - val_loss: 1.5436 - val_acc: 0.3235\n",
      "Epoch 42/1000\n",
      "8s - loss: 1.5226 - acc: 0.3186 - val_loss: 1.5405 - val_acc: 0.3213\n",
      "Epoch 43/1000\n",
      "8s - loss: 1.5210 - acc: 0.3159 - val_loss: 1.5385 - val_acc: 0.3253\n",
      "Epoch 44/1000\n",
      "8s - loss: 1.5173 - acc: 0.3207 - val_loss: 1.5328 - val_acc: 0.3312\n",
      "Epoch 45/1000\n",
      "8s - loss: 1.5201 - acc: 0.3201 - val_loss: 1.5331 - val_acc: 0.3344\n",
      "Epoch 46/1000\n",
      "8s - loss: 1.5174 - acc: 0.3176 - val_loss: 1.5357 - val_acc: 0.3276\n",
      "Epoch 47/1000\n",
      "8s - loss: 1.5178 - acc: 0.3175 - val_loss: 1.5292 - val_acc: 0.3389\n",
      "Epoch 48/1000\n",
      "8s - loss: 1.5159 - acc: 0.3165 - val_loss: 1.5335 - val_acc: 0.3321\n",
      "Epoch 49/1000\n",
      "8s - loss: 1.5074 - acc: 0.3196 - val_loss: 1.5329 - val_acc: 0.3317\n",
      "Epoch 50/1000\n",
      "8s - loss: 1.5067 - acc: 0.3329 - val_loss: 1.5303 - val_acc: 0.3348\n",
      "Epoch 51/1000\n",
      "8s - loss: 1.5056 - acc: 0.3274 - val_loss: 1.5321 - val_acc: 0.3362\n",
      "Epoch 52/1000\n",
      "8s - loss: 1.5042 - acc: 0.3301 - val_loss: 1.5285 - val_acc: 0.3344\n",
      "Epoch 53/1000\n",
      "8s - loss: 1.5068 - acc: 0.3328 - val_loss: 1.5311 - val_acc: 0.3317\n",
      "Epoch 54/1000\n",
      "8s - loss: 1.5028 - acc: 0.3325 - val_loss: 1.5260 - val_acc: 0.3416\n",
      "Epoch 55/1000\n",
      "8s - loss: 1.4987 - acc: 0.3384 - val_loss: 1.5258 - val_acc: 0.3439\n",
      "Epoch 56/1000\n",
      "8s - loss: 1.5006 - acc: 0.3385 - val_loss: 1.5238 - val_acc: 0.3380\n",
      "Epoch 57/1000\n",
      "8s - loss: 1.4983 - acc: 0.3348 - val_loss: 1.5149 - val_acc: 0.3448\n",
      "Epoch 58/1000\n",
      "8s - loss: 1.4978 - acc: 0.3301 - val_loss: 1.5248 - val_acc: 0.3403\n",
      "Epoch 59/1000\n",
      "8s - loss: 1.4930 - acc: 0.3408 - val_loss: 1.5157 - val_acc: 0.3480\n",
      "Epoch 60/1000\n",
      "9s - loss: 1.4859 - acc: 0.3444 - val_loss: 1.5209 - val_acc: 0.3403\n",
      "Epoch 61/1000\n",
      "8s - loss: 1.4843 - acc: 0.3373 - val_loss: 1.5141 - val_acc: 0.3516\n",
      "Epoch 62/1000\n",
      "9s - loss: 1.4869 - acc: 0.3382 - val_loss: 1.5128 - val_acc: 0.3538\n",
      "Epoch 63/1000\n",
      "9s - loss: 1.4848 - acc: 0.3395 - val_loss: 1.5193 - val_acc: 0.3425\n",
      "Epoch 64/1000\n",
      "10s - loss: 1.4856 - acc: 0.3401 - val_loss: 1.5155 - val_acc: 0.3498\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9cfd43ce6686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m           validation_data=(x_test, y_test), verbose=2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = model.fit(x_train, y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs=1000,\n",
    "          validation_data=(x_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Save the model (marking as continued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "date = str(datetime.date.today() )\n",
    "time = str(datetime.datetime.now().time())[:-7]\n",
    "\n",
    "filename = '/home/shikhar/Datasets/Models/' + model_type + '_continued_' + date + '_' +time;\n",
    "with open( filename, 'wb') as output:\n",
    "    pickle.dump([model.get_config(), model.get_weights(), model.history.history], output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('say done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "files = [\n",
    "    'CNN-rand_continued_2017-04-02_19:26:35',\n",
    "    'CNN-rand_continued_2017-04-03_16:50:47',\n",
    "    'CNN-rand_continued_2017-04-03_17:18:47'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_acc, train_loss, val_acc, val_loss = [],[],[],[]\n",
    "\n",
    "for file in files:\n",
    "    filename = '/home/shikhar/Datasets/Models/'  + file\n",
    "    with open( filename, 'rb') as input:\n",
    "        out = pickle.load(input)\n",
    "    train_acc += out[2]['acc']\n",
    "    train_loss += out[2]['loss']\n",
    "    val_acc += out[2]['val_acc']\n",
    "    val_loss += out[2]['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAGRCAYAAAAzRlR8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ad4f0c278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.plot(train_acc)\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_acc)\n",
    "# plt.plot(val_loss)\n",
    "plt.legend(['Train acc','Train loss','Valid acc', 'Valid loss'], loc=2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.title('Using '+ model_type)\n",
    "date = str(datetime.date.today() )\n",
    "time = str(datetime.datetime.now().time())[:-7]\n",
    "imgName = 'Images/' + model_type + '_' + date + '_' + time + '.jpg'\n",
    "plt.savefig( imgName, dpi= 200, bbox_inches='tight', transparent=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
