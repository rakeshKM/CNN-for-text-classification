{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Embedding, regularizers\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from w2v import train_word2vec \n",
    "import pickle, datetime\n",
    "import numpy as np\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ------------------------------- Data Preprocessing -----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Phrase -> index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239232 14058\n"
     ]
    }
   ],
   "source": [
    "phr_to_ind = dict()\n",
    "\n",
    "with open('../../Datasets/SST1_dataset/dictionary.txt') as f:\n",
    "    for line in f:\n",
    "        entry = line.split('|')\n",
    "        phr_to_ind[entry[0]] = int(entry[1])\n",
    "\n",
    "keys = phr_to_ind.keys();\n",
    "\n",
    "print(len(phr_to_ind), phr_to_ind['Good'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Getting Index corresponding to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11855\n"
     ]
    }
   ],
   "source": [
    "# Without doing the below computation directly load the stored output\n",
    "sentence_list = []\n",
    "sentiment = []\n",
    "\n",
    "with open('../../Datasets/SST1_dataset/SentenceWithCorrection.txt') as f:\n",
    "    for line in f:\n",
    "        sent = line[:-1]\n",
    "        sentence_list.append(sent)\n",
    "        sentiment.append(phr_to_ind[sent])\n",
    "\n",
    "print(len(sentence_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# sentence_list = []\n",
    "# sentiment = []\n",
    "\n",
    "# with open('../../Datasets/SST1_dataset/datasetSentences.txt') as f:\n",
    "#     f.readline()\n",
    "#     for line in f:\n",
    "#         entry = line.split('\\t')\n",
    "#         sent = entry[1][:-1]\n",
    "#         sent = sent.replace('-LRB-', '(')\n",
    "#         sent = sent.replace('-RRB-', ')')\n",
    "    \n",
    "#         if sent in phr_to_ind.keys():\n",
    "#             sentiment.append(phr_to_ind[sent])\n",
    "#         else:\n",
    "#             print('.', end=\"\")\n",
    "#             keys_subset = [k for k in keys if (k[0] == sent[0])]\n",
    "#             key = difflib.get_close_matches(sent, keys_subset, n=1);\n",
    "#             sent = key[0]\n",
    "#             sentiment.append(phr_to_ind[sent])\n",
    "            \n",
    "#         sentence_list.append(sent)\n",
    "        \n",
    "# print(len(sentence_list))\n",
    "\n",
    "# # Written the output in a file\n",
    "# f = open('../../Datasets/SST1_dataset/SentenceWithCorrection.txt', 'w')\n",
    "# for sent in sentence_list:\n",
    "#     f.write(sent + '\\n')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Phrase Index -> Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239232\n"
     ]
    }
   ],
   "source": [
    "ind_to_senti = dict()\n",
    "\n",
    "with open('../../Datasets/SST1_dataset/sentiment_labels.txt') as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        entry = line.split('|')\n",
    "        ind_to_senti[int(entry[0])] = float(entry[1])\n",
    "\n",
    "print(len(ind_to_senti))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading train, test and valid split info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11855\n",
      "9645 2210 0\n"
     ]
    }
   ],
   "source": [
    "split_ind = []\n",
    "with open('../../Datasets/SST1_dataset/datasetSplit.txt') as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        entry = line.split(',')\n",
    "        split_ind.append(int(entry[1]))\n",
    "\n",
    "print(len(split_ind))\n",
    "\n",
    "for i in range(len(split_ind)):\n",
    "    if split_ind[i] == 3:\n",
    "        split_ind[i] = 1\n",
    "        \n",
    "N_train = split_ind.count(1)\n",
    "N_test = split_ind.count(2)\n",
    "N_valid = split_ind.count(3)\n",
    "print (N_train, N_test, N_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Assigning label to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510 3140 2242 3111\n"
     ]
    }
   ],
   "source": [
    "N_sent = len(sentence_list);\n",
    "N_category = 5\n",
    "\n",
    "y_label = []\n",
    "\n",
    "for ind in sentiment:\n",
    "    val = ind_to_senti[ind]\n",
    "    if val >= 0.0 and val <= 0.2:\n",
    "        y_label.append(0);\n",
    "    elif val > 0.2 and val <= 0.4:\n",
    "        y_label.append(1)\n",
    "    elif val > 0.4 and val <= 0.6:\n",
    "        y_label.append(2)\n",
    "    elif val > 0.6 and val <= 0.8:\n",
    "        y_label.append(3)\n",
    "    else:\n",
    "        y_label.append(4)\n",
    "\n",
    "print(y_label.count(0), y_label.count(1), y_label.count(2), y_label.count(3))\n",
    "\n",
    "# Labels in one-hot encoding\n",
    "y_train = np.zeros((N_train, N_category), np.uint8)\n",
    "y_test  = np.zeros((N_test , N_category), np.uint8)\n",
    "y_valid = np.zeros((N_valid, N_category), np.uint8)\n",
    "\n",
    "c1,c2,c3 = 0,0,0\n",
    "for i in range(len(y_label)):\n",
    "    label = y_label[i]\n",
    "    if split_ind[i] == 1:\n",
    "        y_train[c1, label] = 1;  c1 += 1\n",
    "    elif split_ind[i] == 2:\n",
    "        y_test [c2, label] = 1;  c2 += 1\n",
    "    else:\n",
    "        y_valid[c3, label] = 1;  c3 += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Reducing the size of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239232 21699\n"
     ]
    }
   ],
   "source": [
    "x_all = []\n",
    "max_sent_len = -1;\n",
    "max_wrd_len = -1\n",
    "wrd_to_ind = dict()\n",
    "\n",
    "ind_new = 1;\n",
    "for sent in sentence_list:\n",
    "    wrds = sent.split()\n",
    "    vec = []\n",
    "    for wrd in wrds:\n",
    "        if wrd not in wrd_to_ind.keys():\n",
    "            wrd_to_ind[wrd] = ind_new\n",
    "            ind_new += 1\n",
    "            \n",
    "        ind = wrd_to_ind[wrd]\n",
    "        vec.append(ind)\n",
    "            \n",
    "    max_sent_len = max(len(vec), max_sent_len)\n",
    "    x_all.append(vec)\n",
    "\n",
    "# Get inverse dictionary\n",
    "ind_to_wrd = dict((v, k) for k, v in wrd_to_ind.items())\n",
    "ind_to_wrd[0] = \"<PAD/>\"\n",
    "\n",
    "print(len(phr_to_ind), len(wrd_to_ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9645 2210 0\n"
     ]
    }
   ],
   "source": [
    "x_train = np.zeros((N_train, max_sent_len), np.int32)\n",
    "x_test  = np.zeros((N_test,  max_sent_len), np.int32)\n",
    "x_valid = np.zeros((N_valid, max_sent_len), np.int32)\n",
    "\n",
    "c1, c2, c3 = 0,0,0\n",
    "for i in range(len(x_all)):\n",
    "    vec = x_all[i]\n",
    "    if split_ind[i] == 1:\n",
    "        x_train[c1,0:len(vec)] = np.int32(vec); \n",
    "        c1 += 1\n",
    "    elif split_ind[i] == 2:\n",
    "        x_test [c2,0:len(vec)] = np.int32(vec); \n",
    "        c2 += 1\n",
    "    else:\n",
    "        x_valid[c3,0:len(vec)] = np.int32(vec); \n",
    "        c3 += 1\n",
    "\n",
    "print(c1, c2, c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -------------------------------- Training model  -----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Paremeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_type    = 'CNN-rand'  # CNN-rand|CNN-non-static|CNN-static\n",
    "embedding_dim = 300         # word2vec dim\n",
    "vocab_size    = len(ind_to_wrd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Generate word2vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if model_type in ['CNN-non-static', 'CNN-static']:\n",
    "    embedding_wts = train_word2vec( np.vstack((x_train, x_test, x_valid)), \n",
    "                                    ind_to_wrd, num_features = embedding_dim)\n",
    "    if model_type == 'CNN-static':\n",
    "        x_train = embedding_wts[0][x_train]\n",
    "        x_test  = embedding_wts[0][x_test]\n",
    "        x_valid = embedding_wts[0][x_valid]\n",
    "        \n",
    "elif model_type == 'CNN-rand':\n",
    "    embedding_wts = None\n",
    "    \n",
    "else:\n",
    "    raise ValueError(\"Unknown model type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 56)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding (Embedding)            (None, 56, 300)       6510000                                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 56, 300)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)                (None, 54, 100)       90100                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)                (None, 53, 100)       120100                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)                (None, 52, 100)       150100                                       \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)   (None, 27, 100)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)   (None, 26, 100)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)   (None, 26, 100)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 2700)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 2600)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 2600)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 7900)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 7900)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 100)           790100                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 5)             505                                          \n",
      "====================================================================================================\n",
      "Total params: 7,660,905.0\n",
      "Trainable params: 7,660,905.0\n",
      "Non-trainable params: 0.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size   = 50\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters  = 100\n",
    "dropout_prob = (0.5, 0.8)\n",
    "hidden_dims  = 100\n",
    "\n",
    "l2_reg = 0.3\n",
    "embedding_dim = 300\n",
    "\n",
    "# Deciding dimension of input based on the model\n",
    "input_shape = (max_sent_len, embedding_dim) if model_type == \"CNN-static\" else (max_sent_len,)\n",
    "model_input = Input(shape = input_shape)\n",
    "\n",
    "# Static model do not have embedding layer\n",
    "if model_type == \"CNN-static\":\n",
    "    z = Dropout(dropout_prob[0])(model_input)\n",
    "else:\n",
    "    z = Embedding(vocab_size, embedding_dim, input_length = max_sent_len, name=\"embedding\")(model_input)\n",
    "    z = Dropout(dropout_prob[0])(z)\n",
    "\n",
    "# Convolution layers\n",
    "z1 = Conv1D(    filters=100, kernel_size=3, \n",
    "                padding=\"valid\", activation=\"relu\", \n",
    "                strides=1)(z)\n",
    "z1 = MaxPooling1D(pool_size=2)(z1)\n",
    "z1 = Flatten()(z1)\n",
    "\n",
    "z2 = Conv1D(    filters=100, kernel_size=4, \n",
    "                padding=\"valid\", activation=\"relu\", \n",
    "                strides=1)(z)\n",
    "z2 = MaxPooling1D(pool_size=2)(z2)\n",
    "z2 = Flatten()(z2)\n",
    "\n",
    "z3 = Conv1D(    filters=100, kernel_size=5, \n",
    "                padding=\"valid\", activation=\"relu\",\n",
    "                strides=1)(z)\n",
    "z3 = MaxPooling1D(pool_size=2)(z3)\n",
    "z3 = Flatten()(z3)\n",
    "\n",
    "# Concatenate the output of all convolution layers\n",
    "z = Concatenate()([z1, z2, z3])\n",
    "z = Dropout(dropout_prob[1])(z)\n",
    "\n",
    "# Dense(64, input_dim=64, kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.01))\n",
    "\n",
    "z = Dense(hidden_dims, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(z)\n",
    "model_output = Dense(N_category, activation=\"sigmoid\")(z)\n",
    "    \n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adadelta(lr=1, decay=0.001), metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8544 samples, validate on 1101 samples\n",
      "Epoch 1/100\n",
      "32s - loss: 1.9798 - acc: 0.2623 - val_loss: 1.6068 - val_acc: 0.2534\n",
      "Epoch 2/100\n",
      "29s - loss: 1.5861 - acc: 0.2656 - val_loss: 1.5814 - val_acc: 0.2534\n",
      "Epoch 3/100\n",
      "29s - loss: 1.5775 - acc: 0.2667 - val_loss: 1.5816 - val_acc: 0.2534\n",
      "Epoch 4/100\n",
      "29s - loss: 1.5757 - acc: 0.2710 - val_loss: 1.5784 - val_acc: 0.2534\n",
      "Epoch 5/100\n",
      "29s - loss: 1.5740 - acc: 0.2681 - val_loss: 1.5773 - val_acc: 0.2534\n",
      "Epoch 6/100\n",
      "29s - loss: 1.5730 - acc: 0.2717 - val_loss: 1.5776 - val_acc: 0.2534\n",
      "Epoch 7/100\n",
      "29s - loss: 1.5737 - acc: 0.2711 - val_loss: 1.5775 - val_acc: 0.2534\n",
      "Epoch 8/100\n",
      "29s - loss: 1.5719 - acc: 0.2725 - val_loss: 1.5764 - val_acc: 0.2534\n",
      "Epoch 9/100\n",
      "29s - loss: 1.5717 - acc: 0.2717 - val_loss: 1.5756 - val_acc: 0.2534\n",
      "Epoch 10/100\n",
      "29s - loss: 1.5715 - acc: 0.2708 - val_loss: 1.5764 - val_acc: 0.2534\n",
      "Epoch 11/100\n",
      "29s - loss: 1.5709 - acc: 0.2719 - val_loss: 1.5761 - val_acc: 0.2534\n",
      "Epoch 12/100\n",
      "29s - loss: 1.5701 - acc: 0.2721 - val_loss: 1.5756 - val_acc: 0.2534\n",
      "Epoch 13/100\n",
      "29s - loss: 1.5697 - acc: 0.2694 - val_loss: 1.5759 - val_acc: 0.2534\n",
      "Epoch 14/100\n",
      "29s - loss: 1.5695 - acc: 0.2719 - val_loss: 1.5757 - val_acc: 0.2534\n",
      "Epoch 15/100\n",
      "29s - loss: 1.5687 - acc: 0.2714 - val_loss: 1.5754 - val_acc: 0.2534\n",
      "Epoch 16/100\n",
      "29s - loss: 1.5678 - acc: 0.2718 - val_loss: 1.5764 - val_acc: 0.2534\n",
      "Epoch 17/100\n",
      "29s - loss: 1.5668 - acc: 0.2766 - val_loss: 1.5754 - val_acc: 0.2534\n",
      "Epoch 18/100\n",
      "29s - loss: 1.5654 - acc: 0.2728 - val_loss: 1.5753 - val_acc: 0.2534\n",
      "Epoch 19/100\n",
      "29s - loss: 1.5643 - acc: 0.2759 - val_loss: 1.5757 - val_acc: 0.2507\n",
      "Epoch 20/100\n",
      "29s - loss: 1.5628 - acc: 0.2749 - val_loss: 1.5743 - val_acc: 0.2525\n",
      "Epoch 21/100\n",
      "29s - loss: 1.5597 - acc: 0.2732 - val_loss: 1.5760 - val_acc: 0.2534\n",
      "Epoch 22/100\n",
      "29s - loss: 1.5587 - acc: 0.2773 - val_loss: 1.5736 - val_acc: 0.2507\n",
      "Epoch 23/100\n",
      "29s - loss: 1.5561 - acc: 0.2782 - val_loss: 1.5745 - val_acc: 0.2616\n",
      "Epoch 24/100\n",
      "29s - loss: 1.5545 - acc: 0.2836 - val_loss: 1.5710 - val_acc: 0.2643\n",
      "Epoch 25/100\n",
      "29s - loss: 1.5522 - acc: 0.2858 - val_loss: 1.5700 - val_acc: 0.2743\n",
      "Epoch 26/100\n",
      "29s - loss: 1.5490 - acc: 0.2884 - val_loss: 1.5695 - val_acc: 0.2743\n",
      "Epoch 27/100\n",
      "29s - loss: 1.5466 - acc: 0.2846 - val_loss: 1.5674 - val_acc: 0.2797\n",
      "Epoch 28/100\n",
      "29s - loss: 1.5437 - acc: 0.2884 - val_loss: 1.5654 - val_acc: 0.2870\n",
      "Epoch 29/100\n",
      "29s - loss: 1.5407 - acc: 0.2946 - val_loss: 1.5646 - val_acc: 0.2843\n",
      "Epoch 30/100\n",
      "29s - loss: 1.5377 - acc: 0.3004 - val_loss: 1.5633 - val_acc: 0.2888\n",
      "Epoch 31/100\n",
      "29s - loss: 1.5366 - acc: 0.2924 - val_loss: 1.5615 - val_acc: 0.2888\n",
      "Epoch 32/100\n",
      "29s - loss: 1.5349 - acc: 0.2986 - val_loss: 1.5594 - val_acc: 0.2888\n",
      "Epoch 33/100\n",
      "29s - loss: 1.5319 - acc: 0.3035 - val_loss: 1.5585 - val_acc: 0.2943\n",
      "Epoch 34/100\n",
      "29s - loss: 1.5299 - acc: 0.3043 - val_loss: 1.5571 - val_acc: 0.2861\n",
      "Epoch 35/100\n",
      "29s - loss: 1.5275 - acc: 0.3055 - val_loss: 1.5547 - val_acc: 0.2888\n",
      "Epoch 36/100\n",
      "29s - loss: 1.5251 - acc: 0.3057 - val_loss: 1.5539 - val_acc: 0.2961\n",
      "Epoch 37/100\n",
      "29s - loss: 1.5226 - acc: 0.3082 - val_loss: 1.5534 - val_acc: 0.2961\n",
      "Epoch 38/100\n",
      "29s - loss: 1.5205 - acc: 0.3105 - val_loss: 1.5513 - val_acc: 0.2988\n",
      "Epoch 39/100\n",
      "29s - loss: 1.5178 - acc: 0.3111 - val_loss: 1.5505 - val_acc: 0.2997\n",
      "Epoch 40/100\n",
      "29s - loss: 1.5153 - acc: 0.3164 - val_loss: 1.5500 - val_acc: 0.2979\n",
      "Epoch 41/100\n",
      "29s - loss: 1.5136 - acc: 0.3123 - val_loss: 1.5488 - val_acc: 0.2988\n",
      "Epoch 42/100\n",
      "29s - loss: 1.5119 - acc: 0.3136 - val_loss: 1.5466 - val_acc: 0.3034\n",
      "Epoch 43/100\n",
      "29s - loss: 1.5083 - acc: 0.3176 - val_loss: 1.5477 - val_acc: 0.3043\n",
      "Epoch 44/100\n",
      "29s - loss: 1.5081 - acc: 0.3181 - val_loss: 1.5466 - val_acc: 0.3061\n",
      "Epoch 45/100\n",
      "29s - loss: 1.5046 - acc: 0.3184 - val_loss: 1.5443 - val_acc: 0.3070\n",
      "Epoch 46/100\n",
      "29s - loss: 1.5042 - acc: 0.3181 - val_loss: 1.5440 - val_acc: 0.3061\n",
      "Epoch 47/100\n",
      "29s - loss: 1.5004 - acc: 0.3224 - val_loss: 1.5418 - val_acc: 0.3061\n",
      "Epoch 48/100\n",
      "29s - loss: 1.4998 - acc: 0.3291 - val_loss: 1.5408 - val_acc: 0.3079\n",
      "Epoch 49/100\n",
      "29s - loss: 1.4952 - acc: 0.3249 - val_loss: 1.5414 - val_acc: 0.3079\n",
      "Epoch 50/100\n",
      "29s - loss: 1.4938 - acc: 0.3226 - val_loss: 1.5399 - val_acc: 0.3061\n",
      "Epoch 51/100\n",
      "29s - loss: 1.4924 - acc: 0.3277 - val_loss: 1.5390 - val_acc: 0.3088\n",
      "Epoch 52/100\n",
      "29s - loss: 1.4878 - acc: 0.3309 - val_loss: 1.5372 - val_acc: 0.3124\n",
      "Epoch 53/100\n",
      "29s - loss: 1.4861 - acc: 0.3325 - val_loss: 1.5372 - val_acc: 0.3134\n",
      "Epoch 54/100\n",
      "29s - loss: 1.4846 - acc: 0.3283 - val_loss: 1.5365 - val_acc: 0.3115\n",
      "Epoch 55/100\n",
      "29s - loss: 1.4814 - acc: 0.3344 - val_loss: 1.5360 - val_acc: 0.3115\n",
      "Epoch 56/100\n",
      "29s - loss: 1.4789 - acc: 0.3338 - val_loss: 1.5340 - val_acc: 0.3134\n",
      "Epoch 57/100\n",
      "29s - loss: 1.4751 - acc: 0.3373 - val_loss: 1.5345 - val_acc: 0.3134\n",
      "Epoch 58/100\n",
      "29s - loss: 1.4733 - acc: 0.3382 - val_loss: 1.5326 - val_acc: 0.3124\n",
      "Epoch 59/100\n",
      "29s - loss: 1.4720 - acc: 0.3398 - val_loss: 1.5329 - val_acc: 0.3143\n",
      "Epoch 60/100\n",
      "29s - loss: 1.4692 - acc: 0.3413 - val_loss: 1.5329 - val_acc: 0.3124\n",
      "Epoch 61/100\n",
      "29s - loss: 1.4671 - acc: 0.3411 - val_loss: 1.5306 - val_acc: 0.3161\n",
      "Epoch 62/100\n",
      "29s - loss: 1.4658 - acc: 0.3416 - val_loss: 1.5289 - val_acc: 0.3143\n",
      "Epoch 63/100\n",
      "29s - loss: 1.4587 - acc: 0.3464 - val_loss: 1.5295 - val_acc: 0.3188\n",
      "Epoch 64/100\n",
      "29s - loss: 1.4592 - acc: 0.3432 - val_loss: 1.5269 - val_acc: 0.3161\n",
      "Epoch 65/100\n",
      "29s - loss: 1.4545 - acc: 0.3474 - val_loss: 1.5260 - val_acc: 0.3170\n",
      "Epoch 66/100\n",
      "29s - loss: 1.4537 - acc: 0.3488 - val_loss: 1.5251 - val_acc: 0.3179\n",
      "Epoch 67/100\n",
      "29s - loss: 1.4499 - acc: 0.3503 - val_loss: 1.5249 - val_acc: 0.3179\n",
      "Epoch 68/100\n",
      "29s - loss: 1.4454 - acc: 0.3525 - val_loss: 1.5239 - val_acc: 0.3197\n",
      "Epoch 69/100\n",
      "29s - loss: 1.4418 - acc: 0.3557 - val_loss: 1.5249 - val_acc: 0.3224\n",
      "Epoch 70/100\n",
      "29s - loss: 1.4447 - acc: 0.3528 - val_loss: 1.5205 - val_acc: 0.3224\n",
      "Epoch 71/100\n",
      "29s - loss: 1.4387 - acc: 0.3576 - val_loss: 1.5204 - val_acc: 0.3233\n",
      "Epoch 72/100\n",
      "29s - loss: 1.4375 - acc: 0.3560 - val_loss: 1.5224 - val_acc: 0.3233\n",
      "Epoch 73/100\n",
      "29s - loss: 1.4335 - acc: 0.3569 - val_loss: 1.5177 - val_acc: 0.3279\n",
      "Epoch 74/100\n",
      "30s - loss: 1.4295 - acc: 0.3621 - val_loss: 1.5182 - val_acc: 0.3243\n",
      "Epoch 75/100\n",
      "29s - loss: 1.4290 - acc: 0.3626 - val_loss: 1.5175 - val_acc: 0.3297\n",
      "Epoch 76/100\n",
      "29s - loss: 1.4254 - acc: 0.3653 - val_loss: 1.5163 - val_acc: 0.3233\n",
      "Epoch 77/100\n",
      "29s - loss: 1.4216 - acc: 0.3681 - val_loss: 1.5139 - val_acc: 0.3306\n",
      "Epoch 78/100\n",
      "29s - loss: 1.4170 - acc: 0.3713 - val_loss: 1.5160 - val_acc: 0.3342\n",
      "Epoch 79/100\n",
      "29s - loss: 1.4137 - acc: 0.3741 - val_loss: 1.5131 - val_acc: 0.3315\n",
      "Epoch 80/100\n",
      "29s - loss: 1.4150 - acc: 0.3732 - val_loss: 1.5122 - val_acc: 0.3342\n",
      "Epoch 81/100\n",
      "28s - loss: 1.4103 - acc: 0.3837 - val_loss: 1.5121 - val_acc: 0.3370\n",
      "Epoch 82/100\n",
      "33s - loss: 1.4106 - acc: 0.3817 - val_loss: 1.5121 - val_acc: 0.3406\n",
      "Epoch 83/100\n",
      "29s - loss: 1.4054 - acc: 0.3847 - val_loss: 1.5104 - val_acc: 0.3451\n",
      "Epoch 84/100\n",
      "29s - loss: 1.4004 - acc: 0.3910 - val_loss: 1.5100 - val_acc: 0.3379\n",
      "Epoch 85/100\n",
      "29s - loss: 1.4021 - acc: 0.3893 - val_loss: 1.5092 - val_acc: 0.3406\n",
      "Epoch 86/100\n",
      "29s - loss: 1.3962 - acc: 0.3935 - val_loss: 1.5085 - val_acc: 0.3451\n",
      "Epoch 87/100\n",
      "29s - loss: 1.3959 - acc: 0.3981 - val_loss: 1.5086 - val_acc: 0.3488\n",
      "Epoch 88/100\n",
      "29s - loss: 1.3918 - acc: 0.3970 - val_loss: 1.5073 - val_acc: 0.3497\n",
      "Epoch 89/100\n",
      "29s - loss: 1.3867 - acc: 0.4027 - val_loss: 1.5075 - val_acc: 0.3488\n",
      "Epoch 90/100\n",
      "29s - loss: 1.3842 - acc: 0.4058 - val_loss: 1.5090 - val_acc: 0.3506\n",
      "Epoch 91/100\n",
      "29s - loss: 1.3848 - acc: 0.4078 - val_loss: 1.5069 - val_acc: 0.3506\n",
      "Epoch 92/100\n",
      "29s - loss: 1.3780 - acc: 0.4180 - val_loss: 1.5084 - val_acc: 0.3488\n",
      "Epoch 93/100\n",
      "29s - loss: 1.3766 - acc: 0.4109 - val_loss: 1.5061 - val_acc: 0.3497\n",
      "Epoch 94/100\n",
      "29s - loss: 1.3763 - acc: 0.4161 - val_loss: 1.5082 - val_acc: 0.3488\n",
      "Epoch 95/100\n",
      "29s - loss: 1.3766 - acc: 0.4158 - val_loss: 1.5044 - val_acc: 0.3488\n",
      "Epoch 96/100\n",
      "29s - loss: 1.3709 - acc: 0.4195 - val_loss: 1.5054 - val_acc: 0.3470\n",
      "Epoch 97/100\n",
      "29s - loss: 1.3700 - acc: 0.4190 - val_loss: 1.5057 - val_acc: 0.3451\n",
      "Epoch 98/100\n",
      "29s - loss: 1.3645 - acc: 0.4240 - val_loss: 1.5025 - val_acc: 0.3515\n",
      "Epoch 99/100\n",
      "29s - loss: 1.3659 - acc: 0.4226 - val_loss: 1.5062 - val_acc: 0.3506\n",
      "Epoch 100/100\n",
      "29s - loss: 1.3626 - acc: 0.4217 - val_loss: 1.5053 - val_acc: 0.3415\n"
     ]
    }
   ],
   "source": [
    "if model_type == \"CNN-non-static\":\n",
    "    embedding_layer = model.get_layer(\"embedding\")\n",
    "    embedding_layer.set_weights(embedding_wts)\n",
    "\n",
    "res = model.fit(x_train, y_train, \n",
    "          batch_size = batch_size,\n",
    "          epochs=100,\n",
    "          validation_data=(x_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Computing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 67.579056506\n",
      "Testing Accuracy 39.9095022624\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "predictions = model.predict(x_train)\n",
    "pred_train = np.argmax(predictions, axis=1)\n",
    "train_label = np.argmax(y_train, axis=1)\n",
    "print('Training Accuracy', np.sum(pred_train == train_label) / N_train * 100)\n",
    "\n",
    "# # Training Accuracy\n",
    "# predictions = model.predict(x_valid)\n",
    "# pred_valid = np.argmax(predictions, axis=1)\n",
    "# valid_label = np.argmax(y_valid, axis=1)\n",
    "# print('Validation Accuracy', np.sum(pred_valid == valid_label) / N_valid * 100)\n",
    "\n",
    "# Test Accuracy\n",
    "predictions = model.predict(x_test)\n",
    "pred_test = np.argmax(predictions, axis=1)\n",
    "test_label = np.argmax(y_test, axis=1)\n",
    "print('Testing Accuracy', np.sum(pred_test == test_label) / N_test * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "date = str(datetime.date.today() )\n",
    "time = str(datetime.datetime.now().time())[:-7]\n",
    "\n",
    "filename = '/home/shikhar/Datasets/Models/' + model_type + '_' + date + '_' +time;\n",
    "with open( filename, 'wb') as output:\n",
    "    pickle.dump([res.model.get_config(), res.model.get_weights(), res.history], output, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "## Loading saved data\n",
    "# with open( filename, 'rb') as input:\n",
    "#     out = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAGRCAYAAAAzRlR8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9124cab828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.plot(res.history['acc'])\n",
    "plt.plot(res.history['loss'])\n",
    "plt.plot(res.history['val_acc'])\n",
    "plt.plot(res.history['val_loss'])\n",
    "plt.legend(['Train acc','Train loss','Valid acc', 'Valid loss'], loc=2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.title('Using '+ model_type)\n",
    "imgName = 'Images/' + model_type + '_' + date + '_' + time + '.jpg'\n",
    "plt.savefig( imgName, dpi= 200, bbox_inches='tight', transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Continue from a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9645 samples, validate on 2210 samples\n",
      "Epoch 1/100\n",
      "35s - loss: 1.3078 - acc: 0.4572 - val_loss: 1.4622 - val_acc: 0.3878\n",
      "Epoch 2/100\n",
      "36s - loss: 1.2892 - acc: 0.4649 - val_loss: 1.4579 - val_acc: 0.4032\n",
      "Epoch 3/100\n",
      "34s - loss: 1.2742 - acc: 0.4732 - val_loss: 1.4617 - val_acc: 0.4027\n",
      "Epoch 4/100\n",
      "33s - loss: 1.2765 - acc: 0.4754 - val_loss: 1.4688 - val_acc: 0.4032\n",
      "Epoch 5/100\n",
      "33s - loss: 1.2716 - acc: 0.4773 - val_loss: 1.4616 - val_acc: 0.4027\n",
      "Epoch 6/100\n",
      "33s - loss: 1.2652 - acc: 0.4765 - val_loss: 1.4660 - val_acc: 0.4023\n",
      "Epoch 7/100\n",
      "34s - loss: 1.2560 - acc: 0.4826 - val_loss: 1.4620 - val_acc: 0.4018\n",
      "Epoch 8/100\n",
      "33s - loss: 1.2566 - acc: 0.4788 - val_loss: 1.4582 - val_acc: 0.4018\n",
      "Epoch 9/100\n",
      "33s - loss: 1.2570 - acc: 0.4807 - val_loss: 1.4612 - val_acc: 0.4027\n",
      "Epoch 10/100\n",
      "33s - loss: 1.2495 - acc: 0.4841 - val_loss: 1.4607 - val_acc: 0.3991\n",
      "Epoch 11/100\n",
      "33s - loss: 1.2464 - acc: 0.4891 - val_loss: 1.4593 - val_acc: 0.4036\n",
      "Epoch 12/100\n",
      "33s - loss: 1.2443 - acc: 0.4942 - val_loss: 1.4629 - val_acc: 0.4023\n",
      "Epoch 13/100\n",
      "33s - loss: 1.2456 - acc: 0.4841 - val_loss: 1.4649 - val_acc: 0.4054\n",
      "Epoch 14/100\n",
      "36s - loss: 1.2468 - acc: 0.4881 - val_loss: 1.4604 - val_acc: 0.4054\n",
      "Epoch 15/100\n",
      "35s - loss: 1.2470 - acc: 0.4873 - val_loss: 1.4598 - val_acc: 0.3991\n",
      "Epoch 16/100\n",
      "33s - loss: 1.2374 - acc: 0.4905 - val_loss: 1.4622 - val_acc: 0.4032\n",
      "Epoch 17/100\n",
      "34s - loss: 1.2382 - acc: 0.4900 - val_loss: 1.4640 - val_acc: 0.4050\n",
      "Epoch 18/100\n",
      "33s - loss: 1.2432 - acc: 0.4872 - val_loss: 1.4616 - val_acc: 0.4054\n",
      "Epoch 19/100\n",
      "34s - loss: 1.2341 - acc: 0.4888 - val_loss: 1.4615 - val_acc: 0.4032\n",
      "Epoch 20/100\n",
      "33s - loss: 1.2404 - acc: 0.4881 - val_loss: 1.4615 - val_acc: 0.4050\n",
      "Epoch 21/100\n",
      "34s - loss: 1.2341 - acc: 0.4880 - val_loss: 1.4601 - val_acc: 0.4000\n",
      "Epoch 22/100\n",
      "33s - loss: 1.2364 - acc: 0.4868 - val_loss: 1.4593 - val_acc: 0.4018\n",
      "Epoch 23/100\n",
      "34s - loss: 1.2326 - acc: 0.4926 - val_loss: 1.4607 - val_acc: 0.4041\n",
      "Epoch 24/100\n",
      "33s - loss: 1.2339 - acc: 0.4870 - val_loss: 1.4604 - val_acc: 0.3995\n",
      "Epoch 25/100\n",
      "33s - loss: 1.2333 - acc: 0.4880 - val_loss: 1.4603 - val_acc: 0.4009\n",
      "Epoch 26/100\n",
      "33s - loss: 1.2260 - acc: 0.4920 - val_loss: 1.4603 - val_acc: 0.3991\n",
      "Epoch 27/100\n",
      "33s - loss: 1.2327 - acc: 0.4904 - val_loss: 1.4592 - val_acc: 0.3986\n",
      "Epoch 28/100\n",
      "33s - loss: 1.2274 - acc: 0.4950 - val_loss: 1.4601 - val_acc: 0.4041\n",
      "Epoch 29/100\n",
      "33s - loss: 1.2298 - acc: 0.4913 - val_loss: 1.4590 - val_acc: 0.4000\n",
      "Epoch 30/100\n",
      "33s - loss: 1.2292 - acc: 0.4903 - val_loss: 1.4607 - val_acc: 0.4032\n",
      "Epoch 31/100\n",
      "33s - loss: 1.2283 - acc: 0.4912 - val_loss: 1.4603 - val_acc: 0.4014\n",
      "Epoch 32/100\n",
      "33s - loss: 1.2238 - acc: 0.4960 - val_loss: 1.4607 - val_acc: 0.4000\n",
      "Epoch 33/100\n",
      "33s - loss: 1.2292 - acc: 0.4896 - val_loss: 1.4612 - val_acc: 0.4014\n",
      "Epoch 34/100\n",
      "35s - loss: 1.2260 - acc: 0.4919 - val_loss: 1.4607 - val_acc: 0.4018\n",
      "Epoch 35/100\n",
      "33s - loss: 1.2289 - acc: 0.4917 - val_loss: 1.4605 - val_acc: 0.4023\n",
      "Epoch 36/100\n",
      "33s - loss: 1.2245 - acc: 0.4987 - val_loss: 1.4604 - val_acc: 0.4005\n",
      "Epoch 37/100\n",
      "36s - loss: 1.2286 - acc: 0.4935 - val_loss: 1.4613 - val_acc: 0.4014\n",
      "Epoch 38/100\n",
      "35s - loss: 1.2220 - acc: 0.4968 - val_loss: 1.4613 - val_acc: 0.4018\n",
      "Epoch 39/100\n",
      "33s - loss: 1.2207 - acc: 0.4968 - val_loss: 1.4599 - val_acc: 0.4018\n",
      "Epoch 40/100\n",
      "33s - loss: 1.2237 - acc: 0.4973 - val_loss: 1.4611 - val_acc: 0.4023\n",
      "Epoch 41/100\n",
      "33s - loss: 1.2202 - acc: 0.4942 - val_loss: 1.4612 - val_acc: 0.4000\n",
      "Epoch 42/100\n",
      "33s - loss: 1.2220 - acc: 0.4962 - val_loss: 1.4613 - val_acc: 0.4005\n",
      "Epoch 43/100\n",
      "33s - loss: 1.2257 - acc: 0.4927 - val_loss: 1.4615 - val_acc: 0.4009\n",
      "Epoch 44/100\n",
      "37s - loss: 1.2209 - acc: 0.4971 - val_loss: 1.4608 - val_acc: 0.4014\n",
      "Epoch 45/100\n",
      "36s - loss: 1.2183 - acc: 0.4996 - val_loss: 1.4613 - val_acc: 0.4000\n",
      "Epoch 46/100\n",
      "36s - loss: 1.2220 - acc: 0.4920 - val_loss: 1.4609 - val_acc: 0.4005\n",
      "Epoch 47/100\n",
      "36s - loss: 1.2182 - acc: 0.4976 - val_loss: 1.4606 - val_acc: 0.4005\n",
      "Epoch 48/100\n",
      "33s - loss: 1.2163 - acc: 0.5005 - val_loss: 1.4619 - val_acc: 0.4009\n",
      "Epoch 49/100\n",
      "34s - loss: 1.2235 - acc: 0.4890 - val_loss: 1.4620 - val_acc: 0.4045\n",
      "Epoch 50/100\n",
      "34s - loss: 1.2218 - acc: 0.5019 - val_loss: 1.4615 - val_acc: 0.4014\n",
      "Epoch 51/100\n",
      "34s - loss: 1.2138 - acc: 0.4949 - val_loss: 1.4617 - val_acc: 0.4009\n",
      "Epoch 52/100\n",
      "34s - loss: 1.2161 - acc: 0.4982 - val_loss: 1.4619 - val_acc: 0.4014\n",
      "Epoch 53/100\n",
      "33s - loss: 1.2185 - acc: 0.4948 - val_loss: 1.4611 - val_acc: 0.4018\n",
      "Epoch 54/100\n",
      "34s - loss: 1.2126 - acc: 0.4997 - val_loss: 1.4613 - val_acc: 0.4018\n",
      "Epoch 55/100\n",
      "33s - loss: 1.2185 - acc: 0.4993 - val_loss: 1.4616 - val_acc: 0.4005\n",
      "Epoch 56/100\n",
      "34s - loss: 1.2160 - acc: 0.4971 - val_loss: 1.4615 - val_acc: 0.4018\n",
      "Epoch 57/100\n",
      "34s - loss: 1.2153 - acc: 0.5005 - val_loss: 1.4619 - val_acc: 0.4009\n",
      "Epoch 58/100\n",
      "34s - loss: 1.2151 - acc: 0.5004 - val_loss: 1.4617 - val_acc: 0.4023\n",
      "Epoch 59/100\n",
      "34s - loss: 1.2184 - acc: 0.4971 - val_loss: 1.4618 - val_acc: 0.4023\n",
      "Epoch 60/100\n",
      "33s - loss: 1.2186 - acc: 0.4946 - val_loss: 1.4614 - val_acc: 0.4023\n",
      "Epoch 61/100\n",
      "34s - loss: 1.2164 - acc: 0.4959 - val_loss: 1.4620 - val_acc: 0.4009\n",
      "Epoch 62/100\n",
      "33s - loss: 1.2161 - acc: 0.4971 - val_loss: 1.4618 - val_acc: 0.4014\n",
      "Epoch 63/100\n",
      "34s - loss: 1.2119 - acc: 0.4995 - val_loss: 1.4613 - val_acc: 0.4032\n",
      "Epoch 64/100\n",
      "34s - loss: 1.2137 - acc: 0.4942 - val_loss: 1.4612 - val_acc: 0.4032\n",
      "Epoch 65/100\n",
      "33s - loss: 1.2101 - acc: 0.5024 - val_loss: 1.4612 - val_acc: 0.4023\n",
      "Epoch 66/100\n",
      "34s - loss: 1.2129 - acc: 0.5010 - val_loss: 1.4623 - val_acc: 0.4027\n",
      "Epoch 67/100\n",
      "34s - loss: 1.2128 - acc: 0.4971 - val_loss: 1.4618 - val_acc: 0.4036\n",
      "Epoch 68/100\n",
      "34s - loss: 1.2117 - acc: 0.4952 - val_loss: 1.4622 - val_acc: 0.4009\n",
      "Epoch 69/100\n",
      "33s - loss: 1.2120 - acc: 0.5020 - val_loss: 1.4621 - val_acc: 0.4009\n",
      "Epoch 70/100\n",
      "34s - loss: 1.2100 - acc: 0.4984 - val_loss: 1.4623 - val_acc: 0.4023\n",
      "Epoch 71/100\n",
      "34s - loss: 1.2108 - acc: 0.5006 - val_loss: 1.4621 - val_acc: 0.4023\n",
      "Epoch 72/100\n",
      "33s - loss: 1.2053 - acc: 0.5026 - val_loss: 1.4625 - val_acc: 0.4032\n",
      "Epoch 73/100\n",
      "34s - loss: 1.2094 - acc: 0.5037 - val_loss: 1.4619 - val_acc: 0.4027\n",
      "Epoch 74/100\n",
      "33s - loss: 1.2075 - acc: 0.5020 - val_loss: 1.4625 - val_acc: 0.4036\n",
      "Epoch 75/100\n",
      "34s - loss: 1.2155 - acc: 0.4983 - val_loss: 1.4622 - val_acc: 0.4032\n",
      "Epoch 76/100\n",
      "33s - loss: 1.2091 - acc: 0.4990 - val_loss: 1.4625 - val_acc: 0.4032\n",
      "Epoch 77/100\n",
      "34s - loss: 1.2110 - acc: 0.5008 - val_loss: 1.4632 - val_acc: 0.4018\n",
      "Epoch 78/100\n",
      "34s - loss: 1.2065 - acc: 0.4992 - val_loss: 1.4624 - val_acc: 0.4032\n",
      "Epoch 79/100\n",
      "33s - loss: 1.2119 - acc: 0.5017 - val_loss: 1.4627 - val_acc: 0.4032\n",
      "Epoch 80/100\n",
      "34s - loss: 1.2095 - acc: 0.4964 - val_loss: 1.4630 - val_acc: 0.4032\n",
      "Epoch 81/100\n",
      "33s - loss: 1.2085 - acc: 0.5026 - val_loss: 1.4627 - val_acc: 0.4032\n",
      "Epoch 82/100\n",
      "34s - loss: 1.2121 - acc: 0.5017 - val_loss: 1.4622 - val_acc: 0.4027\n",
      "Epoch 83/100\n",
      "33s - loss: 1.2061 - acc: 0.5019 - val_loss: 1.4626 - val_acc: 0.4036\n",
      "Epoch 84/100\n",
      "34s - loss: 1.2125 - acc: 0.4973 - val_loss: 1.4625 - val_acc: 0.4023\n",
      "Epoch 85/100\n",
      "34s - loss: 1.2055 - acc: 0.4996 - val_loss: 1.4629 - val_acc: 0.4032\n",
      "Epoch 86/100\n",
      "33s - loss: 1.2078 - acc: 0.4984 - val_loss: 1.4629 - val_acc: 0.4041\n",
      "Epoch 87/100\n",
      "34s - loss: 1.2065 - acc: 0.5009 - val_loss: 1.4625 - val_acc: 0.4041\n",
      "Epoch 88/100\n",
      "33s - loss: 1.2057 - acc: 0.5030 - val_loss: 1.4629 - val_acc: 0.4036\n",
      "Epoch 89/100\n",
      "34s - loss: 1.2052 - acc: 0.5044 - val_loss: 1.4630 - val_acc: 0.4027\n",
      "Epoch 90/100\n",
      "33s - loss: 1.2044 - acc: 0.5019 - val_loss: 1.4631 - val_acc: 0.4027\n",
      "Epoch 91/100\n",
      "34s - loss: 1.2011 - acc: 0.5025 - val_loss: 1.4631 - val_acc: 0.4027\n",
      "Epoch 92/100\n",
      "34s - loss: 1.2060 - acc: 0.5058 - val_loss: 1.4633 - val_acc: 0.4018\n",
      "Epoch 93/100\n",
      "34s - loss: 1.2046 - acc: 0.5058 - val_loss: 1.4635 - val_acc: 0.4027\n",
      "Epoch 94/100\n",
      "34s - loss: 1.2095 - acc: 0.5025 - val_loss: 1.4633 - val_acc: 0.4027\n",
      "Epoch 95/100\n",
      "33s - loss: 1.2054 - acc: 0.5002 - val_loss: 1.4632 - val_acc: 0.4045\n",
      "Epoch 96/100\n",
      "34s - loss: 1.2028 - acc: 0.5071 - val_loss: 1.4632 - val_acc: 0.4041\n",
      "Epoch 97/100\n",
      "33s - loss: 1.2088 - acc: 0.5053 - val_loss: 1.4632 - val_acc: 0.4027\n",
      "Epoch 98/100\n",
      "34s - loss: 1.1972 - acc: 0.5023 - val_loss: 1.4629 - val_acc: 0.4027\n",
      "Epoch 99/100\n",
      "34s - loss: 1.2028 - acc: 0.5050 - val_loss: 1.4629 - val_acc: 0.4018\n",
      "Epoch 100/100\n",
      "33s - loss: 1.2033 - acc: 0.5029 - val_loss: 1.4633 - val_acc: 0.4032\n"
     ]
    }
   ],
   "source": [
    "# Loading saved data\n",
    "import pickle\n",
    "\n",
    "# filename = '/home/shikhar/Datasets/Models/CNN-rand_continued_2017-04-02_07:34:54'\n",
    "with open( filename, 'rb') as input:\n",
    "    out = pickle.load(input)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adadelta(lr=.5, decay=0.005), metrics=[\"accuracy\"])\n",
    "model.set_weights(out[1])\n",
    "\n",
    "res = model.fit(x_train, y_train, \n",
    "          batch_size = batch_size,\n",
    "          epochs=100,\n",
    "          validation_data=(x_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "date = str(datetime.date.today() )\n",
    "time = str(datetime.datetime.now().time())[:-7]\n",
    "\n",
    "filename = '/home/shikhar/Datasets/Models/' + model_type + '_continued_' + date + '_' +time;\n",
    "with open( filename, 'wb') as output:\n",
    "    pickle.dump([model.get_config(), model.get_weights(), model.history.history], output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9645 samples, validate on 2210 samples\n",
      "Epoch 1/50\n",
      "29s - loss: 1.2987 - acc: 0.5014 - val_loss: 1.5091 - val_acc: 0.4100\n",
      "Epoch 2/50\n",
      "27s - loss: 1.1156 - acc: 0.5962 - val_loss: 1.6418 - val_acc: 0.3842\n",
      "Epoch 3/50\n",
      "29s - loss: 0.9404 - acc: 0.6837 - val_loss: 1.8923 - val_acc: 0.3814\n",
      "Epoch 4/50\n",
      "27s - loss: 0.7824 - acc: 0.7579 - val_loss: 2.1546 - val_acc: 0.3710\n",
      "Epoch 5/50\n",
      "27s - loss: 0.6796 - acc: 0.8083 - val_loss: 2.3504 - val_acc: 0.3787\n",
      "Epoch 6/50\n",
      "27s - loss: 0.5658 - acc: 0.8540 - val_loss: 2.6239 - val_acc: 0.3697\n",
      "Epoch 7/50\n",
      "27s - loss: 0.5065 - acc: 0.8782 - val_loss: 2.8259 - val_acc: 0.3620\n",
      "Epoch 8/50\n",
      "28s - loss: 0.4497 - acc: 0.8980 - val_loss: 3.0957 - val_acc: 0.3760\n",
      "Epoch 9/50\n",
      "30s - loss: 0.4030 - acc: 0.9157 - val_loss: 3.2679 - val_acc: 0.3575\n",
      "Epoch 10/50\n",
      "27s - loss: 0.3794 - acc: 0.9259 - val_loss: 3.4511 - val_acc: 0.3602\n",
      "Epoch 11/50\n",
      "28s - loss: 0.3592 - acc: 0.9279 - val_loss: 3.4120 - val_acc: 0.3652\n",
      "Epoch 12/50\n",
      "28s - loss: 0.3331 - acc: 0.9337 - val_loss: 3.5887 - val_acc: 0.3480\n",
      "Epoch 13/50\n",
      "28s - loss: 0.3139 - acc: 0.9448 - val_loss: 3.8514 - val_acc: 0.3498\n",
      "Epoch 14/50\n",
      "28s - loss: 0.3153 - acc: 0.9434 - val_loss: 3.9626 - val_acc: 0.3584\n",
      "Epoch 15/50\n",
      "29s - loss: 0.2984 - acc: 0.9498 - val_loss: 4.2054 - val_acc: 0.3525\n",
      "Epoch 16/50\n",
      "28s - loss: 0.2722 - acc: 0.9532 - val_loss: 4.3271 - val_acc: 0.3615\n",
      "Epoch 17/50\n",
      "29s - loss: 0.2713 - acc: 0.9551 - val_loss: 4.3429 - val_acc: 0.3480\n",
      "Epoch 18/50\n",
      "30s - loss: 0.2739 - acc: 0.9576 - val_loss: 4.3322 - val_acc: 0.3588\n",
      "Epoch 19/50\n",
      "29s - loss: 0.2518 - acc: 0.9615 - val_loss: 4.5974 - val_acc: 0.3489\n",
      "Epoch 20/50\n",
      "27s - loss: 0.2496 - acc: 0.9626 - val_loss: 4.4761 - val_acc: 0.3471\n",
      "Epoch 21/50\n",
      "29s - loss: 0.2569 - acc: 0.9601 - val_loss: 4.6500 - val_acc: 0.3511\n",
      "Epoch 22/50\n",
      "30s - loss: 0.2483 - acc: 0.9646 - val_loss: 4.4837 - val_acc: 0.3656\n",
      "Epoch 23/50\n",
      "28s - loss: 0.2395 - acc: 0.9680 - val_loss: 4.7591 - val_acc: 0.3462\n",
      "Epoch 24/50\n",
      "28s - loss: 0.2465 - acc: 0.9658 - val_loss: 5.1256 - val_acc: 0.3357\n",
      "Epoch 25/50\n",
      "27s - loss: 0.2333 - acc: 0.9696 - val_loss: 4.9469 - val_acc: 0.3462\n",
      "Epoch 26/50\n"
     ]
    }
   ],
   "source": [
    "# Loading saved data\n",
    "import pickle\n",
    "\n",
    "# filename = '/home/shikhar/Datasets/Models/CNN-rand_continued_2017-04-02_07:34:54'\n",
    "with open( filename, 'rb') as input:\n",
    "    out = pickle.load(input)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(), metrics=[\"accuracy\"])\n",
    "model.set_weights(out[1])\n",
    "\n",
    "res = model.fit(x_train, y_train, \n",
    "          batch_size = batch_size,\n",
    "          epochs=50,\n",
    "          validation_data=(x_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('say done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
