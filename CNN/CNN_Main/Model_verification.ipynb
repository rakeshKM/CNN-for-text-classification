{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import data_helpers\n",
    "from w2v import train_word2vec\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------- Parameters section -------------------\n",
    "#\n",
    "# Model type. See Kim Yoon's Convolutional Neural Networks for Sentence Classification, Section 3\n",
    "model_type = \"CNN-rand\"  # CNN-rand|CNN-non-static|CNN-static\n",
    "\n",
    "# Model Hyperparameters\n",
    "embedding_dim = 50\n",
    "filter_sizes = (3, 8)\n",
    "num_filters = 10\n",
    "dropout_prob = (0.5, 0.8)\n",
    "hidden_dims = 50\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "# Prepossessing parameters\n",
    "sequence_length = 400\n",
    "max_words = 5000\n",
    "\n",
    "# Word2Vec parameters (see train_word2vec)\n",
    "min_word_count = 1\n",
    "context = 10\n",
    "#\n",
    "# ---------------------- Parameters end -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n",
      "x_train shape: (25000, 400)\n",
      "x_test shape: (25000, 400)\n",
      "Model type is CNN-rand\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "47s - loss: 0.6047 - acc: 0.6160 - val_loss: 0.3351 - val_acc: 0.8609\n",
      "Epoch 2/10\n",
      "42s - loss: 0.3071 - acc: 0.8724 - val_loss: 0.2760 - val_acc: 0.8838\n",
      "Epoch 3/10\n",
      "39s - loss: 0.2571 - acc: 0.8978 - val_loss: 0.2812 - val_acc: 0.8832\n",
      "Epoch 4/10\n",
      "39s - loss: 0.2352 - acc: 0.9084 - val_loss: 0.2802 - val_acc: 0.8839\n",
      "Epoch 5/10\n",
      "41s - loss: 0.2213 - acc: 0.9120 - val_loss: 0.2751 - val_acc: 0.8872\n",
      "Epoch 6/10\n",
      "38s - loss: 0.2132 - acc: 0.9156 - val_loss: 0.2767 - val_acc: 0.8846\n",
      "Epoch 7/10\n",
      "39s - loss: 0.1939 - acc: 0.9246 - val_loss: 0.2893 - val_acc: 0.8826\n",
      "Epoch 8/10\n",
      "39s - loss: 0.1895 - acc: 0.9237 - val_loss: 0.2966 - val_acc: 0.8806\n",
      "Epoch 9/10\n",
      "38s - loss: 0.1855 - acc: 0.9280 - val_loss: 0.3016 - val_acc: 0.8814\n",
      "Epoch 10/10\n",
      "39s - loss: 0.1781 - acc: 0.9280 - val_loss: 0.2991 - val_acc: 0.8804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe5b3beb6a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Preparation\n",
    "print(\"Load data...\")\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_words, start_char=None)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=sequence_length, padding=\"post\", truncating=\"post\")\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=sequence_length, padding=\"post\", truncating=\"post\")\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "\n",
    "vocabulary = imdb.get_word_index()\n",
    "vocabulary_inv = dict((v, k) for k, v in vocabulary.items())\n",
    "vocabulary_inv[0] = \"<PAD/>\"\n",
    "\n",
    "\n",
    "# Prepare embedding layer weights and convert inputs for static model\n",
    "print(\"Model type is\", model_type)\n",
    "if model_type == \"CNN-non-static\" or model_type == \"CNN-static\":\n",
    "    embedding_weights = train_word2vec(np.vstack((x_train, x_test)), vocabulary_inv, num_features=embedding_dim,\n",
    "                                       min_word_count=min_word_count, context=context)\n",
    "    if model_type == \"CNN-static\":\n",
    "        x_train = embedding_weights[0][x_train]\n",
    "        x_test = embedding_weights[0][x_test]\n",
    "elif model_type == \"CNN-rand\":\n",
    "    embedding_weights = None\n",
    "else:\n",
    "    raise ValueError(\"Unknown model type\")\n",
    "\n",
    "\n",
    "# Build model\n",
    "input_shape = (sequence_length, embedding_dim) if model_type == \"CNN-static\" else (sequence_length,)\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "# Static model do not have embedding layer\n",
    "if model_type == \"CNN-static\":\n",
    "    z = Dropout(dropout_prob[0])(model_input)\n",
    "else:\n",
    "    z = Embedding(len(vocabulary_inv), embedding_dim, input_length=sequence_length, name=\"embedding\")(model_input)\n",
    "    z = Dropout(dropout_prob[0])(z)\n",
    "\n",
    "# Convolutional block\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes:\n",
    "    conv = Convolution1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"valid\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    conv = MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "z = Dropout(dropout_prob[1])(z)\n",
    "z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "model_output = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Initialize weights with word2vec\n",
    "if model_type == \"CNN-non-static\":\n",
    "    embedding_layer = model.get_layer(\"embedding\")\n",
    "    embedding_layer.set_weights(embedding_weights)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          validation_data=(x_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
